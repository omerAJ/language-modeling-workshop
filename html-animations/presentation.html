<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Day 1 — Language Modeling from Scratch</title>
<style>
  @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap');

  * { margin: 0; padding: 0; box-sizing: border-box; }

  :root {
    --bg: #0f1117;
    --surface: #1a1d27;
    --surface2: #242836;
    --border: #2e3345;
    --text: #f3f3f5;
    --text-dim: #8a8fa8;
    --accent: #6c8cff;
    --accent-glow: rgba(108,140,255,0.25);
    --green: #4ade80;
    --green-glow: rgba(74,222,128,0.2);
    --red: #f87171;
    --orange: #fb923c;
    --purple: #a78bfa;
    --yellow: #facc15;
    --cyan: #22d3ee;
    --pink: #f472b6;
    --slide-max-width: 1100px;
  }

  body {
    background: var(--bg);
    color: var(--text);
    font-family: 'Inter', sans-serif;
    height: 100vh;
    overflow: hidden;
    display: flex;
    flex-direction: column;
  }

  /* ── Slide system ── */
  .slide-container {
    flex: 1;
    position: relative;
    overflow: hidden;
  }
  .slide {
    position: absolute;
    inset: 0;
    display: none;
    flex-direction: column;
    padding: 40px max(60px, calc((100vw - var(--slide-max-width)) / 2)) 80px;
    overflow-y: auto;
    scrollbar-width: thin;
    scrollbar-color: var(--border) transparent;
    animation: fadeSlideIn 0.45s ease;
  }
  .slide.active { display: flex; }

  @keyframes fadeSlideIn {
    from { opacity: 0; transform: translateY(20px); }
    to   { opacity: 1; transform: translateY(0); }
  }

  .slide.centered {
    align-items: center;
    justify-content: center;
    text-align: center;
  }

  /* ── Typography ── */
  h1 {
    font-size: 2.6rem;
    font-weight: 800;
    letter-spacing: -0.03em;
    line-height: 1.15;
    background: linear-gradient(135deg, var(--accent), var(--purple));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
  }
  h1.large { font-size: 3.2rem; }
  h2 {
    font-size: 1.6rem;
    font-weight: 700;
    letter-spacing: -0.02em;
    margin-bottom: 12px;
  }
  h3 {
    font-size: 1.1rem;
    font-weight: 600;
    margin-bottom: 8px;
  }
  .subtitle {
    font-size: 1.15rem;
    color: var(--text-dim);
    margin-top: 8px;
    line-height: 1.5;
    max-width: 700px;
  }
  .small-text {
    font-size: 0.85rem;
    color: var(--text-dim);
    line-height: 1.55;
  }
  .tiny {
    font-size: 0.75rem;
    color: var(--text-dim);
  }

  /* ── Highlight spans ── */
  .hl        { color: var(--accent); font-weight: 600; }
  .hl-green  { color: var(--green);  font-weight: 600; }
  .hl-red    { color: var(--red);    font-weight: 600; }
  .hl-orange { color: var(--orange); font-weight: 600; }
  .hl-purple { color: var(--purple); font-weight: 600; }
  .hl-yellow { color: var(--yellow); font-weight: 600; }
  .hl-cyan   { color: var(--cyan);   font-weight: 600; }
  .hl-pink   { color: var(--pink);   font-weight: 600; }

  /* ── Cards ── */
  .card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 14px;
    padding: 24px;
    position: relative;
    overflow: visible;
  }
  .card::before {
    content: '';
    position: absolute;
    inset: 0;
    border-radius: inherit;
    background: radial-gradient(ellipse at top left, rgba(108,140,255,0.04), transparent 60%);
    pointer-events: none;
  }

  /* ── Callouts ── */
  .callout {
    display: flex;
    gap: 10px;
    padding: 14px 18px;
    border-radius: 10px;
    font-size: 0.85rem;
    line-height: 1.55;
  }
  .callout.info    { background: rgba(108,140,255,0.08); border: 1px solid rgba(108,140,255,0.18); color: #b8c7ff; }
  .callout.warn    { background: rgba(251,146,60,0.08);  border: 1px solid rgba(251,146,60,0.18);  color: #fdc89b; }
  .callout.success { background: rgba(74,222,128,0.08);  border: 1px solid rgba(74,222,128,0.18);  color: #9eefbe; }
  .callout.question { background: rgba(167,139,250,0.08); border: 1px solid rgba(167,139,250,0.18); color: #cbb8ff; }
  .callout.pink    { background: rgba(244,114,182,0.08); border: 1px solid rgba(244,114,182,0.18); color: #fbb8d8; }
  .callout .icon { flex-shrink: 0; font-size: 1.1rem; }

  /* ── Badges / pills ── */
  .badge {
    display: inline-block;
    font-size: 0.7rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    padding: 4px 12px;
    border-radius: 20px;
    margin-bottom: 12px;
  }
  .badge.day1 { background: rgba(108,140,255,0.15); color: var(--accent); }
  .badge.activity { background: rgba(74,222,128,0.15); color: var(--green); }
  .badge.concept { background: rgba(167,139,250,0.15); color: var(--purple); }
  .badge.discussion { background: rgba(251,146,60,0.15); color: var(--orange); }
  .badge.deepdive { background: rgba(250,204,21,0.15); color: var(--yellow); }

  /* ── Grid layouts ── */
  .grid-2 { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
  .grid-3 { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 16px; }
  .grid-4 { display: grid; grid-template-columns: repeat(4, 1fr); gap: 14px; }
  @media (max-width: 800px) {
    .grid-2, .grid-3, .grid-4 { grid-template-columns: 1fr; }
  }
  @media (max-width: 768px) {
    .slide { padding: 30px 24px 70px; }
  }

  /* ── Flow diagrams ── */
  .flow {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 10px;
    flex-wrap: wrap;
    margin: 16px 0;
  }
  .flow-box {
    padding: 12px 20px;
    border-radius: 10px;
    font-size: 0.85rem;
    font-weight: 600;
    text-align: center;
    border: 1px solid var(--border);
    background: var(--surface);
    min-width: 100px;
  }
  .flow-arrow {
    display: none;          /* arrows now live as ::before on each box */
  }
  .flow .flow-box ~ .flow-box {
    position: relative;
    margin-left: 24px;
  }
  .flow .flow-box ~ .flow-box::before {
    content: '→';
    position: absolute;
    right: calc(100% + 4px);
    top: 50%;
    transform: translateY(-50%);
    color: var(--text-dim);
    font-size: 1.3rem;
    pointer-events: none;
  }
  .flow-loop {
    color: var(--text-dim);
    font-size: 1.3rem;
    flex-shrink: 0;
  }
  .flow-box.data    { border-color: rgba(34,211,238,0.4); color: var(--cyan); background: rgba(34,211,238,0.06); }
  .flow-box.model   { border-color: rgba(108,140,255,0.4); color: var(--accent); background: rgba(108,140,255,0.06); }
  .flow-box.blue    { border-color: rgba(108,140,255,0.4); color: var(--accent); background: rgba(108,140,255,0.06); }
  .flow-box.loss    { border-color: rgba(248,113,113,0.4); color: var(--red); background: rgba(248,113,113,0.06); }
  .flow-box.grad    { border-color: rgba(251,146,60,0.4); color: var(--orange); background: rgba(251,146,60,0.06); }
  .flow-box.param   { border-color: rgba(167,139,250,0.4); color: var(--purple); background: rgba(167,139,250,0.06); }
  .flow-box.target  { border-color: rgba(74,222,128,0.5); color: var(--green); background: rgba(74,222,128,0.08); border-style: dashed; }
  .flow-box.green   { border-color: rgba(74,222,128,0.4); color: var(--green); background: rgba(74,222,128,0.06); }
  .flow-box.pink    { border-color: rgba(244,114,182,0.4); color: var(--pink); background: rgba(244,114,182,0.06); }
  .flow-box.yellow  { border-color: rgba(250,204,21,0.4); color: var(--yellow); background: rgba(250,204,21,0.06); }
  /* Backward flow — arrows point left for backpropagation */
  .flow.flow-backward .flow-box ~ .flow-box::before { content: '←'; }

  /* ── Live demo video ── */
  .live-demo-shell {
    width: 100%;
    max-width: 100%;
    margin: 0;
    border: 1px solid var(--border);
    border-radius: 12px;
    background: var(--surface2);
    overflow: hidden;
    aspect-ratio: 16 / 9;
  }
  .live-demo-placeholder {
    height: 100%;
    min-height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
    flex-direction: column;
    gap: 10px;
    padding: 20px;
  }
  .live-demo-video {
    width: 100%;
    height: 100%;
    display: block;
    background: #000;
    object-fit: contain;
  }

  .forward-pass-caption {
    font-size: 0.95rem;
    margin-top: 18px;
    opacity: 0.9;
  }

  /* ── Interactive reveal ── */
  .reveal-btn {
    font-family: 'Inter', sans-serif;
    font-size: 0.85rem;
    font-weight: 600;
    padding: 10px 24px;
    border-radius: 10px;
    border: 1px dashed var(--purple);
    background: rgba(167,139,250,0.08);
    color: var(--purple);
    cursor: pointer;
    transition: all 0.3s;
    margin-top: 8px;
  }
  .reveal-btn:hover { background: rgba(167,139,250,0.15); }
  .hidden-content {
    overflow: hidden;
    max-height: 0;
    opacity: 0;
    transition: max-height 0.6s ease, opacity 0.4s ease, margin 0.4s ease;
    margin-top: 0;
  }
  .hidden-content.revealed {
    max-height: 2000px;
    opacity: 1;
    margin-top: 16px;
  }
  .hidden-content.revealed.settled {
    max-height: none;
    overflow: visible;
  }

  /* ── NTP game ── */
  .ntp-sentence {
    font-family: 'JetBrains Mono', monospace;
    font-size: 1.15rem;
    line-height: 1.7;
    padding: 18px 22px;
    background: var(--surface2);
    border-radius: 10px;
    border: 1px solid var(--border);
    margin: 10px 0;
  }
  .ntp-blank {
    display: inline-block;
    min-width: 80px;
    border-bottom: 2px dashed var(--orange);
    color: var(--orange);
    text-align: center;
    padding: 0 4px;
    cursor: pointer;
    transition: all 0.3s;
  }
  .ntp-blank.show {
    border-bottom-color: var(--green);
    color: var(--green);
    font-weight: 600;
  }
  .ntp-concept-btn {
    display: inline-block;
    margin-left: 8px;
    padding: 1px 8px;
    border-radius: 6px;
    border: 1px dashed var(--purple);
    color: var(--purple);
    font-size: 0.68rem;
    font-weight: 600;
    cursor: pointer;
    vertical-align: middle;
    transition: all 0.2s;
  }
  .ntp-concept-btn:hover { background: rgba(167,139,250,0.1); }
  .ntp-tag {
    display: inline-block;
    font-size: 0.7rem;
    font-weight: 600;
    padding: 2px 8px;
    border-radius: 6px;
    margin-left: 8px;
    vertical-align: middle;
    opacity: 0;
    transform: translateY(3px);
    transition: opacity 0.25s ease, transform 0.25s ease;
    pointer-events: none;
  }
  .ntp-tag.show { opacity: 1; transform: translateY(0); }
  .ntp-tag.fact  { background: rgba(34,211,238,0.15); color: var(--cyan); }
  .ntp-tag.logic { background: rgba(251,146,60,0.15); color: var(--orange); }
  .ntp-tag.code  { background: rgba(167,139,250,0.15); color: var(--purple); }
  .ntp-tag.lang  { background: rgba(108,140,255,0.15); color: var(--accent); }
  .ntp-tag.math  { background: rgba(250,204,21,0.15); color: var(--yellow); }

  /* ── Math formulas ── */
  .math {
    font-family: 'JetBrains Mono', monospace;
    font-size: 1rem;
    text-align: center;
    padding: 16px;
    background: var(--surface2);
    border-radius: 10px;
    margin: 12px 0;
    color: var(--yellow);
    letter-spacing: 0.02em;
    line-height: 1.6;
  }
  .math-big { font-size: 1.3rem; padding: 22px; }
  .math mjx-container {
    margin: 0 auto !important;
    color: inherit;
  }
  .math mjx-container[display="true"] {
    margin: 0 auto !important;
  }

  /* ── Animated gradient line ── */
  .gradient-line {
    height: 2px;
    background: linear-gradient(90deg, var(--accent), var(--purple), var(--accent));
    background-size: 200% 100%;
    animation: shimmer 2s linear infinite;
    border-radius: 2px;
    margin: 10px 0;
  }
  @keyframes shimmer {
    0%   { background-position: 200% 0; }
    100% { background-position: -200% 0; }
  }

  /* ── Token display ── */
  .token-row {
    display: flex;
    align-items: center;
    gap: 6px;
    flex-wrap: wrap;
    font-family: 'JetBrains Mono', monospace;
    font-size: 1.05rem;
    margin: 12px 0;
  }
  .tok {
    display: inline-flex;
    align-items: center;
    padding: 5px 12px;
    border-radius: 7px;
    background: var(--surface2);
    border: 1px solid var(--border);
    white-space: nowrap;
  }
  .tok.input  { border-color: var(--accent); background: rgba(108,140,255,0.1); }
  .tok.target { border-color: var(--green);  background: rgba(74,222,128,0.1); color: var(--green); font-weight: 600; }
  .tok.blank  { border: 2px dashed var(--orange); color: var(--orange); min-width: 60px; justify-content: center; cursor: pointer; }
  .tok.done   { border: 1px solid var(--text-dim); color: var(--text-dim); cursor: default; opacity: 0.5; }

  /* ── Pipeline boxes ── */
  .pipeline-box {
    padding: 20px;
    border-radius: 12px;
    border: 1px solid var(--border);
    background: var(--surface);
    position: relative;
  }
  .pipeline-box h3 { font-size: 1rem; margin-bottom: 6px; }
  .pipeline-box .small-text { font-size: 0.8rem; }
  .pipeline-box .pipe-num {
    position: absolute;
    top: -10px; left: -10px;
    width: 26px; height: 26px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 0.75rem;
    font-weight: 700;
    color: #fff;
  }

  /* ── Not-in-objective list ── */
  .not-list {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    margin: 12px 0;
  }
  .not-item {
    padding: 8px 16px;
    border-radius: 8px;
    font-size: 0.85rem;
    font-weight: 500;
    background: rgba(248,113,113,0.06);
    border: 1px solid rgba(248,113,113,0.2);
    color: var(--red);
    position: relative;
    padding-left: 32px;
  }
  .not-item::before {
    content: '✕';
    position: absolute;
    left: 12px;
    top: 50%;
    transform: translateY(-50%);
    font-weight: 700;
    font-size: 0.75rem;
  }

  /* ── Data stats ── */
  .data-stat { text-align: center; padding: 16px; }
  .data-stat .big-num {
    font-family: 'JetBrains Mono', monospace;
    font-size: 2rem;
    font-weight: 700;
  }
  .data-stat .stat-label {
    font-size: 0.78rem;
    color: var(--text-dim);
    margin-top: 2px;
  }

  /* ── Bar chart (for loss deep-dive slides) ── */
  .bar-row {
    display: flex;
    align-items: center;
    gap: 10px;
    margin-bottom: 6px;
    height: 28px;
  }
  .bar-word {
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.8rem;
    width: 75px;
    text-align: right;
    color: var(--text-dim);
    flex-shrink: 0;
  }
  .bar-track {
    flex: 1;
    height: 22px;
    background: var(--surface2);
    border-radius: 6px;
    overflow: hidden;
  }
  .bar-fill {
    height: 100%;
    border-radius: 6px;
    transition: width 1s cubic-bezier(0.22, 1, 0.36, 1);
    min-width: 0;
  }
  .bar-fill.predicted { background: linear-gradient(90deg, var(--accent), var(--purple)); }
  .bar-fill.target-fill { background: linear-gradient(90deg, var(--green), #34d399); }
  .bar-pct {
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.72rem;
    color: var(--text-dim);
    width: 48px;
    text-align: left;
    flex-shrink: 0;
  }

  /* dual chart layout */
  .dual-charts {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 20px;
    margin-top: 10px;
  }
  @media (max-width: 640px) {
    .dual-charts { grid-template-columns: 1fr; }
  }
  .chart-col {
    background: var(--surface2);
    border-radius: 10px;
    padding: 14px;
  }
  .chart-title {
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    margin-bottom: 8px;
  }

  /* loss display */
  .loss-display {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 18px;
    margin: 16px 0;
    flex-wrap: wrap;
  }
  .loss-box {
    text-align: center;
    padding: 14px 24px;
    border-radius: 12px;
    background: var(--surface2);
    border: 1px solid var(--border);
    min-width: 130px;
  }
  .loss-box .label {
    font-size: 0.7rem;
    text-transform: uppercase;
    letter-spacing: 0.06em;
    color: var(--text-dim);
    margin-bottom: 4px;
  }
  .loss-box .value {
    font-family: 'JetBrains Mono', monospace;
    font-size: 1.4rem;
    font-weight: 700;
  }
  .loss-box .value.high { color: var(--red); }
  .loss-box .value.low  { color: var(--green); }
  .loss-box .formula {
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.7rem;
    color: var(--text-dim);
    margin-top: 4px;
  }
  .comparison-arrow {
    font-size: 2rem;
    color: var(--text-dim);
    animation: pulseOpacity 1.5s ease-in-out infinite;
  }
  @keyframes pulseOpacity {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.3; }
  }

  /* loss meter */
  .loss-meter {
    width: 100%;
    height: 10px;
    border-radius: 6px;
    background: var(--surface2);
    margin: 8px 0;
    overflow: hidden;
  }
  .loss-meter-fill {
    height: 100%;
    border-radius: 6px;
    transition: width 1.2s cubic-bezier(0.22, 1, 0.36, 1);
  }

  /* before / after */
  .before-after {
    display: grid;
    grid-template-columns: 1fr auto 1fr;
    gap: 16px;
    align-items: start;
    margin-top: 10px;
  }
  @media (max-width: 640px) {
    .before-after { grid-template-columns: 1fr; }
  }
  .ba-col {
    background: var(--surface2);
    border-radius: 10px;
    padding: 14px;
  }
  .ba-col .ba-label {
    font-size: 0.72rem;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    font-weight: 600;
    margin-bottom: 8px;
  }
  .ba-col.before .ba-label { color: var(--red); }
  .ba-col.after  .ba-label { color: var(--green); }
  .ba-arrow {
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 1.8rem;
    color: var(--text-dim);
    padding-top: 40px;
  }

  /* backprop arrows */
  .backprop-arrows {
    display: flex;
    justify-content: center;
    gap: 4px;
    margin: 8px 0;
    font-size: 1.3rem;
  }
  .backprop-arrows span {
    color: var(--orange);
    animation: flowLeft 1s ease-in-out infinite;
    animation-delay: 0.45s;
  }
  .backprop-arrows span:nth-child(2) { animation-delay: 0.30s; }
  .backprop-arrows span:nth-child(3) { animation-delay: 0.15s; }
  .backprop-arrows span:nth-child(4) { animation-delay: 0.0s; }
  @keyframes flowLeft {
    0%, 100% { opacity: 0.2; }
    50% { opacity: 1; }
  }

  /* flow node (for backprop) */
  .update-flow {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 12px;
    margin: 14px 0;
    flex-wrap: wrap;
  }
  .flow-node {
    padding: 10px 18px;
    border-radius: 10px;
    font-size: 0.82rem;
    font-weight: 600;
    text-align: center;
    border: 1px solid var(--border);
  }
  .flow-node.loss-node   { background: rgba(248,113,113,0.1); border-color: rgba(248,113,113,0.3); color: var(--red); }
  .flow-node.grad-node   { background: rgba(251,146,60,0.1);  border-color: rgba(251,146,60,0.3);  color: var(--orange); }
  .flow-node.param-node  { background: rgba(167,139,250,0.1); border-color: rgba(167,139,250,0.3); color: var(--purple); }
  .flow-node.better-node { background: rgba(74,222,128,0.1);  border-color: rgba(74,222,128,0.3);  color: var(--green); }

  /* ── Bottom nav ── */
  .bottom-bar {
    display: flex;
    align-items: center;
    justify-content: space-between;
    position: fixed;
    left: 0;
    right: 0;
    bottom: 0;
    padding: 10px 24px;
    background: var(--surface);
    border-top: 1px solid var(--border);
    z-index: 10;
    flex-shrink: 0;
  }
  .progress-track {
    flex: 1;
    height: 3px;
    background: var(--surface2);
    border-radius: 3px;
    margin: 0 20px;
    overflow: hidden;
  }
  .progress-fill {
    height: 100%;
    background: linear-gradient(90deg, var(--accent), var(--purple));
    border-radius: 3px;
    transition: width 0.4s ease;
  }
  .nav-btn {
    font-family: 'Inter', sans-serif;
    font-size: 0.82rem;
    font-weight: 600;
    padding: 8px 22px;
    border-radius: 8px;
    border: 1px solid var(--border);
    background: var(--surface2);
    color: var(--text);
    cursor: pointer;
    transition: all 0.2s;
    white-space: nowrap;
  }
  .nav-btn:hover { background: var(--border); }
  .nav-btn.primary { background: var(--accent); border-color: var(--accent); color: #fff; }
  .nav-btn.primary:hover { background: #5a7bef; }
  .nav-btn:disabled { opacity: 0.3; cursor: not-allowed; }
  .slide-counter {
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.75rem;
    color: var(--text-dim);
    min-width: 60px;
    text-align: center;
  }

  /* ── Speaker notes ── */
  .speaker-notes { margin-top: auto; padding-top: 16px; }
  .notes-toggle {
    font-family: 'Inter', sans-serif;
    font-size: 0.72rem;
    font-weight: 500;
    color: var(--text-dim);
    background: none;
    border: 1px solid var(--border);
    padding: 4px 12px;
    border-radius: 6px;
    cursor: pointer;
    transition: all 0.2s;
  }
  .notes-toggle:hover { background: var(--surface2); }
  .notes-body {
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.4s ease, opacity 0.3s ease;
    opacity: 0;
  }
  .notes-body.open {
    max-height: 400px;
    opacity: 1;
    margin-top: 8px;
  }
  .notes-body p {
    font-size: 0.8rem;
    color: var(--text-dim);
    line-height: 1.55;
    font-style: italic;
    padding: 10px 14px;
    background: var(--surface2);
    border-radius: 8px;
    border-left: 3px solid var(--accent);
  }

  /* ── Spacers ── */
  .spacer-sm { height: 12px; }
  .spacer    { height: 20px; }
  .spacer-lg { height: 32px; }

  /* ── Objective list ── */
  .obj-list { list-style: none; margin: 10px 0; }
  .obj-list li {
    padding: 10px 16px 10px 36px;
    border-radius: 8px;
    margin-bottom: 8px;
    font-size: 0.9rem;
    line-height: 1.5;
    background: var(--surface2);
    border: 1px solid var(--border);
    position: relative;
  }
  .obj-list li::before {
    content: attr(data-num);
    position: absolute;
    left: 12px;
    top: 10px;
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.75rem;
    font-weight: 700;
    color: var(--accent);
  }

  .loop-arrow-anim { animation: pulseGlow 1.5s ease-in-out infinite; }
  @keyframes pulseGlow { 0%, 100% { opacity: 0.5; } 50% { opacity: 1; } }

  .section-tag {
    position: absolute;
    top: 18px; left: 28px;
    font-size: 0.7rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.07em;
    color: var(--text-dim);
    opacity: 0.5;
  }

  /* network box (for forward-pass slide) */
  .network-box {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 14px;
    padding: 16px 24px;
    background: linear-gradient(135deg, rgba(108,140,255,0.08), rgba(167,139,250,0.08));
    border: 1px solid rgba(108,140,255,0.2);
    border-radius: 12px;
    margin: 0 auto;
    max-width: 340px;
    position: relative;
  }
  .network-box .nn-label { font-weight: 600; font-size: 0.9rem; }
  .network-box .nn-sub   { font-size: 0.72rem; color: var(--text-dim); }
  .network-box .param-badge {
    position: absolute;
    top: -10px; right: -10px;
    font-size: 0.65rem;
    font-weight: 600;
    background: var(--purple);
    color: #fff;
    padding: 3px 9px;
    border-radius: 12px;
  }
  .arrow-down {
    text-align: center;
    color: var(--text-dim);
    font-size: 1.4rem;
    margin: 4px 0;
    animation: bobDown 1.2s ease-in-out infinite;
  }
  @keyframes bobDown { 0%, 100% { transform: translateY(0); } 50% { transform: translateY(5px); } }

  /* context row (for loss slides) */
  .context-row {
    display: flex;
    align-items: center;
    gap: 6px;
    flex-wrap: wrap;
    margin: 14px 0 6px;
    font-family: 'JetBrains Mono', monospace;
    font-size: 1.05rem;
  }
  .ctx-tok {
    padding: 5px 12px;
    border-radius: 7px;
    border: 1px solid var(--accent);
    background: rgba(108,140,255,0.1);
  }
  .ctx-blank {
    padding: 5px 12px;
    border-radius: 7px;
    border: 2px dashed var(--orange);
    color: var(--orange);
    min-width: 60px;
    text-align: center;
    animation: pulseBorder 1.5s ease-in-out infinite;
  }
  @keyframes pulseBorder {
    0%, 100% { border-color: var(--orange); }
    50% { border-color: rgba(251,146,60,0.3); }
  }

  /* step label pill (for loss deep-dive slides) */
  .step-label {
    display: inline-block;
    font-size: 0.7rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    color: var(--yellow);
    background: rgba(250,204,21,0.1);
    padding: 3px 10px;
    border-radius: 20px;
    margin-bottom: 10px;
  }

  /* reasoning-emergence slides */
  .pressure-grid {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 12px;
    max-width: 780px;
    margin-top: 12px;
  }
  @media (max-width: 760px) {
    .pressure-grid { grid-template-columns: 1fr; }
  }
  .pressure-card {
    background: var(--surface2);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 14px;
    opacity: 0.28;
    transform: translateY(8px);
    transition: opacity 0.35s ease, transform 0.35s ease, border-color 0.35s ease;
  }
  .pressure-grid.revealed .pressure-card {
    opacity: 1;
    transform: translateY(0);
    border-color: rgba(108,140,255,0.35);
  }
  .pressure-card .title {
    font-size: 0.78rem;
    text-transform: uppercase;
    letter-spacing: 0.06em;
    color: var(--accent);
    margin-bottom: 6px;
    font-weight: 600;
  }
  .drama-script {
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.82rem;
    line-height: 1.75;
    background: var(--surface2);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 14px 16px;
  }
  .drama-choices {
    display: flex;
    gap: 10px;
    flex-wrap: wrap;
    margin-top: 10px;
  }
  .drama-choice.correct {
    background: rgba(74,222,128,0.16);
    border-color: rgba(74,222,128,0.4);
    color: var(--green);
  }
  .drama-choice.wrong {
    background: rgba(248,113,113,0.13);
    border-color: rgba(248,113,113,0.35);
    color: var(--red);
  }

  /* dataset-mix bars (for capability profile slide) */
  .mix-bar {
    display: flex;
    height: 12px;
    border-radius: 999px;
    overflow: hidden;
    border: 1px solid var(--border);
    background: var(--surface2);
    margin: 10px 0 8px;
  }
  .mix-seg.code { background: linear-gradient(90deg, rgba(167,139,250,0.95), rgba(108,140,255,0.95)); }
  .mix-seg.lit  { background: linear-gradient(90deg, rgba(34,211,238,0.95), rgba(74,222,128,0.95)); }

  .prompt-block {
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.76rem;
    line-height: 1.65;
    background: var(--surface2);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 12px 14px;
    white-space: pre-wrap;
  }

  /* ── Vertical pipeline ── */
  .pipeline-v {
    display: flex;
    flex-direction: column;
    gap: 0;
    max-width: 820px;
    position: relative;
  }
  .pipeline-v::before {
    content: '';
    position: absolute;
    left: 17px;
    top: 18px;
    bottom: 18px;
    width: 2px;
    background: linear-gradient(to bottom, var(--cyan), var(--accent), var(--orange), var(--green));
    opacity: 0.35;
  }
  .pv-step {
    display: flex;
    align-items: flex-start;
    gap: 16px;
    padding: 10px 0;
    position: relative;
  }
  .pv-dot {
    width: 36px;
    height: 36px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 0.75rem;
    font-weight: 700;
    flex-shrink: 0;
    z-index: 1;
    border: 2px solid;
  }
  .pv-dot.cyan   { border-color: var(--cyan);   color: var(--cyan);   background: rgba(34,211,238,0.1); }
  .pv-dot.accent { border-color: var(--accent); color: var(--accent); background: rgba(108,140,255,0.1); }
  .pv-dot.orange { border-color: var(--orange); color: var(--orange); background: rgba(251,146,60,0.1); }
  .pv-dot.purple { border-color: var(--purple); color: var(--purple); background: rgba(167,139,250,0.1); }
  .pv-dot.green  { border-color: var(--green);  color: var(--green);  background: rgba(74,222,128,0.1); }
  .pv-dot.red    { border-color: var(--red);    color: var(--red);    background: rgba(248,113,113,0.1); }
  .pv-body {
    flex: 1;
    min-width: 0;
    padding-top: 4px;
  }
  .pv-body h4 {
    font-size: 0.9rem;
    font-weight: 700;
    margin-bottom: 2px;
  }
  .pv-body .pv-detail {
    font-size: 0.78rem;
    color: var(--text-dim);
    line-height: 1.5;
  }
  .pv-body .pv-tag {
    display: inline-block;
    font-size: 0.65rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.06em;
    padding: 2px 8px;
    border-radius: 4px;
    margin-left: 8px;
    vertical-align: middle;
  }
  .pv-tag.data   { background: rgba(34,211,238,0.12); color: var(--cyan); }
  .pv-tag.train  { background: rgba(108,140,255,0.12); color: var(--accent); }
  .pv-tag.align  { background: rgba(251,146,60,0.12); color: var(--orange); }
  .pv-tag.eval   { background: rgba(74,222,128,0.12); color: var(--green); }
</style>
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['\\(', '\\)']],
      displayMath: [['\\[', '\\]']]
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>

<div class="slide-container" id="slideContainer">

<!-- ═══════ SLIDE 0 — TITLE ═══════ -->
<div class="slide centered" id="slide-0">
  <div class="badge day1">Day 1</div>
  <h1 class="large">Language Modeling<br>from Scratch</h1>
  <div class="spacer-sm"></div>
  <p class="subtitle">From data to behavior: the full language-modeling pipeline</p>
  <div class="spacer-lg"></div>
  <div class="gradient-line" style="width:200px;"></div>
</div>

<!-- ═══════ SLIDE 1 — OBJECTIVES ═══════ -->
<!-- ═══════ SLIDE 1 — OBJECTIVES ═══════ -->
<div class="slide" id="slide-1">
  <span class="section-tag">Day 1</span>
  <div class="badge day1">Today’s goal: leave with a clear internal map of how large language models actually work.</div>
  <h2>By the end, you should understand:</h2>
  <div class="spacer-sm"></div>
  <ul class="obj-list">
    <li data-num="1">What an LLM <span class="hl">computes at runtime</span> — tokens in, probability distribution out</li>
    <li data-num="2">How a simple objective like <span class="hl-green">next-token prediction</span> can create complex capabilities</li>
    <li data-num="3">What <span class="hl-purple">"training an LLM"</span> concretely means: <span class="hl-cyan">data</span> → <span class="hl">train</span> → <span class="hl-orange">align</span> → <span class="hl-green">eval</span></li>
    <li data-num="4">How <span class="hl-cyan">raw text becomes the data that shapes models</span> — collection, cleaning, deduplication, filtering, and annotation</li>
  </ul>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>These four objectives are what we want every participant to walk away with. They don't need to implement a transformer — just hold the correct mental model.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 2 — OPENING ═══════ -->
<div class="slide" id="slide-2">
  <span class="section-tag">Opening</span>
  <div class="badge concept">Live Demo</div>
  <h2>Let's watch an LLM complete a sentence</h2>
  <div class="spacer-sm"></div>
  <div class="spacer"></div>
  <div class="card" style="text-align:center; max-width:100%; margin:0 auto;">
    <p class="small-text" style="margin-bottom:14px; color:var(--text-dim);">LLM Forward Pass Animation</p>
    <div class="live-demo-shell" id="liveDemoHost"
      data-video-relative="LanguageModelingPipeline.mp4"
      data-video-path="/home/maincoder/Documents/inside-LLM/manimations/media/videos/pipeline/1080p60/LanguageModelingPipeline.mp4">
      <div class="live-demo-placeholder">
        <button class="nav-btn primary" id="loadLiveDemoBtn" style="min-width:180px;">Load Demo Video</button>
        <p class="tiny">Large file is lazy-loaded only when this slide is opened.</p>
      </div>
    </div>
    <p class="tiny forward-pass-caption">Black box → Functional stages → Computational mechanisms</p>
  </div>
  <div class="spacer"></div>
  <div class="callout info">
    <span class="icon">i</span>
    <span><em>"Over two days, we'll reduce LLMs to a small set of operations: tokens become vectors, vectors undergo repeated structured transforms, and we end with a probability distribution over the next token. By the end you'll be able to trace a forward pass end-to-end, understand what each matrix multiplication is doing, and connect those mechanics to the model's behavior — both its strengths and its failure modes."</em></span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Play the pipeline animation video here. Let it run fully. Then use the framing quote to set the tone for the two-day workshop.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 3 — THREE INGREDIENTS ═══════ -->
<div class="slide" id="slide-3">
  <span class="section-tag">The Big Picture</span>
  <div class="badge discussion">Quick Check-in</div>
  <h2>What makes an LLM work</h2>
  <div class="spacer-sm"></div>

  <div class="grid-3" id="ingredientsGrid">
    <!-- INGREDIENT 1 -->
    <div class="card" style="text-align:center;" id="ingredient1Card">
      <div style="font-size:2.2rem; margin-bottom:8px;">1</div>
      <div id="ingredient1Hidden">
        <h3 style="color:var(--cyan);">???</h3>
        <p class="small-text" style="color:var(--text-dim);">Click to reveal</p>
        <button class="reveal-btn" onclick="revealIngredient(1)" style="margin-top:12px;">Reveal</button>
      </div>
      <div id="ingredient1Revealed" style="display:none;">
        <h3 style="color:var(--cyan);">Data</h3>
        <p class="small-text">
          corpus · scale · quality
        </p>
      </div>
    </div>

    <!-- INGREDIENT 2 -->
    <div class="card" style="text-align:center;" id="ingredient2Card">
      <div style="font-size:2.2rem; margin-bottom:8px;">2</div>
      <div id="ingredient2Hidden">
        <h3 style="color:var(--accent);">???</h3>
        <p class="small-text" style="color:var(--text-dim);">Click to reveal</p>
        <button class="reveal-btn" onclick="revealIngredient(2)" style="margin-top:12px;">Reveal</button>
      </div>
      <div id="ingredient2Revealed" style="display:none;">
        <h3 style="color:var(--accent);">Architecture</h3>
        <p class="small-text">
          structure · information flow · parameters
        </p>
      </div>
    </div>

    <!-- INGREDIENT 3 -->
    <div class="card" style="text-align:center;" id="ingredient3Card">
      <div style="font-size:2.2rem; margin-bottom:8px;">3</div>
      <div id="ingredient3Hidden">
        <h3 style="color:var(--purple);">???</h3>
        <p class="small-text" style="color:var(--text-dim);">Click to reveal</p>
        <button class="reveal-btn" onclick="revealIngredient(3)" style="margin-top:12px;">Reveal</button>
      </div>
      <div id="ingredient3Revealed" style="display:none;">
        <h3 style="color:var(--purple);">Learning Dynamics</h3>
        <p class="small-text">
          objective · feedback · compute
        </p>
      </div>
    </div>
  </div>

  <!-- DATA EXPLANATION -->
  <div class="hidden-content" id="ingredientExplanation1">
    <div class="callout info">
      <span class="icon">i</span>
      <span>
        <strong>Data</strong> is three things:
        (1) the <span class="hl-cyan">raw corpus</span> — books, web pages, code, and conversations,
        (2) the <span class="hl-yellow">scale</span> — trillions of tokens, because statistical patterns only emerge with massive coverage, and
        (3) the <span class="hl-orange">quality</span> — filtering, deduplication, and curation that determine what the model actually learns.
      </span>
    </div>
  </div>

  <!-- ARCHITECTURE EXPLANATION -->
  <div class="hidden-content" id="ingredientExplanation2">
    <div class="callout info">
      <span class="icon">i</span>
      <span>
        <strong>Architecture</strong> is three things:
        (1) the <span class="hl-cyan">Transformer</span> — a neural network built around self-attention,
        (2) the <span class="hl-yellow">information flow</span> — attention mixes information across tokens, while residual connections preserve and accumulate it across layers, and
        (3) the <span class="hl-orange">parameter space</span> — billions of tunable weights that store a compressed statistical model of language.
      </span>
    </div>
  </div>

  <!-- LEARNING EXPLANATION -->
  <div class="hidden-content" id="ingredientExplanation3">
    <div class="callout info">
      <span class="icon">i</span>
      <span>
        <strong>Learning</strong> here means three things:
        (1) the <span class="hl-yellow">training objective</span> — next-token prediction via cross-entropy loss,
        (2) the <span class="hl-orange">optimization process</span> — the feedback loop that turns prediction error into parameter updates, and
        (3) <span class="hl-purple">computation at scale</span> — thousands of GPUs running for weeks.
      </span>
    </div>
  </div>

  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body">
      <p>
        Ask: “When people say data, architecture, or learning — what do they actually mean?”
        Reveal each ingredient, then pause on its decomposition before moving on.
      </p>
    </div>
  </div>
</div>

<!-- ═══════ SLIDE 4 — WORKSHOP ROADMAP ═══════ -->
<div class="slide" id="slide-4">
  <span class="section-tag">Roadmap</span>
  <div class="badge day1">Causality</div>
  <h2>Workshop roadmap</h2>
  <div class="spacer-sm"></div>

  <div class="grid-2">
    <!-- DAY 1 -->
    <div class="card" style="border-color: rgba(108,140,255,0.3);">
      <div class="badge day1">Day 1 — Today</div>
      <h3 style="color:var(--accent);">Why LLMs behave the way they do</h3>
      <ul style="list-style:none; margin-top:10px;">
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--accent);">→</span>
          Inference vs. training
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--accent);">→</span>
          Next-token prediction objective
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--accent);">→</span>
          Loss → gradients → parameter updates
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--accent);">→</span>
          Why next-token prediction works
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--accent);">→</span>
          From one update to a full training pipeline
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--accent);">→</span>
          Data work: collection → filtering → annotation
        </li>
      </ul>
      <div class="callout info" style="margin-top:14px;">
        <span class="icon">i</span>
        <span>Treat the model as a <strong>system being shaped.</strong></span>
      </div>
    </div>

    <!-- DAY 2 -->
    <div class="card" style="border-color: rgba(167,139,250,0.25); opacity:0.6;">
      <div class="badge concept">Day 2 — Tomorrow</div>
      <h3 style="color:var(--purple);">How a Transformer processes text and computes the next word</h3>
      <ul style="list-style:none; margin-top:10px;">
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--purple);">→</span>
          Tokenization & embeddings
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--purple);">→</span>
          Self-attention mechanics
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--purple);">→</span>
          Feed-forward layers
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--purple);">→</span>
          Full forward pass end-to-end
        </li>
        <li class="small-text" style="padding:5px 0 5px 20px; position:relative;">
          <span style="position:absolute;left:0;color:var(--purple);">→</span>
          Connecting mechanics to behavior
        </li>
      </ul>
      <div class="callout info" style="margin-top:14px;">
        <span class="icon">i</span>
        <span>Treat it as a <strong>machine executing computation.</strong></span>
      </div>
    </div>
  </div>

  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">
      speaker notes
    </button>
    <div class="notes-body">
      <p>
        “You’ve already seen inference: context goes in, a next-token distribution comes out.
        But that behavior only exists because of how the weights were trained.
        Today is the causal story. Tomorrow we zoom all the way into the computation.”
      </p>
    </div>
  </div>
</div>


<!-- ═══════ SLIDE 5 — INFERENCE LOOP ═══════ -->
<div class="slide" id="slide-5">
  <span class="section-tag">Inference vs Training</span>
  <div class="badge concept">Concept</div>
  <h2>The inference (use-time) loop</h2>

  <p class="small-text" style="max-width:600px;">
    At use time, the model runs a fixed computation.
    The input text is tokenized once. After that, the model repeatedly predicts the next token,
    which is decoded for display and appended to the context.
  </p>

  <div class="spacer"></div>

  <div class="card" style="max-width:900px; margin: 0 auto;">

    <!-- ONE-TIME SETUP -->
    <div class="flow" style="margin-bottom:10px;">
      <div class="flow-box data">Text<br>input</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box blue">Tokenize<br><span class="tiny">(one-time)</span></div>
      <div class="flow-arrow">→</div>
      <div class="flow-box data">Context<br>tokens</div>
    </div>

    <!-- REPEATED LOOP -->
    <div class="flow">
      <div class="flow-box data">Context<br>tokens</div>
      <div class="flow-arrow loop-arrow-anim">→</div>

      <div class="flow-box model">
        Transformer Blocks<br><span class="tiny">(fixed)</span>
      </div>
      <div class="flow-arrow loop-arrow-anim">→</div>

      <div class="flow-box yellow">
        Logits<br><span class="tiny">(scores for each token)</span>
      </div>
      <div class="flow-arrow loop-arrow-anim">→</div>

      <div class="flow-box pink">Softmax</div>
      <div class="flow-arrow loop-arrow-anim">→</div>

      <div class="flow-box green">Sample<br>next token</div>
      <div class="flow-arrow loop-arrow-anim">→</div>

      <div class="flow-box purple">
        Decode<br><span class="tiny">(token → text)</span>
      </div>
    </div>

    <div style="text-align:center; margin-top:8px;">
      <span class="tiny" style="color:var(--orange);">
        ↻ append token to context and repeat
      </span>
    </div>
  </div>

  <div class="spacer"></div>

  <div class="token-row" id="inferenceDemo">
    <span class="tok input">The</span>
    <span class="tok input">capital</span>
    <span class="tok input">of</span>
    <span class="tok input">Pakistan</span>
    <span class="tok input">is</span>
    <span class="tok blank" id="infCurrent" onclick="animateInference()">click</span>
  </div>

  <p class="tiny" id="infHint">
    Click the blank to simulate one inference step
  </p>

  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">
      speaker notes
    </button>
    <div class="notes-body">
      <p>
        “The model never produces words directly — it produces token IDs.
        Decoding just turns those IDs into readable text.
        The loop itself runs entirely at the token level.”
      </p>
    </div>
  </div>
</div>




<!-- ═══════ SLIDE 6 — TRAINING LOOP ═══════ -->
<div class="slide" id="slide-6">
  <span class="section-tag">Inference vs Training</span>
  <div class="badge concept">Concept</div>
  <h2>The training (learning) loop</h2>

  <p class="small-text" style="max-width:680px;">
    Training uses the <strong>same forward pass</strong> as inference — but adds a teacher.
    The error flows <em>backward</em> through the network, reshaping it one batch at a time.
  </p>

  <div class="spacer-sm"></div>

  <!-- Step controls -->
  <div style="display:flex; gap:6px; justify-content:center; flex-wrap:wrap; margin-bottom:14px;">
    <button class="reveal-btn" onclick="trainStep(1)" id="trainBtn1">1 · Forward</button>
    <button class="reveal-btn" onclick="trainStep(2)" id="trainBtn2">2 · Teacher</button>
    <button class="reveal-btn" onclick="trainStep(3)" id="trainBtn3">3 · Loss</button>
    <button class="reveal-btn" onclick="trainStep(4)" id="trainBtn4">4 · Backprop</button>
    <button class="reveal-btn" onclick="trainStep(5)" id="trainBtn5">5 · Update</button>
  </div>

  <div class="card" style="max-width:960px; margin:0 auto; overflow:visible; position:relative;">

    <!-- ── PHASE 1: FORWARD PASS (same as inference) ── -->
    <div class="flow" id="trainFwd" style="opacity:0.25; transition:opacity 0.4s;">
      <div class="flow-box data">Context<br>tokens</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box model" id="trainTransformer">Transformer<br>Blocks<br><span class="tiny">(weights θ)</span></div>
      <div class="flow-arrow">→</div>
      <div class="flow-box yellow">Logits<br><span class="tiny">(raw scores)</span></div>
      <div class="flow-arrow">→</div>
      <div class="flow-box pink">Softmax</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box green">Predicted<br>next token</div>
    </div>

    <!-- ── PHASE 2: GROUND TRUTH COMPARISON ── -->
    <div id="trainCompare" style="display:none;">
      <div style="display:flex; align-items:center; justify-content:center; gap:16px; margin:10px 0 4px;">
        <div class="flow-box green" style="opacity:0.65; min-width:90px;">Predicted<br><span class="tiny">P(token)</span></div>
        <span style="font-size:1.6rem; color:var(--red); font-weight:700;">&#x2260;</span>
        <div class="flow-box target" style="min-width:90px;">Actual<br><span class="tiny">(from data)</span></div>
      </div>
      <p class="tiny" style="text-align:center; color:var(--text-dim); margin:0;">
        teacher forcing — the correct next token is always known during training
      </p>
    </div>

    <!-- ── PHASE 3: LOSS COMPUTATION ── -->
    <div id="trainLoss" style="display:none; text-align:center; margin:8px 0;">
      <div style="color:var(--text-dim); font-size:1.1rem;">&#x2193;</div>
      <div class="flow-box loss" style="display:inline-block;">
        Cross-Entropy Loss<br>
        <span class="tiny">L = &minus;log P(correct token)</span>
      </div>
      <p class="tiny" style="color:var(--red); margin:4px 0 0;">
        "How surprised was the model by the right answer?"
      </p>
    </div>

    <!-- ── PHASE 4: BACKPROPAGATION ── -->
    <div id="trainBackprop" style="display:none; margin-top:8px;">
      <p class="tiny" style="text-align:center; color:var(--orange); margin:0 0 6px;">
        &#x2193; error signal flows backward through every layer (chain rule)
      </p>
      <div class="flow flow-backward">
        <div class="flow-box param">&#x2202;L/&#x2202;&#x03B8;<br><span class="tiny">gradient for<br>every weight</span></div>
        <div class="flow-arrow">&larr;</div>
        <div class="flow-box grad">Backpropagate<br><span class="tiny">layer N &rarr; N&minus;1<br>&rarr; &hellip; &rarr; layer 1</span></div>
        <div class="flow-arrow">&larr;</div>
        <div class="flow-box loss">L<br><span class="tiny">error at<br>output</span></div>
      </div>
    </div>

    <!-- ── PHASE 5: WEIGHT UPDATE + FEEDBACK LOOP ── -->
    <div id="trainUpdate" style="display:none; text-align:center; margin-top:8px;">
      <div style="color:var(--text-dim); font-size:1.1rem;">&#x2193;</div>
      <div class="flow-box param" style="display:inline-block; border-width:2px;">
        &#x03B8; &larr; &#x03B8; &minus; &#x03B7; &middot; &#x2207;L<br>
        <span class="tiny">nudge every weight to reduce the loss</span>
      </div>
      <div style="margin-top:12px;">
        <span style="color:var(--orange); font-size:1rem;">
          &#x21BB; updated weights feed back into the Transformer — repeat with next batch
        </span>
      </div>
    </div>

  </div>

  <!-- Step explanation callout -->
  <div id="trainExplain" class="callout info" style="max-width:750px; margin:10px auto 0; display:none;">
    <span class="icon">i</span>
    <span id="trainExplainText"></span>
  </div>

  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">
      speaker notes
    </button>
    <div class="notes-body">
      <p>
        Walk through each step. Emphasize: "The forward pass is identical to inference.
        Training only adds the teacher signal and backward pass.
        Backpropagation is just the chain rule applied mechanically —
        for each weight, how much did it contribute to the error?
        Then nudge it to contribute less."
      </p>
    </div>
  </div>
</div>


<!-- ═══════ SLIDE 7 — TRAINING OBJECTIVE ═══════ -->
<div class="slide" id="slide-7">
  <span class="section-tag">Training</span>
  <div class="badge concept">Core Concept</div>
  <h2>The training objective</h2>

  <p class="small-text" style="max-width:760px;">
    Objective: make the model assign high probability to the training text.
    With a causal language model, this factorizes into next-token prediction at every position.
  </p>

  <div class="spacer-sm"></div>

  <div class="card" style="max-width:860px;">
    <p class="small-text" style="margin-bottom:10px;">
      Given a token sequence <span class="hl">\(x_1, x_2, \ldots, x_T\)</span>, training uses <span class="hl-yellow">teacher forcing</span>:
    </p>

    <div class="grid-2" style="gap:14px;">
      <div>
        <p class="tiny" style="margin:0 0 6px 0; color:var(--text-dim);">Inputs (prefixes)</p>
        <div class="token-row" style="font-size:0.95rem;">
          <span class="tok input">\(x_1\)</span>
          <span class="tok input">\(x_2\)</span>
          <span class="tok input" style="color:var(--text-dim);">\(\ldots\)</span>
          <span class="tok input">\(x_{T-1}\)</span>
        </div>
      </div>

      <div>
        <p class="tiny" style="margin:0 0 6px 0; color:var(--text-dim);">Targets (next tokens)</p>
        <div class="token-row" style="font-size:0.95rem;">
          <span class="tok target">\(x_2\)</span>
          <span class="tok target">\(x_3\)</span>
          <span class="tok target" style="color:var(--text-dim);">\(\ldots\)</span>
          <span class="tok target">\(x_T\)</span>
        </div>
      </div>
    </div>

    <p class="tiny" style="margin-top:10px;">
      At each position \(t\), the model outputs a distribution \(P_{\theta}(\,\cdot \mid x_{\le t})\) and is scored on the true next token \(x_{t+1}\).
    </p>
  </div>

  <div class="spacer-sm"></div>

  <div class="callout info">
    <span class="icon">→</span>
    <span>
      <strong>Objective (maximize likelihood):</strong>
      maximize the average log-probability the model assigns to the true next token.
    </span>
  </div>

  <div class="math math-big">
    \[
      \max_{\theta}\;\; \frac{1}{T-1}\sum_{t=1}^{T-1}\log P_{\theta}(x_{t+1}\mid x_{\le t})
    \]
  </div>

  <div class="callout warn">
    <span class="icon">!</span>
    <span>
      <strong>Equivalent form (minimize loss):</strong>
      minimizing negative log-likelihood is the same objective, written as a loss function (cross-entropy).
    </span>
  </div>

  <div class="math math-big">
    \[
      \mathcal{L}(\theta)
      = -\frac{1}{T-1}\sum_{t=1}^{T-1}\log P_{\theta}(x_{t+1}\mid x_{\le t})
    \]
  </div>

  <p class="tiny" style="text-align:center;">
    Lower loss means the model assigns higher probability to the tokens that actually occurred in the dataset
  </p>

  <div class="spacer"></div>

  <div class="callout warn">
    <span class="icon">!</span>
    <span>
      <strong>Key insight:</strong> this is <span class="hl-orange">distribution matching</span>, not decision-making:
      it reshapes probabilities to fit observed text, without any explicit notion of truth or goals.
    </span>
  </div>

  <div class="spacer-sm"></div>

  <div class="callout info">
    <span class="icon">→</span>
    <span>
      <strong>Next:</strong> one training iteration end-to-end: forward → loss → backward → update.
    </span>
  </div>

  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body">
      <p>
        “State the objective first: maximize likelihood of the training text under the model. Then show the equivalent loss: negative log-likelihood (cross-entropy).
        Emphasize the shift: inputs are prefixes, targets are the next tokens.”
      </p>
    </div>
  </div>
</div>


<!-- ═══════ SLIDE 8 — WHAT'S NOT IN THE LOSS ═══════ -->
<div class="slide" id="slide-8">
  <span class="section-tag">Pretraining</span>
  <div class="badge concept">Critical Point</div>
  <h2>What the loss does <em>not</em> contain</h2>
  <p class="small-text" style="max-width:700px;">After tracing one full iteration, notice what supervision signal the model actually receives. Training has no explicit term for any of these; if they emerge, they must be <em>instrumentally useful for predicting text</em>.</p>
  <div class="spacer"></div>
  <div class="not-list">
    <div class="not-item">Truth</div>
    <div class="not-item">Reasoning</div>
    <div class="not-item">Helpfulness</div>
    <div class="not-item">Safety</div>
    <div class="not-item">Intelligence</div>
    <div class="not-item">Goals</div>
    <div class="not-item">World model</div>
    <div class="not-item">Consistency</div>
  </div>
  <div class="spacer-sm"></div>
  <div class="math">
    \[\mathcal{L} = -\log P_{\theta}(x_t \mid x_{\lt t})\] <span style="color:var(--text-dim); font-size:0.82rem;"> that's the ENTIRE signal</span>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success">
    <span class="icon">i</span>
    <span><strong>The narrow bottleneck:</strong> Everything the model learns has to pass through this single constraint — lowering next-token prediction error. This explains both <span class="hl-green">emergence</span> and <span class="hl-red">brittleness</span>.</span>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout question">
    <span class="icon">?</span>
    <span><strong>Think about it:</strong> Why would a model learn facts, reasoning, or code from only this signal? Next we'll zoom back out from one step to the full repeated training loop.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"There are no terms here for truth, reasoning, helpfulness, safety, goals, or intelligence. Everything the model learns has to pass through this very narrow bottleneck — lowering next-token prediction error."</p></div>
  </div>
</div>

<!-- ═══════════════════════════════════════════════════ -->
<!--  SLIDES 9–14 : NEXT-TOKEN LOSS DEEP DIVE          -->
<!--  (embedded from next-token-loss.html)              -->
<!-- ═══════════════════════════════════════════════════ -->

<!-- ═══════ SLIDE 9 — THE TASK ═══════ -->
<div class="slide" id="slide-9">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 1 — The Task</div>
  <h2>Predict the next token</h2>
  <p class="small-text" style="max-width:700px;">Let's jump in and take a deeper dive into one training iteration. We'll trace one concrete example from input context to parameter update.</p>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:700px;">
    <div class="context-row">
      <span class="ctx-tok">"The</span>
      <span class="ctx-tok">capital</span>
      <span class="ctx-tok">of</span>
      <span class="ctx-tok">Pakistan</span>
      <span class="ctx-tok">is</span>
      <span class="ctx-blank">???</span>
    </div>
    <div class="spacer-sm"></div>
    <div class="callout info" style="margin:0;">
      <span class="icon">i</span>
      <span>The model receives <span class="hl">input context tokens</span> and must produce a probability for <em>every word in its vocabulary</em> as the next token. The training data already contains the answer — we just hide it and ask the model to guess.</span>
    </div>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Set up the concrete example. This is one single training step — we'll trace it all the way through loss computation to parameter update.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 10 — FORWARD PASS ═══════ -->
<div class="slide" id="slide-10">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 2 — Forward Pass</div>
  <h2>The model outputs a probability distribution</h2>
  <p class="small-text" style="max-width:660px;">The input tokens flow through billions of parameters — attention layers, feed-forward networks — and out comes a <span class="hl">probability distribution over the entire vocabulary</span>.</p>

  <div class="spacer-sm"></div>
  <div style="max-width:700px;">
    <div class="context-row" style="justify-content:center;">
      <span class="ctx-tok">"The</span>
      <span class="ctx-tok">capital</span>
      <span class="ctx-tok">of</span>
      <span class="ctx-tok">Pakistan</span>
      <span class="ctx-tok">is</span>
    </div>
    <div class="arrow-down">↓</div>
    <div class="network-box">
      <div>
        <div class="nn-label">Transformer</div>
        <div class="nn-sub">attention + FFN layers</div>
      </div>
      <span class="param-badge">\(\sim 7 \times 10^9\) params</span>
    </div>
    <div class="arrow-down">↓</div>
    <div class="chart-title" style="color:var(--text-dim); margin-top:8px;">Model's predicted distribution (softmax output)</div>
    <div id="predictedChart"></div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout info" style="max-width:700px;">
    <span class="icon">i</span>
    <span>The final layer outputs a <span class="hl">logit</span> for each vocabulary token, then <span class="hl">softmax</span> converts these to probabilities satisfying \(\sum_i p_i = 1\). An untrained model spreads probability almost evenly — basically guessing randomly.</span>
  </div>
</div>

<!-- ═══════ SLIDE 11 — TARGET DISTRIBUTION ═══════ -->
<div class="slide" id="slide-11">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 3 — The Target</div>
  <h2>What the model <em>should</em> have predicted</h2>
  <p class="small-text" style="max-width:640px;">We know the correct next token from the training data. The <span class="hl-green">target distribution</span> puts \(100\%\) probability on the correct answer.</p>
  <div class="spacer-sm"></div>
  <div class="dual-charts" style="max-width:720px;">
    <div class="chart-col">
      <div class="chart-title" style="color:var(--accent);">Model's prediction</div>
      <div id="dualPredicted"></div>
    </div>
    <div class="chart-col">
      <div class="chart-title" style="color:var(--green);">Target (ground truth)</div>
      <div id="dualTarget"></div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout warn" style="max-width:720px;">
    <span class="icon">!</span>
    <span>The model only gave <span class="hl" id="correctPctText">\(8\%\)</span> to <span class="hl-green">"Islamabad"</span>, but the target says it should be <span class="hl-green">\(100\%\)</span>. That gap is what the <span class="hl-red">loss function</span> measures.</span>
  </div>
</div>

<!-- ═══════ SLIDE 12 — LOSS COMPUTATION ═══════ -->
<div class="slide" id="slide-12">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 4 — Compute the Loss</div>
  <h2>Cross-entropy loss: how wrong is the model?</h2>
  <p class="small-text" style="max-width:680px;">The loss measures the gap between prediction and target. For next-token prediction, we use <span class="hl-yellow">cross-entropy loss</span>.</p>
  <div class="spacer-sm"></div>
  <div class="math math-big" style="max-width:700px;" id="lossFormula">
    \[\mathcal{L} = -\log(P_{\text{model}}(\text{Islamabad})) = -\log(0.08) = 2.53\]
  </div>
  <div class="loss-display">
    <div class="loss-box">
      <div class="label">\(P(\text{Islamabad})\)</div>
      <div class="value high" id="lossProbDisplay">\(0.08\)</div>
    </div>
    <div class="comparison-arrow">→</div>
    <div class="loss-box">
      <div class="label">\(\mathcal{L}\)</div>
      <div class="value high" id="lossValueDisplay">\(2.53\)</div>
      <div class="formula">\(\mathcal{L} = -\log(p)\)</div>
    </div>
  </div>
  <div style="max-width:400px; margin:0 auto;">
    <div style="display:flex; justify-content:space-between; gap: 24px; font-size:0.72rem; color:var(--text-dim); margin-bottom:2px;">
      <span class="hl-green">low loss (good)</span>
      <span class="hl-red">high loss (bad)</span>
    </div>
    <div class="loss-meter">
      <div class="loss-meter-fill" id="lossMeter" style="width:0%; background: linear-gradient(90deg, var(--green), var(--yellow), var(--red));"></div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout info" style="max-width:700px;">
    <span class="icon">i</span>
    <span><span class="hl-yellow">Intuition:</span> if the model gave \(100\%\) to "Islamabad", \(\mathcal{L} = -\log(1) =\) <span class="hl-green">\(0\)</span> (perfect). If only \(1\%\), \(\mathcal{L} = -\log(0.01) \approx\) <span class="hl-red">\(4.6\)</span> (terrible). The loss captures "how surprised the model is by the right answer."</span>
  </div>
</div>

<!-- ═══════ SLIDE 13 — BACKPROPAGATION ═══════ -->
<div class="slide" id="slide-13">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 5 — Backpropagation</div>
  <h2>Compute gradients and update parameters</h2>
  <p class="small-text" style="max-width:680px;">The loss signal flows <em>backwards</em> through the network. For each parameter, we compute: "how much would changing this parameter reduce the loss?" Then we nudge every parameter in that direction.</p>
  <div class="spacer-sm"></div>
  <div class="update-flow">
    <div class="flow-node loss-node">\(\mathcal{L} = 2.53\)</div>
    <div class="flow-arrow">→</div>
    <div class="flow-node grad-node">\(\frac{\partial \mathcal{L}}{\partial \theta}\)<br><small>compute gradients</small></div>
    <div class="flow-arrow">→</div>
    <div class="flow-node param-node">\(\theta \leftarrow \theta - \eta \nabla \mathcal{L}\)<br><small>update params</small></div>
  </div>
  <div class="backprop-arrows">
    <span>◂</span><span>◂</span><span>◂</span><span>◂</span>
    <span style="font-size:0.8rem; color:var(--text-dim); animation:none; margin-left:4px;">gradients flow backward</span>
  </div>
  <div class="math" style="max-width:500px; margin:10px auto;">
    \[\theta_{\text{new}} = \theta_{\text{old}} - \eta \frac{\partial \mathcal{L}}{\partial \theta}\]
  </div>
  <div class="callout info" style="max-width:700px;">
    <span class="icon">i</span>
    <span><span class="hl-purple">\(\eta\) (eta)</span> is the <strong>learning rate</strong> — a small number (e.g., \(10^{-4}\)) that controls step size. The <span class="hl-orange">gradient \(\frac{\partial \mathcal{L}}{\partial \theta}\)</span> tells us the direction and magnitude of adjustment needed for each of the billions of parameters.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"This is the part that actually makes learning happen. The gradient is a vector pointing in the direction of steepest increase of the loss — so we go the opposite direction to decrease it."</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 14 — AFTER UPDATE ═══════ -->
<div class="slide" id="slide-14">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 6 — After Update</div>
  <h2>The model improves!</h2>
  <p class="small-text" style="max-width:700px;">That completes one training iteration: after the update, the model assigns <em>more</em> probability to the correct token. Repeating this loop at scale is how the model learns language.</p>
  <div class="spacer-sm"></div>
  <div class="before-after" style="max-width:720px;">
    <div class="ba-col before">
      <div class="ba-label">Before update</div>
      <div id="beforeBars"></div>
    </div>
    <div class="ba-arrow">→</div>
    <div class="ba-col after">
      <div class="ba-label">After update</div>
      <div id="afterBars"></div>
    </div>
  </div>
  <div class="loss-display">
    <div class="loss-box">
      <div class="label">Loss before</div>
      <div class="value high">\(2.53\)</div>
    </div>
    <div class="comparison-arrow">→</div>
    <div class="loss-box">
      <div class="label">Loss after</div>
      <div class="value low" id="lossAfterVal">\(1.27\)</div>
    </div>
  </div>
  <div class="callout success" style="max-width:720px;">
    <span class="icon">✓</span>
    <span>The model now assigns <span class="hl-green" id="afterCorrectPct">\(28\%\)</span> to "Islamabad" (up from <span class="hl-red">\(8\%\)</span>). The loss dropped from <span class="hl-red">\(2.53\)</span> to <span class="hl-green" id="afterLossText">\(1.27\)</span>. After many more steps, the model will learn to confidently predict "Islamabad" — and generalize to countless other facts.</span>
  </div>
</div>

<!-- ═══════ SLIDE 22 — LOCAL OBJECTIVE, GLOBAL PRESSURE ═══════ -->
<div class="slide" id="slide-22">
  <span class="section-tag">Reasoning Emergence</span>
  <div class="badge concept">Key Idea</div>
  <h2>Why next-token prediction can produce reasoning-like behavior</h2>
  <p class="small-text" style="max-width:760px;"><strong>Local objective, global pressure:</strong> the training signal is local (predict one token), but minimizing that error often requires building global structure over the context.</p>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:780px;">
    <div class="math" style="margin:0;">
      \[\text{Objective: } \max_{\theta} \; P_{\theta}(x_t \mid x_{\lt t}) \text{ for each token position}\]
    </div>
    <div class="spacer-sm"></div>
    <button class="reveal-btn" onclick="revealReasoningPressure()">Reveal what the model often must infer</button>
    <div class="pressure-grid" id="reasoningPressureGrid">
      <div class="pressure-card">
        <div class="title">Entities</div>
        <p class="small-text">Who or what is being discussed, and how references resolve across sentences.</p>
      </div>
      <div class="pressure-card">
        <div class="title">Causal Cues</div>
        <p class="small-text">What caused what, and which events enable or block later outcomes.</p>
      </div>
      <div class="pressure-card">
        <div class="title">Constraints</div>
        <p class="small-text">What is consistent or impossible given timing, access, and prior facts.</p>
      </div>
      <div class="pressure-card">
        <div class="title">Multi-step Structure</div>
        <p class="small-text">What comes next in a plan, argument, proof, or narrative arc.</p>
      </div>
    </div>
  </div>
  <div class="hidden-content" id="reasoningEmergenceQuote">
    <div class="callout success" style="max-width:780px;">
      <span class="icon">i</span>
      <span><strong>So "reasoning" can emerge as an instrumentally useful strategy for reducing prediction error,</strong> even when it is never explicitly specified as a training target.</span>
    </div>
  </div>
</div>

<!-- ═══════ SLIDE 23 — PAKISTANI DRAMA EXAMPLE ═══════ -->
<div class="slide" id="slide-23">
  <span class="section-tag">Reasoning Emergence</span>
  <div class="badge discussion">Interactive Example</div>
  <h2>Next-token prediction in a Pakistani drama</h2>
  <p class="small-text" style="max-width:780px;">Nothing explicitly states the answer. To predict the next words, the model must integrate distributed constraints.</p>
  <div class="spacer-sm"></div>
  <div class="drama-script" style="max-width:800px;">
    Karachi mein aik shaam...<br>
    10:30 baje Shahbaz Ahmed apne office mein be-harkat mila...<br>
    thori dair baad pata chala ke maut ki wajah zehr tha...<br>
    Us waqt office mein sirf teen log thay...<br>
    Farah, jo us ki secretary thi...<br>
    Salman, jo us ka business partner tha...<br>
    aur Rukhsana, jo safai karti thi...<br>
    Farah 9:50 baje office se nikal chuki thi...<br>
    Salman 10:00 baje meeting ke liye bahar gaya...<br>
    10:20 baje Rukhsana ne Shahbaz ke liye chai banayi...<br>
    Forensic report ke mutabiq zehr 10:20 aur 10:30 ke darmiyan liya gaya...<br>
    CCTV se yeh bhi clear hua ke 10:00 ke baad sirf aik shakhs pantry mein gaya...<br>
    ...<br>
    Investigation ke baad shahbaz ki family ne police walon se pucha keh qatil kon tha.<br>
    Police ne btaya keh tamaam subuton ke mutabik qatil <span class="ntp-blank" id="dramaKillerBlank" data-answer="Rukhsana thi">___</span>
  </div>
  <div class="drama-choices" id="dramaChoices">
    <button class="nav-btn drama-choice" onclick="chooseDramaSuspect('Farah', this)">Farah</button>
    <button class="nav-btn drama-choice" onclick="chooseDramaSuspect('Salman', this)">Salman</button>
    <button class="nav-btn drama-choice" onclick="chooseDramaSuspect('Rukhsana', this)">Rukhsana</button>
    <button class="nav-btn" onclick="revealDramaAnswer()">Reveal token</button>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout warn" id="dramaResult" style="max-width:800px;">
    <span class="icon">?</span>
    <span>Select a suspect. Then check whether your choice satisfies the timing + access constraints.</span>
  </div>
  <div class="hidden-content" id="dramaWhy">
    <div class="callout info" style="max-width:800px;">
      <span class="icon">i</span>
      <span><strong>Notice:</strong> no line explicitly says "Rukhsana qatil hai." The required information is distributed across the text. Correct next-token prediction requires integrating entity tracking, timing, access, and consistency constraints introduced earlier.</span>
    </div>
    <div class="callout success" style="max-width:800px; margin-top:10px;">
      <span class="icon">→</span>
      <span><strong>That pressure is exactly what next-token prediction creates during training.</strong></span>
    </div>
  </div>
</div>

<!-- ═══════ SLIDE 24 — LOCAL OBJECTIVE TO GLOBAL STRUCTURE ═══════ -->
<div class="slide" id="slide-24">
  <span class="section-tag">Reasoning Emergence</span>
  <div class="badge concept">Synthesis</div>
  <h2>Why a local objective creates global structure</h2>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:820px;">
    <div class="card">
      <h3 style="color:var(--accent);">Local objective</h3>
      <div class="math" style="margin:8px 0 0;">
        \[\hat{x}_t = \arg\max_{x_t} P_{\theta}(x_t \mid x_{\lt t})\]
      </div>
      <p class="tiny" style="margin-top:8px;">The training signal never says "identify the killer" or "reason explicitly."</p>
    </div>
    <div class="card">
      <h3 style="color:var(--green);">To do that reliably, infer:</h3>
      <ul class="obj-list" style="margin-top:8px;">
        <li data-num="1">entities (who is who)</li>
        <li data-num="2">state (who was where, and when)</li>
        <li data-num="3">causality (what enables what)</li>
        <li data-num="4">constraints (what is impossible)</li>
        <li data-num="5">narrative consistency</li>
      </ul>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success" style="max-width:820px;">
    <span class="icon">✓</span>
    <span><strong>Result:</strong> reasoning-like behavior emerges as a <em>means</em>, not a goal.</span>
  </div>
  <div class="callout info" style="max-width:820px;">
    <span class="icon">i</span>
    <span>In narratives, plans, arguments, and code, accurate next-token prediction often demands internal representations of entities, state, and constraints. So reasoning is not trained directly; it is instrumentally useful for prediction.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Close this segment by emphasizing mechanism over mystique: the objective is local, but the easiest way to minimize it across long contexts is to build useful global structure.</p></div>
  </div>
</div>

<!-- ═══════════════════════════════════════════════ -->
<!--  BACK TO MAIN PRESENTATION FLOW               -->
<!-- ═══════════════════════════════════════════════ -->

<!-- ═══════ SLIDE 16 — YOU ARE THE LANGUAGE MODEL ═══════ -->
<div class="slide" id="slide-16">
  <span class="section-tag">Activity</span>
  <div class="badge activity">Interactive Activity</div>
  <h2>You Are the Language Model</h2>
  <p class="small-text" style="max-width:700px;">Now you run the same objective yourself: predict the next token. Notice what <em>kind of knowledge</em> each example requires. This is why next-token training yields more than memorization.</p>
  <div class="spacer-sm"></div>
  <div style="display:flex; flex-direction:column; gap:10px; max-width:780px;" id="ntpGame">
    <div class="ntp-sentence">
      The Eiffel Tower is located in <span class="ntp-blank" onclick="revealNTP(this)" data-answer="Paris">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag fact">world knowledge</span>
    </div>
    <div class="ntp-sentence">
      After the rain stopped, the children ran outside to <span class="ntp-blank" onclick="revealNTP(this)" data-answer="play">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag lang">language / common sense</span>
    </div>
    <div class="ntp-sentence">
      def fibonacci(n):<br>&nbsp;&nbsp;if n <= 1: return n<br>&nbsp;&nbsp;return fibonacci(n-1) + <span class="ntp-blank" onclick="revealNTP(this)" data-answer="fibonacci(n-2)">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag code">code understanding</span>
    </div>
    <div class="ntp-sentence">
      If all roses are flowers, and all flowers need water, then all roses need <span class="ntp-blank" onclick="revealNTP(this)" data-answer="water">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag logic">logical reasoning</span>
    </div>
    <div class="ntp-sentence">
      The sum of \(127\) and \(385\) is <span class="ntp-blank" onclick="revealNTP(this)" data-answer="512">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag math">arithmetic</span>
    </div>
    <div class="ntp-sentence">
      She said "I'm not angry," but the tone of her voice suggested she was actually quite <span class="ntp-blank" onclick="revealNTP(this)" data-answer="upset">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag lang">pragmatics / subtext</span>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <button class="reveal-btn" onclick="revealAllNTP()">Reveal all answers</button>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Let participants think about each one before clicking. The point: "just predicting the next word" requires world knowledge, code understanding, logic, arithmetic, pragmatics. To predict well, you must understand deeply.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 17 — WHY NTP WORKS ═══════ -->
<div class="slide" id="slide-17">
  <span class="section-tag">Activity</span>
  <div class="badge concept">Key Takeaway</div>
  <h2>Why next-token prediction creates capable models</h2>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:720px;">
    <p class="small-text" style="line-height:1.7;">To predict the next token <em>well</em> across all of internet text, the model must develop internal representations of:</p>
    <div class="spacer-sm"></div>
    <div class="grid-3" style="gap:10px;">
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center;">
        <strong style="color:var(--cyan);">Facts</strong>
        <span class="tiny">"The capital of Pakistan is <strong>Islamabad</strong>"</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(167,139,250,0.08); border-color:rgba(167,139,250,0.18); color:#cbb8ff;">
        <strong style="color:var(--purple);">Syntax</strong>
        <span class="tiny">"She <strong>doesn't</strong> like..." not "She don't like..."</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(251,146,60,0.08); border-color:rgba(251,146,60,0.18); color:#fdc89b;">
        <strong style="color:var(--orange);">Logic</strong>
        <span class="tiny">\(\text{If } A \Rightarrow B,\; A,\; \therefore B\)</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(250,204,21,0.08); border-color:rgba(250,204,21,0.18); color:#fde68a;">
        <strong style="color:var(--yellow);">Math</strong>
        <span class="tiny">\(\,2 + 2 = 4\,\)</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(244,114,182,0.08); border-color:rgba(244,114,182,0.18); color:#fbb8d8;">
        <strong style="color:var(--pink);">Social cues</strong>
        <span class="tiny">"'I'm fine' (said angrily) means <strong>not fine</strong>"</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(74,222,128,0.08); border-color:rgba(74,222,128,0.18); color:#9eefbe;">
        <strong style="color:var(--green);">Code patterns</strong>
        <span class="tiny">"for i in range(n): <strong>...</strong>"</span>
      </div>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="callout success" style="max-width:720px;">
    <span class="icon">i</span>
    <span><strong>The compression hypothesis:</strong> The best way to predict text is to <em>understand</em> the process that generated it. Next, we'll use compression as a practical lens before zooming out to the full training pipeline.</span>
  </div>
</div>

<!-- ═══════ SLIDE 25 — COMPRESSION LENS ═══════ -->
<div class="slide" id="slide-25">
  <span class="section-tag">Compression Lens</span>
  <div class="badge concept">Mental Model</div>
  <h2>A useful lens: Intelligence as compression</h2>
  <p class="small-text" style="max-width:780px;">During pretraining, the model learns compressed internal representations that preserve what is useful for predicting text. This is not a full theory of intelligence, but it is a helpful lens.</p>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:820px;">
    <div class="card">
      <h3 style="color:var(--accent);">Compression pressure encourages</h3>
      <ul class="obj-list" style="margin-top:8px;">
        <li data-num="1">abstraction (categories, roles, relations)</li>
        <li data-num="2">reusable features across many tasks</li>
      </ul>
    </div>
    <div class="card">
      <h3 style="color:var(--green);">Why this matters</h3>
      <p class="small-text" style="line-height:1.7;">To predict text efficiently, the model is forced to represent large amounts of structure in a compact internal form.</p>
      <div class="spacer-sm"></div>
      <p class="small-text" style="line-height:1.7;">You can view pretraining as building a compact internal model of patterns that matter for prediction.</p>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <button class="reveal-btn" onclick="document.getElementById('compressionWhy').classList.toggle('revealed')">Why next-token prediction implies compression</button>
  <div class="hidden-content" id="compressionWhy">
    <div class="callout warn" style="max-width:820px;">
      <span class="icon">!</span>
      <span><strong>Raw problem:</strong> language is high-dimensional; tokens are noisy/redundant/ambiguous; surface forms vary wildly while deeper structures repeat.</span>
    </div>
    <div class="callout info" style="max-width:820px; margin-top:10px;">
      <span class="icon">→</span>
      <span><strong>A pure memorizer fails:</strong> poor generalization, huge capacity needs, and brittleness to slightly novel phrasing.</span>
    </div>
    <div class="callout success" style="max-width:820px; margin-top:10px;">
      <span class="icon">✓</span>
      <span><strong>So loss minimization pushes compression:</strong> collapse many surface forms into shared representations; retain what matters for next-token prediction; discard what does not.</span>
    </div>
  </div>
</div>

<!-- ═══════ SLIDE 26 — WHAT GETS COMPRESSED ═══════ -->
<div class="slide" id="slide-26">
  <span class="section-tag">Compression Lens</span>
  <div class="badge concept">Mechanism</div>
  <h2>What gets compressed, and why it looks like reasoning</h2>
  <p class="small-text" style="max-width:800px;">These structures are not explicitly labeled in pretraining. They emerge as latent variables that make prediction easier.</p>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:840px;">
    <div class="card">
      <h3 style="color:var(--cyan);">What gets compressed</h3>
      <ul class="obj-list" style="margin-top:8px;">
        <li data-num="1">entities (people, places, objects)</li>
        <li data-num="2">roles (subject, object, agent, patient)</li>
        <li data-num="3">relations (ownership, causality, temporal order)</li>
        <li data-num="4">abstract patterns (arguments, plans, code structure)</li>
        <li data-num="5">latent state (what is currently true)</li>
      </ul>
    </div>
    <div class="card">
      <h3 style="color:var(--orange);">Why this appears as reasoning</h3>
      <p class="small-text" style="line-height:1.7;">In narratives, explanations, mathematics, programming, and multi-step instructions, accurate continuation requires coherent internal state that respects constraints.</p>
      <div class="spacer-sm"></div>
      <div class="callout info" style="margin:0;">
        <span class="icon">i</span>
        <span>You cannot finish a proof without tracking assumptions, continue a story without tracking who did what, or autocomplete code without tracking scope and types.</span>
      </div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success" style="max-width:840px;">
    <span class="icon">✓</span>
    <span><strong>Transfer intuition:</strong> the same compressed internal features that help predict text also help many downstream tasks.</span>
  </div>
  <div class="callout info" style="max-width:840px;">
    <span class="icon">→</span>
    <span>This lens explains why pretraining transfers broadly. With that framing, now zoom out to the full training pipeline.</span>
  </div>
</div>

<!-- ═══════ SLIDE 27 — BRIDGE: ONE UPDATE → SYSTEM ═══════ -->
<div class="slide" id="slide-27">
  <span class="section-tag">Training Pipeline</span>
  <div class="badge concept">Bridge</div>
  <h2>One update → a system that scales</h2>
  <p class="small-text" style="max-width:780px;">We just traced one training update end-to-end. Now: how do we make <span class="hl">billions</span> of updates work reliably and predictably?</p>
  <div class="spacer"></div>
  <div class="card" style="max-width:800px;">
    <p class="small-text" style="margin-bottom:14px;">A modern LLM training run is a coordinated system:</p>
    <div class="grid-3" style="gap:12px;">
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center;">
        <strong style="color:var(--cyan);">Data System</strong>
        <span class="tiny">What the model is exposed to — source selection, cleaning, mixing</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(251,146,60,0.08); border-color:rgba(251,146,60,0.18); color:#fdc89b;">
        <strong style="color:var(--orange);">Optimization System</strong>
        <span class="tiny">How learning is executed — distributed training, stability, monitoring</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(74,222,128,0.08); border-color:rgba(74,222,128,0.18); color:#9eefbe;">
        <strong style="color:var(--green);">Evaluation Loop</strong>
        <span class="tiny">How failures drive iteration — benchmarks, human eval, data fixes</span>
      </div>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="callout warn" style="max-width:800px;">
    <span class="icon">!</span>
    <span><strong>The math is simple;</strong> making it run at scale is <em>engineering</em>. Next we'll map the full pipeline from raw data to deployed assistant.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Use this as the bridge from the deep-dive step-by-step update to "real training." Keep the focus on systems thinking: reliability, scale, and repeatability.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 18 — PIPELINE MAP ═══════ -->
<div class="slide" id="slide-18">
  <span class="section-tag">Training Pipeline</span>
  <div class="badge concept">Overview</div>
  <h2>From raw text to deployed assistant</h2>
  <p class="small-text" style="max-width:780px;">The same transformer architecture flows through every stage — only the <span class="hl">data</span>, <span class="hl-orange">objective</span>, and <span class="hl-green">feedback signal</span> change.</p>
  <div class="spacer-sm"></div>

  <div class="pipeline-v">
    <div class="pv-step">
      <div class="pv-dot cyan">1</div>
      <div class="pv-body">
        <h4><span class="hl-cyan">Collect raw corpora</span> <span class="pv-tag data">data</span></h4>
        <div class="pv-detail">Web crawls, books, code repos, academic papers, multilingual sources &mdash; \(\sim\!10\text{T}\) tokens of raw text.</div>
      </div>
    </div>
    <div class="pv-step">
      <div class="pv-dot cyan">2</div>
      <div class="pv-body">
        <h4><span class="hl-cyan">Clean, deduplicate &amp; filter</span> <span class="pv-tag data">data</span></h4>
        <div class="pv-detail">Strip boilerplate, fuzzy-dedup (MinHash), quality classifiers, language ID &rarr; \(\sim\!2\text{T}&ndash;5\text{T}\) usable tokens.</div>
      </div>
    </div>
    <div class="pv-step">
      <div class="pv-dot cyan">3</div>
      <div class="pv-body">
        <h4><span class="hl-cyan">Tokenize &amp; package</span> <span class="pv-tag data">data</span></h4>
        <div class="pv-detail">BPE tokenizer maps text to integer IDs. Pack into fixed-length sequences, shuffle, and shard across GPUs.</div>
      </div>
    </div>
    <div class="pv-step">
      <div class="pv-dot accent">4</div>
      <div class="pv-body">
        <h4><span class="hl">Pretrain</span> <span class="pv-tag train">training</span></h4>
        <div class="pv-detail">Next-token prediction on \(10^3\!+\) GPUs for weeks. The model learns grammar, facts, reasoning, and code from raw data alone.</div>
      </div>
    </div>
    <div class="pv-step">
      <div class="pv-dot orange">5</div>
      <div class="pv-body">
        <h4><span class="hl-orange">Supervised fine-tuning (SFT)</span> <span class="pv-tag align">alignment</span></h4>
        <div class="pv-detail">Train on instruction &rarr; response pairs. Teaches the model to follow directions and produce assistant-style output.</div>
      </div>
    </div>
    <div class="pv-step">
      <div class="pv-dot orange">6</div>
      <div class="pv-body">
        <h4><span class="hl-orange">Preference training &amp; RLHF</span> <span class="pv-tag align">alignment</span></h4>
        <div class="pv-detail">Reward model learns from human rankings (A &gt; B). Policy optimization nudges the model toward preferred behavior while staying close to the SFT baseline.</div>
      </div>
    </div>
    <div class="pv-step">
      <div class="pv-dot green">7</div>
      <div class="pv-body">
        <h4><span class="hl-green">Evaluate &amp; iterate</span> <span class="pv-tag eval">eval</span></h4>
        <div class="pv-detail">Run benchmarks, red-teaming, and human evals. Gaps feed back into new data collection and training runs &mdash; the loop repeats.</div>
      </div>
    </div>
    <div class="pv-step">
      <div class="pv-dot green">8</div>
      <div class="pv-body">
        <h4><span class="hl-green">Deploy</span></h4>
        <div class="pv-detail">Serve via API with guardrails, monitoring, and usage policies. Real-world feedback informs the next training cycle.</div>
      </div>
    </div>
  </div>

  <div class="spacer-sm"></div>
  <div class="callout info" style="max-width:820px;">
    <span class="icon">i</span>
    <span><strong>One architecture, many signals:</strong> every stage reuses the same transformer. What changes is the data it trains on and the objective it optimizes.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>This is the road map for the rest of the section. Walk through each step briefly — later slides zoom into each one. Emphasize that the architecture stays the same; data + objective change what is learned.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 28 — DATA PIPELINE ZOOM (STEPS 1-3) ═══════ -->
<div class="slide" id="slide-28">
  <span class="section-tag">Training Pipeline</span>
  <div class="badge deepdive">Step 1-3 Zoom-In</div>
  <h2>Before training: raw text becomes learnable tokens</h2>
  <p class="small-text" style="max-width:820px;">This is still data engineering, not model alignment. We shape noisy internet-scale text into a clean, diverse, efficiently packaged token stream the optimizer can learn from.</p>
  <div class="spacer-sm"></div>
  <div class="flow" style="justify-content:flex-start;">
    <div class="flow-box data">Collect</div>
    <div class="flow-arrow">→</div>
    <div class="flow-box data">Clean / filter</div>
    <div class="flow-arrow">→</div>
    <div class="flow-box yellow">Dedup</div>
    <div class="flow-arrow">→</div>
    <div class="flow-box model">Tokenize / package</div>
  </div>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:860px;">
    <div class="card">
      <h3 style="color:var(--cyan);">What happens in steps 1-3</h3>
      <ul class="obj-list" style="margin-top:8px;">
        <li data-num="1"><strong>Collect:</strong> web, books, code, papers, multilingual sources.</li>
        <li data-num="2"><strong>Clean/filter:</strong> remove boilerplate, spam, malformed text, low-quality shards.</li>
        <li data-num="3"><strong>Dedup:</strong> reduce near-duplicates so the model sees broader coverage.</li>
        <li data-num="4"><strong>Tokenize/package:</strong> map text to IDs, pack into fixed-length sequences, shuffle/shard for training.</li>
      </ul>
    </div>
    <div class="card">
      <h3 style="color:var(--green);">Why this stage exists</h3>
      <div class="callout info" style="margin:0;">
        <span class="icon">i</span>
        <span>Raw corpora are messy, repetitive, and uneven. Without preprocessing, training wastes compute and overfits narrow patterns.</span>
      </div>
      <div class="spacer-sm"></div>
      <div class="callout success" style="margin:0;">
        <span class="icon">✓</span>
        <span>After this stage, tokens are not just scraped text. They are engineered training examples designed for stable large-scale optimization.</span>
      </div>
      <div class="spacer-sm"></div>
      <p class="small-text">We stop here for now: no annotation depth yet. This slide only establishes how and why pretraining data is prepared.</p>
    </div>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Keep this brisk. The takeaway is that "tokens" are engineered artifacts, not raw internet text dumped into GPUs. Save annotation specifics for the post-training section.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 29 — PRETRAINING AT SCALE (STEP 4) ═══════ -->
<div class="slide" id="slide-29">
  <span class="section-tag">Training Pipeline</span>
  <div class="badge concept">Step 4</div>
  <h2>Pretraining at scale: next-token prediction repeated billions of times</h2>
  <p class="small-text" style="max-width:840px;">One objective, huge exposure: the model repeatedly predicts the next token across a massive distribution. This is where the model first learns language itself: structure, syntax, grammar, and broad semantic regularities.</p>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:860px;">
    <div class="math" style="margin:0;">
      \[\min_{\theta}\;-\log P_{\theta}(x_t \mid x_{\lt t})\]
    </div>
    <div class="spacer-sm"></div>
    <div class="flow" style="justify-content:flex-start; margin:0;">
      <div class="flow-box data">Context tokens</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box model">Predict next token</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box loss">Compute loss</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box grad">Update weights</div>
      <div class="flow-loop loop-arrow-anim">↺</div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="grid-3" style="max-width:860px;">
    <div class="card data-stat">
      <div class="big-num" style="color:var(--cyan);">2T-5T</div>
      <div class="stat-label">usable training tokens</div>
    </div>
    <div class="card data-stat">
      <div class="big-num" style="color:var(--accent);">1k+</div>
      <div class="stat-label">GPUs in parallel</div>
    </div>
    <div class="card data-stat">
      <div class="big-num" style="color:var(--orange);">weeks</div>
      <div class="stat-label">continuous optimization</div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success" style="max-width:860px;">
    <span class="icon">✓</span>
    <span><strong>What emerges first:</strong> fluent language modeling (syntax, grammar, coherence) plus broad world/statistical knowledge needed for sensible continuation.</span>
  </div>
  <div class="callout info" style="max-width:860px;">
    <span class="icon">i</span>
    <span><strong>Then specialization:</strong> once this base is solid, teams often run a lighter <strong>mid-training</strong> phase on targeted corpora (for example code, math, legal, or scientific text) to tilt capability toward specific domains.</span>
  </div>
  <div class="callout info" style="max-width:860px;">
    <span class="icon">→</span>
    <span><strong>Key intuition:</strong> capability is not magic; it is the expected result of broad exposure under a scalable objective.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Emphasize sequence: pretraining builds general language competence first. Mid-training then shifts emphasis toward target domains without changing the core objective.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 30 — DATA DISTRIBUTION DRIVES CAPABILITIES ═══════ -->
<div class="slide" id="slide-30">
  <span class="section-tag">Training Pipeline</span>
  <div class="badge concept">Bridge From Pretraining</div>
  <h2>Data drives capabilities: the training distribution is the lever</h2>
  <p class="small-text" style="max-width:860px;">After the model has base language competence, the next question is: <em>what data mix do we continue training on?</em> Capability profile follows that distributional mixture (often in mid-training).</p>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:880px;">
    <div class="card">
      <h3 style="color:var(--purple);">Code-heavy mixture</h3>
      <div class="mix-bar">
        <span class="mix-seg code" style="width:80%;"></span>
        <span class="mix-seg lit" style="width:20%;"></span>
      </div>
      <p class="tiny">Example: 80% code + technical text, 20% generic data</p>
      <ul class="obj-list" style="margin-top:10px;">
        <li data-num="1"><strong>Strength:</strong> stronger symbolic precision, structured problem decomposition, and code-oriented pattern completion.</li>
        <li data-num="2"><strong>Weakness:</strong> weaker stylistic nuance in narrative or poetic generation.</li>
      </ul>
    </div>
    <div class="card">
      <h3 style="color:var(--cyan);">Literary-heavy mixture</h3>
      <div class="mix-bar">
        <span class="mix-seg lit" style="width:80%;"></span>
        <span class="mix-seg code" style="width:20%;"></span>
      </div>
      <p class="tiny">Example: 80% literary/prose text, 20% generic data</p>
      <ul class="obj-list" style="margin-top:10px;">
        <li data-num="1"><strong>Strength:</strong> richer tone control, narrative fluency, and stylistic variation.</li>
        <li data-num="2"><strong>Weakness:</strong> lower reliability on formal symbolic tasks such as coding or math-heavy problem solving.</li>
      </ul>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout warn" style="max-width:880px;">
    <span class="icon">!</span>
    <span>Neither pretraining nor mid-training learns from "intent." Both learn from token statistics in the training distribution.</span>
  </div>
  <div class="callout success" style="max-width:880px;">
    <span class="icon">✓</span>
    <span><strong>Takeaway:</strong> keep pretraining for language foundations, then use mid-training mixture to steer specialization.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>This answers "what is pretraining learning from?" and introduces mid-training as the specialization dial. Foundation first, then targeted distribution shift.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 31 — COMPLETION TO CHAT WRAPPER (ACTIVITY) ═══════ -->
<div class="slide" id="slide-31">
  <span class="section-tag">Bridge To Alignment</span>
  <div class="badge activity">Interactive</div>
  <h2>It's still just a text completer</h2>
  <p class="small-text" style="max-width:860px;">We've pretrained a powerful model — but it was only ever trained to <span class="hl">predict the next token</span>. What happens when we actually try to use it?</p>
  <div class="spacer-sm"></div>

  <!-- PHASE 1: the dumb response -->
  <div class="card" style="max-width:860px;" id="completionPhase1">
    <h3 style="color:var(--accent); margin-bottom:10px;">What does the base model do with this prompt?</h3>
    <div class="prompt-block">What is the capital of France?</div>
    <div class="spacer-sm"></div>
    <button class="reveal-btn" onclick="revealDumbResponse()">Reveal the actual output</button>
    <div class="hidden-content" id="dumbResponseReveal">
      <div class="prompt-block" style="margin-top:10px; border-color:rgba(248,113,113,0.4);"><span style="color:var(--text-dim);">What is the capital of France?</span>
What is the capital of Germany?
What is the capital of Italy?
What is the capital of Spain?
What is the capital of ...</div>
      <div class="callout warn" style="margin-top:10px;">
        <span class="icon">!</span>
        <span><strong>It continued the pattern, not answered the question.</strong> The model learned to predict text — and quiz lists are common on the internet. It has no concept of "being helpful."</span>
      </div>
    </div>
  </div>

  <div class="spacer-sm"></div>

  <!-- PHASE 2: fix it with formatting -->
  <div class="hidden-content" id="completionPhase2">
    <div class="card" style="max-width:860px;">
      <h3 style="color:var(--green); margin-bottom:10px;">Can we fix this without changing the model?</h3>
      <p class="small-text">The weights are frozen. All you can change is the <span class="hl">prompt</span>. How do you steer the completion toward an answer?</p>
      <div class="spacer-sm"></div>
      <div class="grid-3" style="gap:12px;">
        <div class="card" style="padding:14px;">
          <p class="tiny" style="color:var(--text-dim); margin-bottom:6px;">Chat — get a helpful reply</p>
          <div class="prompt-block" style="font-size:0.72rem;">What is the capital of France?</div>
          <button class="reveal-btn" style="margin-top:8px; font-size:0.75rem; padding:6px 14px;" onclick="revealFix('chat')">Show fix</button>
          <div class="hidden-content" id="fixChat">
            <div class="prompt-block" style="font-size:0.72rem; border-color:rgba(74,222,128,0.4);">User: What is the capital of France?
<strong style="color:var(--green);">Assistant:</strong></div>
            <p class="tiny" style="margin-top:6px; color:var(--green);">→ "The capital of France is Paris."</p>
          </div>
        </div>
        <div class="card" style="padding:14px;">
          <p class="tiny" style="color:var(--text-dim); margin-bottom:6px;">Math — get the answer</p>
          <div class="prompt-block" style="font-size:0.72rem;">347 + 128</div>
          <button class="reveal-btn" style="margin-top:8px; font-size:0.75rem; padding:6px 14px;" onclick="revealFix('math')">Show fix</button>
          <div class="hidden-content" id="fixMath">
            <div class="prompt-block" style="font-size:0.72rem; border-color:rgba(74,222,128,0.4);">347 + 128 <strong style="color:var(--green);">=</strong></div>
            <p class="tiny" style="margin-top:6px; color:var(--green);">→ "475"</p>
          </div>
        </div>
        <div class="card" style="padding:14px;">
          <p class="tiny" style="color:var(--text-dim); margin-bottom:6px;">Code — get the implementation</p>
          <div class="prompt-block" style="font-size:0.72rem;">fibonacci function</div>
          <button class="reveal-btn" style="margin-top:8px; font-size:0.75rem; padding:6px 14px;" onclick="revealFix('code')">Show fix</button>
          <div class="hidden-content" id="fixCode">
            <div class="prompt-block" style="font-size:0.72rem; border-color:rgba(74,222,128,0.4);"><strong style="color:var(--green);">def fibonacci(n):</strong>
    """Return the nth Fibonacci number."""</div>
            <p class="tiny" style="margin-top:6px; color:var(--green);">→ completes the function body</p>
          </div>
        </div>
      </div>
      <div class="hidden-content" id="fixTakeaway">
        <div class="spacer-sm"></div>
        <div class="callout success" style="margin:0;">
          <span class="icon">✓</span>
          <span><strong>You're not changing the model.</strong> You're changing the distribution of likely continuations by shaping the context into a pattern where the "next token" is naturally the reply. <code>Assistant:</code> makes a reply likely. <code>=</code> makes an answer likely. A function signature makes code likely.</span>
        </div>
      </div>
    </div>

    <div class="hidden-content" id="fixBridge">
      <div class="spacer-sm"></div>

      <!-- PHASE 3: why this isn't enough -->
      <div class="callout warn" style="max-width:860px;">
        <span class="icon">!</span>
        <span><strong>But this is brittle.</strong> Change the wording slightly and the model drifts. It may roleplay the user, ignore instructions, or produce unsafe output. Formatting tricks steer — they don't <em>align</em>.</span>
      </div>
      <div class="callout info" style="max-width:860px; margin-top:8px;">
        <span class="icon">→</span>
        <span><strong>This is exactly why post-training exists.</strong> Instead of hoping the right context steers behavior, we update the weights so assistant-style responses become the default. That's next.</span>
      </div>
    </div>
  </div>

  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Sequence: (1) show prompt, ask audience to predict output, (2) reveal the dumb continuation — get laughs, (3) ask "how do we fix this without retraining?", (4) show the formatting examples, (5) emphasize this is brittle → bridge to post-training.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 32 — WHY POST-TRAINING EXISTS (STEPS 5-6) ═══════ -->
<div class="slide" id="slide-32">
  <span class="section-tag">Training Pipeline</span>
  <div class="badge concept">Steps 5-6</div>
  <h2>Why post-training exists: from context steering to behavior shaping</h2>
  <p class="small-text" style="max-width:920px;">Templates steer behavior at inference time by changing context. Post-training changes behavior at training time by updating parameters so assistant-style responses are more consistent, robust, and policy-constrained.</p>
  <div class="spacer-sm"></div>
  <div class="callout warn" style="max-width:900px; margin:0;">
    <span class="icon">!</span>
    <span><strong>Before alignment:</strong> "Assistant:" can steer continuation, but outcomes still drift with phrasing, context, and prompt hacks.</span>
  </div>
  <div class="callout info" style="max-width:900px; margin-top:10px;">
    <span class="icon">i</span>
    <span><strong>Inference-time trick:</strong> shape context. <strong>Post-training:</strong> shape parameters.</span>
  </div>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:900px;">
    <div class="card" style="border-color: rgba(251,146,60,0.3);">
      <div class="badge discussion" style="margin-bottom:8px;">Step 5</div>
      <h3 style="color:var(--orange);">Supervised fine-tuning (SFT)</h3>
      <ul class="obj-list" style="margin-top:8px;">
        <li data-num="1">Train on chat demonstrations: user turns -> assistant replies.</li>
        <li data-num="2">Teach stable instruction-following and response structure.</li>
        <li data-num="3">Make assistant-style continuation the default, not a formatting coincidence.</li>
      </ul>
    </div>
    <div class="card" style="border-color: rgba(251,146,60,0.3);">
      <div class="badge discussion" style="margin-bottom:8px;">Step 6</div>
      <h3 style="color:var(--orange);">Preference training + RLHF</h3>
      <ul class="obj-list" style="margin-top:8px;">
        <li data-num="1">Use human rankings to distinguish better vs worse candidate replies.</li>
        <li data-num="2">Push behavior toward helpfulness, policy compliance, and safer refusals.</li>
        <li data-num="3">Improve robustness beyond specific templates or token tricks.</li>
      </ul>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="flow" style="justify-content:flex-start;">
    <div class="flow-box model">Base completer + chat template</div>
    <div class="flow-arrow">→</div>
    <div class="flow-box loss">SFT</div>
    <div class="flow-arrow">→</div>
    <div class="flow-box grad">Preferences / RLHF</div>
    <div class="flow-arrow">→</div>
    <div class="flow-box green">Aligned assistant</div>
  </div>
  <div class="callout info" style="max-width:900px;">
    <span class="icon">i</span>
    <span><strong>The model is still autoregressive next-token generation.</strong> Alignment changes the distribution it learns to generate from.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Bridge directly from the activity: "We can coerce a reply with suffixes, but that is fragile. SFT and preference training make assistant behavior consistent and constrained." Keep repeating: still autoregressive, now better conditioned by training.</p></div>
  </div>
</div>

</div><!-- /slide-container -->

<!-- ── Bottom navigation bar ── -->
<div class="bottom-bar">
  <button class="nav-btn" id="btnPrev" disabled>← Back</button>
  <div class="progress-track">
    <div class="progress-fill" id="progressFill" style="width:0%"></div>
  </div>
  <span class="slide-counter" id="slideCounter">1 / 29</span>
  <button class="nav-btn primary" id="btnNext">Next →</button>
</div>

<script>
// ══════════════════════════════════════
//  Slide engine
// ══════════════════════════════════════
const SLIDE_ORDER = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 8, 22, 23, 24, 16, 17, 25, 26, 27, 18, 28, 29, 30, 31, 32];
const TOTAL = SLIDE_ORDER.length;
let current = 0;

const $ = s => document.querySelector(s);
const $$ = s => document.querySelectorAll(s);
function typesetMath(root = document) {
  if (!window.MathJax || !window.MathJax.typesetPromise) return;
  window.MathJax.typesetPromise([root]).catch(() => {});
}

function goTo(n) {
  if (n < 0 || n >= TOTAL) return;
  $$('.slide').forEach(s => s.classList.remove('active'));
  const slideId = SLIDE_ORDER[n];
  document.getElementById(`slide-${slideId}`).classList.add('active');
  current = n;
  $('#btnPrev').disabled = n === 0;
  $('#btnNext').textContent = n === TOTAL - 1 ? 'Restart ↺' : 'Next →';
  $('#slideCounter').textContent = `${n + 1} / ${TOTAL}`;
  $('#progressFill').style.width = `${(n / (TOTAL - 1)) * 100}%`;

  // trigger animations for specific slides
  onSlideEnter(slideId);
  typesetMath(document.getElementById(`slide-${slideId}`));
}

$('#btnNext').addEventListener('click', () => {
  if (current === TOTAL - 1) goTo(0);
  else goTo(current + 1);
});
$('#btnPrev').addEventListener('click', () => goTo(current - 1));

document.addEventListener('keydown', e => {
  if (e.key === 'ArrowRight' || e.key === ' ') { e.preventDefault(); $('#btnNext').click(); }
  if (e.key === 'ArrowLeft') { e.preventDefault(); $('#btnPrev').click(); }
});

// ══════════════════════════════════════
//  Ingredient reveal (all three)
// ══════════════════════════════════════
var ingredientColors = {
  1: 'rgba(0,255,255,0.35)',
  2: 'rgba(108,140,255,0.35)',
  3: 'rgba(167,139,250,0.4)'
};

function revealIngredient(n) {
  document.getElementById('ingredient' + n + 'Hidden').style.display = 'none';
  document.getElementById('ingredient' + n + 'Revealed').style.display = 'block';
  document.getElementById('ingredient' + n + 'Card').style.borderColor = ingredientColors[n];
  document.getElementById('ingredientExplanation' + n).classList.add('revealed');
}

function resetIngredients() {
  for (var i = 1; i <= 3; i++) {
    document.getElementById('ingredient' + i + 'Hidden').style.display = '';
    document.getElementById('ingredient' + i + 'Revealed').style.display = 'none';
    document.getElementById('ingredient' + i + 'Card').style.borderColor = '';
    var exp = document.getElementById('ingredientExplanation' + i);
    exp.classList.remove('revealed', 'settled');
  }
}

function revealReasoningPressure() {
  const grid = document.getElementById('reasoningPressureGrid');
  const quote = document.getElementById('reasoningEmergenceQuote');
  if (grid) grid.classList.add('revealed');
  if (quote) quote.classList.add('revealed');
}

function revealDramaAnswer() {
  const blank = document.getElementById('dramaKillerBlank');
  const why = document.getElementById('dramaWhy');
  const result = document.getElementById('dramaResult');
  if (blank && !blank.classList.contains('show')) {
    blank.textContent = blank.dataset.answer;
    blank.classList.add('show');
  }
  if (why) why.classList.add('revealed');
  if (result) {
    result.className = 'callout success';
    result.style.maxWidth = '800px';
    result.innerHTML = '<span class="icon">✓</span><span>Best next-token continuation: <strong>Rukhsana thi</strong>, based on timing + access constraints.</span>';
  }
}

function chooseDramaSuspect(choice, btn) {
  const buttons = document.querySelectorAll('#dramaChoices .drama-choice');
  buttons.forEach(b => b.classList.remove('correct', 'wrong'));
  if (choice === 'Rukhsana') btn.classList.add('correct');
  else btn.classList.add('wrong');

  const result = document.getElementById('dramaResult');
  if (result) {
    const isCorrect = choice === 'Rukhsana';
    result.className = isCorrect ? 'callout success' : 'callout warn';
    result.style.maxWidth = '800px';
    result.innerHTML = isCorrect
      ? '<span class="icon">✓</span><span>Consistent choice. Timing and pantry-access constraints point to <strong>Rukhsana</strong>.</span>'
      : '<span class="icon">!</span><span>This choice conflicts with the timeline/access clues. Re-check who could act between 10:20 and 10:30.</span>';
  }

  if (choice === 'Rukhsana') {
    revealDramaAnswer();
  }
}

// ══════════════════════════════════════
//  Completion wrapper activity
// ══════════════════════════════════════
function revealDumbResponse() {
  const reveal = document.getElementById('dumbResponseReveal');
  if (reveal) reveal.classList.add('revealed');
  // After a short pause, show phase 2
  setTimeout(function() {
    const phase2 = document.getElementById('completionPhase2');
    if (phase2) phase2.classList.add('revealed');
  }, 600);
}

var fixesRevealed = { chat: false, math: false, code: false };

function revealFix(which) {
  var el = document.getElementById('fix' + which.charAt(0).toUpperCase() + which.slice(1));
  if (el) el.classList.add('revealed');
  fixesRevealed[which] = true;
  if (fixesRevealed.chat && fixesRevealed.math && fixesRevealed.code) {
    setTimeout(function() {
      var t = document.getElementById('fixTakeaway');
      var b = document.getElementById('fixBridge');
      if (t) t.classList.add('revealed');
      if (b) b.classList.add('revealed');
    }, 400);
  }
}

function resetCompletionActivity() {
  fixesRevealed = { chat: false, math: false, code: false };
  ['dumbResponseReveal', 'completionPhase2', 'fixChat', 'fixMath', 'fixCode', 'fixTakeaway', 'fixBridge'].forEach(function(id) {
    var el = document.getElementById(id);
    if (el) el.classList.remove('revealed', 'settled');
  });
}

// ══════════════════════════════════════
//  Live demo video (lazy load)
// ══════════════════════════════════════
let liveDemoLoaded = false;

function getLiveDemoCandidates(host) {
  const candidates = [];
  // 1) First try same directory as this HTML file.
  if (host.dataset.videoRelative) {
    candidates.push(host.dataset.videoRelative);
  }
  // 2) Fallback to absolute path.
  if (host.dataset.videoPath && host.dataset.videoPath.startsWith('/')) {
    candidates.push(`file://${host.dataset.videoPath}`);
  } else if (host.dataset.videoPath) {
    candidates.push(host.dataset.videoPath);
  }
  return candidates;
}

function ensureLiveDemoLoaded() {
  if (liveDemoLoaded) return;
  const host = document.getElementById('liveDemoHost');
  if (!host) return;

  const candidates = getLiveDemoCandidates(host);
  if (!candidates.length) return;

  const video = document.createElement('video');
  video.className = 'live-demo-video';
  video.controls = true;
  video.preload = 'metadata';
  video.playsInline = true;

  let idx = 0;
  const tryNextSource = () => {
    if (idx >= candidates.length) return;
    video.src = candidates[idx++];
    video.load();
  };
  video.addEventListener('error', tryNextSource);
  tryNextSource();

  host.innerHTML = '';
  host.appendChild(video);
  liveDemoLoaded = true;
}

function pauseLiveDemoIfNeeded() {
  const host = document.getElementById('liveDemoHost');
  if (!host) return;
  const video = host.querySelector('video');
  if (!video) return;
  video.pause();
}

// ══════════════════════════════════════
//  Inference demo (fixed: 3 steps only)
// ══════════════════════════════════════
const INF_TOKENS = ['Islamabad', '.', '⟨EOS⟩'];
let infStep = 0;

function animateInference() {
  if (infStep >= INF_TOKENS.length) return;

  const row = document.getElementById('inferenceDemo');
  const cur = document.getElementById('infCurrent');

  // convert current blank → filled token
  cur.removeAttribute('id');
  cur.classList.remove('blank');
  cur.style.cursor = 'default';
  cur.onclick = null;

  const tok = INF_TOKENS[infStep];
  cur.textContent = tok;

  if (tok === '⟨EOS⟩') {
    // end-of-sentence styling
    cur.classList.add('done');
  } else {
    cur.classList.add('target');
    cur.style.borderStyle = 'solid';
  }

  infStep++;

  // add next blank if not finished
  if (infStep < INF_TOKENS.length) {
    setTimeout(() => {
      const newBlank = document.createElement('span');
      newBlank.className = 'tok blank';
      newBlank.id = 'infCurrent';
      newBlank.textContent = 'click';
      newBlank.onclick = animateInference;
      row.appendChild(newBlank);
    }, 350);
  } else {
    // all done — update hint text
    document.getElementById('infHint').textContent = 'Generation complete — the model produced 3 tokens.';
    document.getElementById('infHint').style.color = 'var(--green)';
  }
}

// ══════════════════════════════════════
//  Training loop (slide 6) — 5-phase interactive reveal
// ══════════════════════════════════════
var trainPhase = 0;
var trainExplanations = {
  1: '<strong>Forward pass</strong> — identical to inference. Tokens go in, the Transformer processes them through all its layers, and a probability distribution over possible next tokens comes out. Nothing is different yet.',
  2: '<strong>The teacher signal</strong> — during training, we already know the correct next token. It\'s simply the next word in the training data. This ground truth is what makes learning possible — the model doesn\'t have to figure out what\'s right on its own.',
  3: '<strong>Cross-entropy loss</strong> — measures how much probability the model gave to the correct token. High confidence in the right answer \u2192 low loss. Surprised by it \u2192 high loss. One number that captures "how wrong was the prediction."',
  4: '<strong>Backpropagation</strong> — the chain rule traces the loss backward through every layer. For each of the billions of weights, it answers: "how much did <em>you</em> contribute to the error?" This produces a gradient \u2202L/\u2202\u03B8 for every single parameter.',
  5: '<strong>Weight update</strong> — each weight is nudged in the direction that reduces the loss. The learning rate \u03B7 controls step size. After updating, the next batch runs through a slightly better model. Repeat billions of times.'
};

function trainStep(phase) {
  trainPhase = phase;

  // Highlight active button, dim future ones
  for (var i = 1; i <= 5; i++) {
    var btn = document.getElementById('trainBtn' + i);
    btn.style.opacity = i <= phase ? '1' : '0.45';
    btn.style.borderColor = i === phase ? 'var(--cyan)' : '';
  }

  // Phase 1: forward pass lights up
  document.getElementById('trainFwd').style.opacity = phase >= 1 ? '1' : '0.25';

  // Phase 2: comparison
  document.getElementById('trainCompare').style.display = phase >= 2 ? '' : 'none';

  // Phase 3: loss
  document.getElementById('trainLoss').style.display = phase >= 3 ? '' : 'none';

  // Phase 4: backpropagation
  document.getElementById('trainBackprop').style.display = phase >= 4 ? '' : 'none';

  // Phase 5: update + loop-back
  document.getElementById('trainUpdate').style.display = phase >= 5 ? '' : 'none';

  // Highlight transformer box during backprop & update
  var tfBox = document.getElementById('trainTransformer');
  if (phase === 4) {
    tfBox.style.borderColor = 'rgba(251,146,60,0.6)';
    tfBox.style.boxShadow = '0 0 8px rgba(251,146,60,0.2)';
  } else if (phase === 5) {
    tfBox.style.borderColor = 'var(--orange)';
    tfBox.style.boxShadow = '0 0 14px rgba(251,146,60,0.35)';
  } else {
    tfBox.style.borderColor = '';
    tfBox.style.boxShadow = '';
  }

  // Explanation callout
  var explainDiv = document.getElementById('trainExplain');
  var explainText = document.getElementById('trainExplainText');
  explainDiv.style.display = '';
  explainText.innerHTML = trainExplanations[phase];
}

function resetTrainLoop() {
  trainPhase = 0;
  document.getElementById('trainFwd').style.opacity = '0.25';
  document.getElementById('trainCompare').style.display = 'none';
  document.getElementById('trainLoss').style.display = 'none';
  document.getElementById('trainBackprop').style.display = 'none';
  document.getElementById('trainUpdate').style.display = 'none';
  document.getElementById('trainExplain').style.display = 'none';
  var tfBox = document.getElementById('trainTransformer');
  tfBox.style.borderColor = '';
  tfBox.style.boxShadow = '';
  for (var i = 1; i <= 5; i++) {
    var btn = document.getElementById('trainBtn' + i);
    btn.style.opacity = '';
    btn.style.borderColor = '';
  }
}

// ══════════════════════════════════════
//  NTP game
// ══════════════════════════════════════
function revealNTP(el) {
  if (el.classList.contains('show')) return;
  el.textContent = el.dataset.answer;
  el.classList.add('show');
}
function revealNTPConcept(btn) {
  const sentence = btn.closest('.ntp-sentence');
  const tag = sentence ? sentence.querySelector('.ntp-tag') : null;
  if (tag) tag.classList.add('show');
  btn.style.display = 'none';
}
function revealAllNTP() {
  $$('.ntp-blank').forEach(el => {
    el.textContent = el.dataset.answer;
    el.classList.add('show');
  });
  $$('.ntp-concept-btn').forEach(btn => { btn.style.display = 'none'; });
  $$('.ntp-tag').forEach(tag => tag.classList.add('show'));
}

// ══════════════════════════════════════
//  Bar chart builder (for loss deep-dive)
// ══════════════════════════════════════
const VOCAB = [
  { word: 'Islamabad', predicted: 0.08, target: 1.00, after: 0.28 },
  { word: 'Karachi',   predicted: 0.11, target: 0.00, after: 0.06 },
  { word: 'the',       predicted: 0.14, target: 0.00, after: 0.09 },
  { word: 'Lahore',    predicted: 0.06, target: 0.00, after: 0.03 },
  { word: 'a',         predicted: 0.10, target: 0.00, after: 0.07 },
  { word: 'Peshawar',  predicted: 0.04, target: 0.00, after: 0.03 },
  { word: 'Delhi',     predicted: 0.05, target: 0.00, after: 0.02 },
  { word: 'not',       predicted: 0.07, target: 0.00, after: 0.05 },
  { word: '...',       predicted: 0.35, target: 0.00, after: 0.37 },
];

function buildBars(container, data, type) {
  const el = typeof container === 'string' ? $(container) : container;
  if (!el) return;
  el.innerHTML = '';
  data.forEach((d, i) => {
    const row = document.createElement('div');
    row.className = 'bar-row';

    const wordEl = document.createElement('div');
    wordEl.className = 'bar-word';
    wordEl.textContent = d.word;
    if (d.word === 'Islamabad') wordEl.style.color = 'var(--green)';

    const track = document.createElement('div');
    track.className = 'bar-track';

    const fill = document.createElement('div');
    fill.className = 'bar-fill ' + type;
    const pctWidth = d.value > 0 ? Math.max(d.value * 100, 1.5) : 0;
    fill.style.width = '0%';
    setTimeout(() => { fill.style.width = pctWidth + '%'; }, 80 + i * 50);

    track.appendChild(fill);

    const pctEl = document.createElement('div');
    pctEl.className = 'bar-pct';
    pctEl.textContent = `\\(${(d.value * 100).toFixed(1)}\\%\\)`;

    row.appendChild(wordEl);
    row.appendChild(track);
    row.appendChild(pctEl);
    el.appendChild(row);
  });
  // Bars can be inserted after slide-enter (e.g., delayed "after update" chart),
  // so explicitly typeset newly injected LaTeX labels here.
  typesetMath(el);
}

function predictedData() { return VOCAB.map(v => ({ word: v.word, value: v.predicted })); }
function targetData()    { return VOCAB.map(v => ({ word: v.word, value: v.target })); }
function afterData()     { return VOCAB.map(v => ({ word: v.word, value: v.after })); }

// ══════════════════════════════════════
//  Slide-specific enter logic
// ══════════════════════════════════════
function onSlideEnter(n) {
  // Slide 2: lazy load live demo video only when needed
  if (n === 2) {
    ensureLiveDemoLoaded();
  } else {
    pauseLiveDemoIfNeeded();
  }

  // Slide 3: reset ingredients
  if (n === 3) {
    resetIngredients();
  }

  // Slide 6: reset training loop
  if (n === 6) {
    resetTrainLoop();
  }

  // Slide 10: forward pass — build predicted chart
  if (n === 10) {
    buildBars('#predictedChart', predictedData(), 'predicted');
  }
  // Slide 11: target comparison — dual charts
  if (n === 11) {
    buildBars('#dualPredicted', predictedData(), 'predicted');
    buildBars('#dualTarget', targetData(), 'target-fill');
    const pct = VOCAB[0].predicted;
    $('#correctPctText').textContent = `\\(${(pct * 100).toFixed(0)}\\%\\)`;
  }
  // Slide 12: loss computation
  if (n === 12) {
    const p = VOCAB[0].predicted;
    const loss = -Math.log(p);
    const pText = p.toFixed(2);
    const lossText = loss.toFixed(2);
    $('#lossFormula').textContent = `\\[\\mathcal{L} = -\\log(P_{\\text{model}}(\\text{Islamabad})) = -\\log(${pText}) = ${lossText}\\]`;
    $('#lossProbDisplay').textContent = `\\(${pText}\\)`;
    $('#lossValueDisplay').textContent = `\\(${lossText}\\)`;
    const meter = $('#lossMeter');
    meter.style.width = '0%';
    setTimeout(() => { meter.style.width = Math.min(loss / 5 * 100, 100) + '%'; }, 200);
  }
  // Slide 14: before/after
  if (n === 14) {
    buildBars('#beforeBars', predictedData(), 'predicted');
    setTimeout(() => {
      buildBars('#afterBars', afterData(), 'target-fill');
    }, 300);
    const afterLoss = -Math.log(VOCAB[0].after);
    $('#lossAfterVal').textContent = `\\(${afterLoss.toFixed(2)}\\)`;
    $('#afterCorrectPct').textContent = `\\(${(VOCAB[0].after * 100).toFixed(0)}\\%\\)`;
    $('#afterLossText').textContent = `\\(${afterLoss.toFixed(2)}\\)`;
  }
  if (n === 22) {
    const grid = document.getElementById('reasoningPressureGrid');
    const quote = document.getElementById('reasoningEmergenceQuote');
    if (grid) grid.classList.remove('revealed', 'settled');
    if (quote) quote.classList.remove('revealed', 'settled');
  }
  if (n === 23) {
    const blank = document.getElementById('dramaKillerBlank');
    const why = document.getElementById('dramaWhy');
    const result = document.getElementById('dramaResult');
    const buttons = document.querySelectorAll('#dramaChoices .drama-choice');
    if (blank) {
      blank.textContent = '___';
      blank.classList.remove('show');
    }
    if (why) why.classList.remove('revealed', 'settled');
    buttons.forEach(b => b.classList.remove('correct', 'wrong'));
    if (result) {
      result.className = 'callout warn';
      result.style.maxWidth = '800px';
      result.innerHTML = '<span class="icon">?</span><span>Select a suspect. Then check whether your choice satisfies the timing + access constraints.</span>';
    }
  }
  if (n === 31) {
    resetCompletionActivity();
  }
}

// ══════════════════════════════════════
//  Init
// ══════════════════════════════════════
const loadLiveDemoBtn = document.getElementById('loadLiveDemoBtn');
if (loadLiveDemoBtn) {
  loadLiveDemoBtn.addEventListener('click', ensureLiveDemoLoaded);
}

// settle hidden-content after reveal transition so scroll works
// After reveal transition, remove max-height constraint so slide can scroll
document.addEventListener('transitionend', function(e) {
  var el = e.target;
  if (!el.classList.contains('hidden-content') || e.propertyName !== 'max-height') return;
  if (el.classList.contains('revealed')) {
    el.classList.add('settled');
  } else {
    el.classList.remove('settled');
  }
});

goTo(0);
</script>
</body>
</html>
