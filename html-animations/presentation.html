<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Day 1 — Language Modeling from Scratch</title>
<style>
  @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap');

  * { margin: 0; padding: 0; box-sizing: border-box; }

  :root {
    --bg: #0f1117;
    --surface: #1a1d27;
    --surface2: #242836;
    --border: #2e3345;
    --text: #f3f3f5;
    --text-dim: #8a8fa8;
    --accent: #6c8cff;
    --accent-glow: rgba(108,140,255,0.25);
    --green: #4ade80;
    --green-glow: rgba(74,222,128,0.2);
    --red: #f87171;
    --orange: #fb923c;
    --purple: #a78bfa;
    --yellow: #facc15;
    --cyan: #22d3ee;
    --pink: #f472b6;
    --deck-base-width: 1600;
    --deck-base-height: 900;
    --deck-scale: 1;
    --deck-max-scale: 1.22;
    --stage-pad-x: clamp(10px, 1.8vw, 28px);
    --stage-pad-y: clamp(10px, 1.8vh, 26px);
    --space-2xs: clamp(4px, 0.35vw, 8px);
    --space-xs: clamp(8px, 0.55vw, 12px);
    --space-sm: clamp(12px, 0.9vw, 18px);
    --space-md: clamp(16px, 1.2vw, 24px);
    --space-lg: clamp(22px, 1.8vw, 34px);
    --space-xl: clamp(30px, 2.6vw, 52px);
    --space-2xl: clamp(42px, 4.2vw, 76px);
    --font-h1: clamp(2.2rem, 1.5rem + 1.7vw, 3.3rem);
    --font-h1-large: clamp(2.75rem, 1.95rem + 2.2vw, 4.2rem);
    --font-h2: clamp(1.45rem, 1.08rem + 0.95vw, 2.15rem);
    --font-h3: clamp(1rem, 0.9rem + 0.4vw, 1.28rem);
    --font-subtitle: clamp(1rem, 0.88rem + 0.48vw, 1.32rem);
    --font-body: clamp(0.84rem, 0.78rem + 0.22vw, 1rem);
    --font-tiny: clamp(0.72rem, 0.68rem + 0.15vw, 0.86rem);
    --font-mono: clamp(0.92rem, 0.84rem + 0.35vw, 1.16rem);
    --measure-compact: clamp(16rem, 24vw, 24rem);
    --measure-xs: clamp(22rem, 34vw, 30rem);
    --measure-sm: clamp(28rem, 46vw, 38rem);
    --measure-md: clamp(34rem, 58vw, 46rem);
    --measure-lg: clamp(40rem, 70vw, 56rem);
    --measure-xl: clamp(46rem, 80vw, 66rem);
    --measure-xxl: clamp(50rem, 88vw, 74rem);
  }

  body {
    background: var(--bg);
    color: var(--text);
    font-family: 'Inter', sans-serif;
    height: 100vh;
    height: 100dvh;
    min-height: 100vh;
    min-height: 100dvh;
    overflow: hidden;
    display: flex;
    flex-direction: column;
  }

  /* ── Slide system ── */
  .slide-container {
    flex: 1;
    position: relative;
    display: grid;
    place-items: center;
    padding: var(--stage-pad-y) var(--stage-pad-x);
    overflow: hidden;
    isolation: isolate;
  }
  .slide-container::before {
    content: '';
    position: absolute;
    inset: 0;
    background:
      radial-gradient(circle at center, rgba(108,140,255,0.12), transparent 62%),
      radial-gradient(circle at center, rgba(167,139,250,0.08), transparent 78%);
    pointer-events: none;
    z-index: 0;
  }
  .slide {
    position: absolute;
    top: 50%;
    left: 50%;
    width: calc(var(--deck-base-width) * 1px);
    height: calc(var(--deck-base-height) * 1px);
    margin: 0;
    transform: translate(-50%, -50%) scale(var(--deck-scale));
    transform-origin: center center;
    display: none;
    flex-direction: column;
    padding: clamp(26px, 2.4vh, 44px) clamp(30px, 3.6vw, 74px) clamp(56px, 6.4vh, 100px);
    overflow-y: auto;
    scrollbar-width: thin;
    scrollbar-color: var(--border) transparent;
    animation: fadeSlideIn 0.45s ease;
    z-index: 1;
    border: 1px solid rgba(108,140,255,0.16);
    border-radius: clamp(14px, 1.3vw, 24px);
    background:
      linear-gradient(180deg, rgba(26,29,39,0.92), rgba(15,17,23,0.9)),
      radial-gradient(ellipse at top left, rgba(108,140,255,0.1), transparent 60%);
    box-shadow:
      0 30px 80px rgba(0,0,0,0.42),
      0 0 0 1px rgba(255,255,255,0.015) inset;
  }
  .slide.active { display: flex; }

  @keyframes fadeSlideIn {
    from { opacity: 0; }
    to   { opacity: 1; }
  }

  .slide.centered {
    align-items: center;
    justify-content: center;
    text-align: center;
  }

  /* ── Typography ── */
  h1 {
    font-size: var(--font-h1);
    font-weight: 800;
    letter-spacing: -0.03em;
    line-height: 1.15;
    background: linear-gradient(135deg, var(--accent), var(--purple));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
  }
  h1.large { font-size: var(--font-h1-large); }
  h2 {
    font-size: var(--font-h2);
    font-weight: 700;
    letter-spacing: -0.02em;
    margin-bottom: var(--space-sm);
  }
  h3 {
    font-size: var(--font-h3);
    font-weight: 600;
    margin-bottom: var(--space-xs);
  }
  .subtitle {
    font-size: var(--font-subtitle);
    color: var(--text-dim);
    margin-top: var(--space-xs);
    line-height: 1.5;
    max-width: var(--measure-md);
  }
  .small-text {
    font-size: var(--font-body);
    color: var(--text-dim);
    line-height: 1.55;
  }
  .tiny {
    font-size: var(--font-tiny);
    color: var(--text-dim);
  }

  .slide > h2,
  .slide > p.small-text,
  .slide > p.subtitle,
  .slide > .math,
  .slide > .token-row,
  .slide > .callout,
  .slide > .card,
  .slide > .grid-2,
  .slide > .grid-3,
  .slide > .grid-4,
  .slide > .flow,
  .slide > .dual-charts,
  .slide > .before-after,
  .slide > .update-flow,
  .slide > .pressure-grid,
  .slide > .drama-script,
  .slide > #ntpGame,
  .slide > .speaker-notes {
    width: min(100%, var(--measure-lg));
    margin-inline: auto;
  }
  .slide > .grid-2,
  .slide > .grid-3,
  .slide > .grid-4,
  .slide > .dual-charts,
  .slide > .before-after,
  .slide > .update-flow,
  .slide > .pressure-grid,
  .slide > .drama-script,
  .slide > #ntpGame {
    width: min(100%, var(--measure-xl));
  }

  /* ── Highlight spans ── */
  .hl        { color: var(--accent); font-weight: 600; }
  .hl-green  { color: var(--green);  font-weight: 600; }
  .hl-red    { color: var(--red);    font-weight: 600; }
  .hl-orange { color: var(--orange); font-weight: 600; }
  .hl-purple { color: var(--purple); font-weight: 600; }
  .hl-yellow { color: var(--yellow); font-weight: 600; }
  .hl-cyan   { color: var(--cyan);   font-weight: 600; }
  .hl-pink   { color: var(--pink);   font-weight: 600; }

  /* ── Cards ── */
  .card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: clamp(12px, 0.9vw, 18px);
    padding: clamp(16px, 1.4vw, 28px);
    position: relative;
    overflow: hidden;
  }
  .card::before {
    content: '';
    position: absolute;
    inset: 0;
    background: radial-gradient(ellipse at top left, rgba(108,140,255,0.04), transparent 60%);
    pointer-events: none;
  }

  /* ── Callouts ── */
  .callout {
    display: flex;
    gap: clamp(8px, 0.8vw, 14px);
    padding: clamp(12px, 1vw, 18px) clamp(14px, 1.1vw, 22px);
    border-radius: clamp(8px, 0.8vw, 12px);
    font-size: var(--font-body);
    line-height: 1.55;
  }
  .callout.info    { background: rgba(108,140,255,0.08); border: 1px solid rgba(108,140,255,0.18); color: #b8c7ff; }
  .callout.warn    { background: rgba(251,146,60,0.08);  border: 1px solid rgba(251,146,60,0.18);  color: #fdc89b; }
  .callout.success { background: rgba(74,222,128,0.08);  border: 1px solid rgba(74,222,128,0.18);  color: #9eefbe; }
  .callout.question { background: rgba(167,139,250,0.08); border: 1px solid rgba(167,139,250,0.18); color: #cbb8ff; }
  .callout.pink    { background: rgba(244,114,182,0.08); border: 1px solid rgba(244,114,182,0.18); color: #fbb8d8; }
  .callout .icon { flex-shrink: 0; font-size: clamp(1rem, 0.92rem + 0.32vw, 1.24rem); }

  /* ── Badges / pills ── */
  .badge {
    display: inline-block;
    font-size: clamp(0.66rem, 0.63rem + 0.1vw, 0.76rem);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    padding: var(--space-2xs) var(--space-sm);
    border-radius: 20px;
    margin-bottom: var(--space-sm);
  }
  .badge.day1 { background: rgba(108,140,255,0.15); color: var(--accent); }
  .badge.activity { background: rgba(74,222,128,0.15); color: var(--green); }
  .badge.concept { background: rgba(167,139,250,0.15); color: var(--purple); }
  .badge.discussion { background: rgba(251,146,60,0.15); color: var(--orange); }
  .badge.deepdive { background: rgba(250,204,21,0.15); color: var(--yellow); }

  /* ── Grid layouts ── */
  .grid-2 { display: grid; grid-template-columns: 1fr 1fr; gap: clamp(14px, 1.4vw, 24px); }
  .grid-3 { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: clamp(12px, 1.1vw, 20px); }
  .grid-4 { display: grid; grid-template-columns: repeat(4, 1fr); gap: clamp(10px, 1vw, 18px); }
  @media (max-width: 800px) {
    .grid-2, .grid-3, .grid-4 { grid-template-columns: 1fr; }
  }

  /* ── Flow diagrams ── */
  .flow {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: clamp(8px, 0.8vw, 14px);
    flex-wrap: wrap;
    margin: var(--space-md) 0;
  }
  .flow-box {
    padding: clamp(10px, 0.85vw, 16px) clamp(14px, 1.2vw, 24px);
    border-radius: clamp(8px, 0.8vw, 12px);
    font-size: var(--font-body);
    font-weight: 600;
    text-align: center;
    border: 1px solid var(--border);
    background: var(--surface);
    min-width: clamp(96px, 8vw, 132px);
  }
  .flow-arrow {
    color: var(--text-dim);
    font-size: clamp(1.15rem, 1rem + 0.45vw, 1.5rem);
    flex-shrink: 0;
  }
  .flow-box.data    { border-color: rgba(34,211,238,0.4); color: var(--cyan); background: rgba(34,211,238,0.06); }
  .flow-box.model   { border-color: rgba(108,140,255,0.4); color: var(--accent); background: rgba(108,140,255,0.06); }
  .flow-box.loss    { border-color: rgba(248,113,113,0.4); color: var(--red); background: rgba(248,113,113,0.06); }
  .flow-box.grad    { border-color: rgba(251,146,60,0.4); color: var(--orange); background: rgba(251,146,60,0.06); }
  .flow-box.param   { border-color: rgba(167,139,250,0.4); color: var(--purple); background: rgba(167,139,250,0.06); }
  .flow-box.green   { border-color: rgba(74,222,128,0.4); color: var(--green); background: rgba(74,222,128,0.06); }
  .flow-box.pink    { border-color: rgba(244,114,182,0.4); color: var(--pink); background: rgba(244,114,182,0.06); }
  .flow-box.yellow  { border-color: rgba(250,204,21,0.4); color: var(--yellow); background: rgba(250,204,21,0.06); }

  /* ── Live demo video ── */
  .live-demo-shell {
    width: 100%;
    max-width: var(--measure-lg);
    margin: var(--space-md) auto 0;
    border: 1px solid var(--border);
    border-radius: clamp(10px, 0.9vw, 14px);
    background: var(--surface2);
    overflow: hidden;
  }
  .live-demo-placeholder {
    min-height: clamp(240px, 26vh, 360px);
    display: flex;
    align-items: center;
    justify-content: center;
    flex-direction: column;
    gap: var(--space-sm);
    padding: clamp(16px, 1.3vw, 24px);
  }
  .live-demo-video {
    width: 100%;
    display: block;
    background: #000;
    max-height: clamp(320px, 48vh, 520px);
  }

  /* ── Interactive reveal ── */
  .reveal-btn {
    font-family: 'Inter', sans-serif;
    font-size: var(--font-body);
    font-weight: 600;
    padding: clamp(8px, 0.8vw, 12px) clamp(18px, 1.4vw, 30px);
    border-radius: clamp(8px, 0.8vw, 12px);
    border: 1px dashed var(--purple);
    background: rgba(167,139,250,0.08);
    color: var(--purple);
    cursor: pointer;
    transition: all 0.3s;
    margin-top: var(--space-xs);
  }
  .reveal-btn:hover { background: rgba(167,139,250,0.15); }
  .hidden-content {
    overflow: hidden;
    max-height: 0;
    opacity: 0;
    transition: max-height 0.6s ease, opacity 0.4s ease, margin 0.4s ease;
    margin-top: 0;
  }
  .hidden-content.revealed {
    max-height: 600px;
    opacity: 1;
    margin-top: var(--space-md);
  }

  /* ── NTP game ── */
  .ntp-sentence {
    font-family: 'JetBrains Mono', monospace;
    font-size: var(--font-mono);
    line-height: 1.7;
    padding: clamp(14px, 1.2vw, 22px) clamp(16px, 1.4vw, 26px);
    background: var(--surface2);
    border-radius: clamp(8px, 0.8vw, 12px);
    border: 1px solid var(--border);
    margin: var(--space-xs) 0;
  }
  .ntp-blank {
    display: inline-block;
    min-width: clamp(74px, 6vw, 108px);
    border-bottom: 2px dashed var(--orange);
    color: var(--orange);
    text-align: center;
    padding: 0 4px;
    cursor: pointer;
    transition: all 0.3s;
  }
  .ntp-blank.show {
    border-bottom-color: var(--green);
    color: var(--green);
    font-weight: 600;
  }
  .ntp-concept-btn {
    display: inline-block;
    margin-left: var(--space-xs);
    padding: 1px var(--space-xs);
    border-radius: 6px;
    border: 1px dashed var(--purple);
    color: var(--purple);
    font-size: clamp(0.64rem, 0.61rem + 0.1vw, 0.74rem);
    font-weight: 600;
    cursor: pointer;
    vertical-align: middle;
    transition: all 0.2s;
  }
  .ntp-concept-btn:hover { background: rgba(167,139,250,0.1); }
  .ntp-tag {
    display: inline-block;
    font-size: clamp(0.66rem, 0.63rem + 0.1vw, 0.76rem);
    font-weight: 600;
    padding: 2px var(--space-xs);
    border-radius: 6px;
    margin-left: var(--space-xs);
    vertical-align: middle;
    opacity: 0;
    transform: translateY(3px);
    transition: opacity 0.25s ease, transform 0.25s ease;
    pointer-events: none;
  }
  .ntp-tag.show { opacity: 1; transform: translateY(0); }
  .ntp-tag.fact  { background: rgba(34,211,238,0.15); color: var(--cyan); }
  .ntp-tag.logic { background: rgba(251,146,60,0.15); color: var(--orange); }
  .ntp-tag.code  { background: rgba(167,139,250,0.15); color: var(--purple); }
  .ntp-tag.lang  { background: rgba(108,140,255,0.15); color: var(--accent); }
  .ntp-tag.math  { background: rgba(250,204,21,0.15); color: var(--yellow); }

  /* ── Math formulas ── */
  .math {
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(0.94rem, 0.86rem + 0.24vw, 1.12rem);
    text-align: center;
    padding: clamp(12px, 1.1vw, 20px);
    background: var(--surface2);
    border-radius: clamp(8px, 0.8vw, 12px);
    margin: var(--space-sm) 0;
    color: var(--yellow);
    letter-spacing: 0.02em;
    line-height: 1.6;
  }
  .math-big { font-size: clamp(1.15rem, 1.02rem + 0.45vw, 1.5rem); padding: clamp(16px, 1.6vw, 28px); }

  /* ── Animated gradient line ── */
  .gradient-line {
    height: 2px;
    background: linear-gradient(90deg, var(--accent), var(--purple), var(--accent));
    background-size: 200% 100%;
    animation: shimmer 2s linear infinite;
    border-radius: 2px;
    margin: var(--space-xs) 0;
  }
  @keyframes shimmer {
    0%   { background-position: 200% 0; }
    100% { background-position: -200% 0; }
  }

  /* ── Token display ── */
  .token-row {
    display: flex;
    align-items: center;
    gap: clamp(4px, 0.45vw, 8px);
    flex-wrap: wrap;
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(0.96rem, 0.88rem + 0.3vw, 1.18rem);
    margin: var(--space-sm) 0;
  }
  .tok {
    display: inline-flex;
    align-items: center;
    padding: clamp(4px, 0.4vw, 7px) clamp(9px, 0.75vw, 14px);
    border-radius: clamp(6px, 0.6vw, 9px);
    background: var(--surface2);
    border: 1px solid var(--border);
    white-space: nowrap;
  }
  .tok.input  { border-color: var(--accent); background: rgba(108,140,255,0.1); }
  .tok.target { border-color: var(--green);  background: rgba(74,222,128,0.1); color: var(--green); font-weight: 600; }
  .tok.blank  { border: 2px dashed var(--orange); color: var(--orange); min-width: clamp(56px, 5vw, 84px); justify-content: center; cursor: pointer; }
  .tok.done   { border: 1px solid var(--text-dim); color: var(--text-dim); cursor: default; opacity: 0.5; }

  /* ── Pipeline boxes ── */
  .pipeline-box {
    padding: clamp(14px, 1.2vw, 24px);
    border-radius: clamp(10px, 0.9vw, 14px);
    border: 1px solid var(--border);
    background: var(--surface);
    position: relative;
  }
  .pipeline-box h3 { font-size: clamp(0.92rem, 0.86rem + 0.22vw, 1.08rem); margin-bottom: var(--space-2xs); }
  .pipeline-box .small-text { font-size: clamp(0.78rem, 0.73rem + 0.16vw, 0.9rem); }
  .pipeline-box .pipe-num {
    position: absolute;
    top: -10px; left: -10px;
    width: clamp(24px, 2vw, 30px); height: clamp(24px, 2vw, 30px);
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: clamp(0.7rem, 0.67rem + 0.1vw, 0.78rem);
    font-weight: 700;
    color: #fff;
  }

  /* ── Not-in-objective list ── */
  .not-list {
    display: flex;
    flex-wrap: wrap;
    gap: clamp(8px, 0.8vw, 14px);
    margin: var(--space-sm) 0;
  }
  .not-item {
    padding: clamp(7px, 0.65vw, 11px) clamp(12px, 1vw, 18px);
    border-radius: clamp(7px, 0.7vw, 10px);
    font-size: var(--font-body);
    font-weight: 500;
    background: rgba(248,113,113,0.06);
    border: 1px solid rgba(248,113,113,0.2);
    color: var(--red);
    position: relative;
    padding-left: clamp(26px, 2vw, 34px);
  }
  .not-item::before {
    content: '✕';
    position: absolute;
    left: clamp(8px, 0.7vw, 12px);
    top: 50%;
    transform: translateY(-50%);
    font-weight: 700;
    font-size: var(--font-tiny);
  }

  /* ── Data stats ── */
  .data-stat { text-align: center; padding: clamp(12px, 1vw, 18px); }
  .data-stat .big-num {
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(1.6rem, 1.2rem + 1vw, 2.3rem);
    font-weight: 700;
  }
  .data-stat .stat-label {
    font-size: clamp(0.72rem, 0.68rem + 0.15vw, 0.86rem);
    color: var(--text-dim);
    margin-top: var(--space-2xs);
  }

  /* ── Bar chart (for loss deep-dive slides) ── */
  .bar-row {
    display: flex;
    align-items: center;
    gap: clamp(8px, 0.7vw, 12px);
    margin-bottom: clamp(4px, 0.4vw, 8px);
    height: clamp(24px, 2vw, 30px);
  }
  .bar-word {
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(0.74rem, 0.7rem + 0.12vw, 0.84rem);
    width: clamp(64px, 5.8vw, 88px);
    text-align: right;
    color: var(--text-dim);
    flex-shrink: 0;
  }
  .bar-track {
    flex: 1;
    height: clamp(18px, 1.6vw, 24px);
    background: var(--surface2);
    border-radius: 6px;
    overflow: hidden;
  }
  .bar-fill {
    height: 100%;
    border-radius: 6px;
    transition: width 1s cubic-bezier(0.22, 1, 0.36, 1);
    min-width: 0;
  }
  .bar-fill.predicted { background: linear-gradient(90deg, var(--accent), var(--purple)); }
  .bar-fill.target-fill { background: linear-gradient(90deg, var(--green), #34d399); }
  .bar-pct {
    font-family: 'JetBrains Mono', monospace;
    font-size: var(--font-tiny);
    color: var(--text-dim);
    width: clamp(40px, 3.4vw, 54px);
    text-align: left;
    flex-shrink: 0;
  }

  /* dual chart layout */
  .dual-charts {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: clamp(12px, 1.2vw, 22px);
    margin-top: var(--space-xs);
  }
  @media (max-width: 640px) {
    .dual-charts { grid-template-columns: 1fr; }
  }
  .chart-col {
    background: var(--surface2);
    border-radius: clamp(8px, 0.8vw, 12px);
    padding: clamp(12px, 1vw, 18px);
  }
  .chart-title {
    font-size: var(--font-tiny);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    margin-bottom: var(--space-xs);
  }

  /* loss display */
  .loss-display {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: clamp(12px, 1.2vw, 22px);
    margin: var(--space-md) 0;
    flex-wrap: wrap;
  }
  .loss-box {
    text-align: center;
    padding: clamp(12px, 1vw, 18px) clamp(16px, 1.4vw, 26px);
    border-radius: clamp(10px, 0.9vw, 14px);
    background: var(--surface2);
    border: 1px solid var(--border);
    min-width: clamp(120px, 9.6vw, 156px);
  }
  .loss-box .label {
    font-size: clamp(0.66rem, 0.63rem + 0.1vw, 0.76rem);
    text-transform: uppercase;
    letter-spacing: 0.06em;
    color: var(--text-dim);
    margin-bottom: var(--space-2xs);
  }
  .loss-box .value {
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(1.2rem, 1.04rem + 0.5vw, 1.56rem);
    font-weight: 700;
  }
  .loss-box .value.high { color: var(--red); }
  .loss-box .value.low  { color: var(--green); }
  .loss-box .formula {
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(0.66rem, 0.63rem + 0.1vw, 0.76rem);
    color: var(--text-dim);
    margin-top: var(--space-2xs);
  }
  .comparison-arrow {
    font-size: clamp(1.6rem, 1.2rem + 0.95vw, 2.2rem);
    color: var(--text-dim);
    animation: pulseOpacity 1.5s ease-in-out infinite;
  }
  @keyframes pulseOpacity {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.3; }
  }

  /* loss meter */
  .loss-meter {
    width: 100%;
    height: 10px;
    border-radius: 6px;
    background: var(--surface2);
    margin: var(--space-xs) 0;
    overflow: hidden;
  }
  .loss-meter-fill {
    height: 100%;
    border-radius: 6px;
    transition: width 1.2s cubic-bezier(0.22, 1, 0.36, 1);
  }

  /* before / after */
  .before-after {
    display: grid;
    grid-template-columns: 1fr auto 1fr;
    gap: clamp(12px, 1vw, 20px);
    align-items: start;
    margin-top: var(--space-xs);
  }
  @media (max-width: 640px) {
    .before-after { grid-template-columns: 1fr; }
  }
  .ba-col {
    background: var(--surface2);
    border-radius: clamp(8px, 0.8vw, 12px);
    padding: clamp(12px, 1vw, 18px);
  }
  .ba-col .ba-label {
    font-size: var(--font-tiny);
    text-transform: uppercase;
    letter-spacing: 0.05em;
    font-weight: 600;
    margin-bottom: var(--space-xs);
  }
  .ba-col.before .ba-label { color: var(--red); }
  .ba-col.after  .ba-label { color: var(--green); }
  .ba-arrow {
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: clamp(1.5rem, 1.14rem + 0.86vw, 2.05rem);
    color: var(--text-dim);
    padding-top: clamp(24px, 3vh, 42px);
  }

  /* backprop arrows */
  .backprop-arrows {
    display: flex;
    justify-content: center;
    gap: var(--space-2xs);
    margin: var(--space-xs) 0;
    font-size: clamp(1.1rem, 0.98rem + 0.4vw, 1.4rem);
  }
  .backprop-arrows span {
    color: var(--orange);
    animation: flowLeft 1s ease-in-out infinite;
    animation-delay: 0.45s;
  }
  .backprop-arrows span:nth-child(2) { animation-delay: 0.30s; }
  .backprop-arrows span:nth-child(3) { animation-delay: 0.15s; }
  .backprop-arrows span:nth-child(4) { animation-delay: 0.0s; }
  @keyframes flowLeft {
    0%, 100% { opacity: 0.2; }
    50% { opacity: 1; }
  }

  /* flow node (for backprop) */
  .update-flow {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: clamp(8px, 0.8vw, 14px);
    margin: var(--space-sm) 0;
    flex-wrap: wrap;
  }
  .flow-node {
    padding: clamp(8px, 0.75vw, 12px) clamp(12px, 1vw, 20px);
    border-radius: clamp(8px, 0.8vw, 12px);
    font-size: clamp(0.78rem, 0.74rem + 0.16vw, 0.9rem);
    font-weight: 600;
    text-align: center;
    border: 1px solid var(--border);
  }
  .flow-node.loss-node   { background: rgba(248,113,113,0.1); border-color: rgba(248,113,113,0.3); color: var(--red); }
  .flow-node.grad-node   { background: rgba(251,146,60,0.1);  border-color: rgba(251,146,60,0.3);  color: var(--orange); }
  .flow-node.param-node  { background: rgba(167,139,250,0.1); border-color: rgba(167,139,250,0.3); color: var(--purple); }
  .flow-node.better-node { background: rgba(74,222,128,0.1);  border-color: rgba(74,222,128,0.3);  color: var(--green); }

  /* ── Bottom nav ── */
  .bottom-bar {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: clamp(8px, 0.8vw, 12px) clamp(14px, 1.8vw, 28px);
    background: var(--surface);
    border-top: 1px solid var(--border);
    z-index: 10;
    flex-shrink: 0;
  }
  .progress-track {
    flex: 1;
    height: 3px;
    background: var(--surface2);
    border-radius: 3px;
    margin: 0 clamp(10px, 1.2vw, 22px);
    overflow: hidden;
  }
  .progress-fill {
    height: 100%;
    background: linear-gradient(90deg, var(--accent), var(--purple));
    border-radius: 3px;
    transition: width 0.4s ease;
  }
  .nav-btn {
    font-family: 'Inter', sans-serif;
    font-size: clamp(0.78rem, 0.74rem + 0.16vw, 0.94rem);
    font-weight: 600;
    padding: clamp(7px, 0.7vw, 10px) clamp(16px, 1.2vw, 26px);
    border-radius: clamp(7px, 0.7vw, 10px);
    border: 1px solid var(--border);
    background: var(--surface2);
    color: var(--text);
    cursor: pointer;
    transition: all 0.2s;
    white-space: nowrap;
  }
  .nav-btn:hover { background: var(--border); }
  .nav-btn.primary { background: var(--accent); border-color: var(--accent); color: #fff; }
  .nav-btn.primary:hover { background: #5a7bef; }
  .nav-btn:disabled { opacity: 0.3; cursor: not-allowed; }
  .slide-counter {
    font-family: 'JetBrains Mono', monospace;
    font-size: var(--font-tiny);
    color: var(--text-dim);
    min-width: clamp(56px, 4.8vw, 78px);
    text-align: center;
  }

  /* ── Speaker notes ── */
  .speaker-notes { margin-top: auto; padding-top: var(--space-md); }
  .notes-toggle {
    font-family: 'Inter', sans-serif;
    font-size: var(--font-tiny);
    font-weight: 500;
    color: var(--text-dim);
    background: none;
    border: 1px solid var(--border);
    padding: var(--space-2xs) var(--space-sm);
    border-radius: clamp(6px, 0.55vw, 9px);
    cursor: pointer;
    transition: all 0.2s;
  }
  .notes-toggle:hover { background: var(--surface2); }
  .notes-body {
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.4s ease, opacity 0.3s ease;
    opacity: 0;
  }
  .notes-body.open {
    max-height: 400px;
    opacity: 1;
    margin-top: var(--space-xs);
  }
  .notes-body p {
    font-size: clamp(0.76rem, 0.72rem + 0.14vw, 0.88rem);
    color: var(--text-dim);
    line-height: 1.55;
    font-style: italic;
    padding: clamp(8px, 0.75vw, 12px) clamp(12px, 1vw, 18px);
    background: var(--surface2);
    border-radius: clamp(7px, 0.7vw, 10px);
    border-left: 3px solid var(--accent);
  }

  /* ── Spacers ── */
  .spacer-sm { height: var(--space-sm); }
  .spacer    { height: var(--space-lg); }
  .spacer-lg { height: var(--space-xl); }

  /* ── Objective list ── */
  .obj-list { list-style: none; margin: var(--space-xs) 0; }
  .obj-list li {
    padding: clamp(8px, 0.7vw, 12px) clamp(12px, 1vw, 18px) clamp(8px, 0.7vw, 12px) clamp(30px, 2.2vw, 38px);
    border-radius: clamp(7px, 0.7vw, 10px);
    margin-bottom: var(--space-xs);
    font-size: clamp(0.86rem, 0.81rem + 0.18vw, 0.98rem);
    line-height: 1.5;
    background: var(--surface2);
    border: 1px solid var(--border);
    position: relative;
  }
  .obj-list li::before {
    content: attr(data-num);
    position: absolute;
    left: clamp(8px, 0.7vw, 12px);
    top: clamp(8px, 0.7vw, 11px);
    font-family: 'JetBrains Mono', monospace;
    font-size: var(--font-tiny);
    font-weight: 700;
    color: var(--accent);
  }

  .loop-arrow-anim { animation: pulseGlow 1.5s ease-in-out infinite; }
  @keyframes pulseGlow { 0%, 100% { opacity: 0.5; } 50% { opacity: 1; } }

  .section-tag {
    position: absolute;
    top: clamp(12px, 1.3vh, 22px);
    left: clamp(18px, 1.8vw, 34px);
    font-size: clamp(0.66rem, 0.63rem + 0.1vw, 0.76rem);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.07em;
    color: var(--text-dim);
    opacity: 0.5;
  }

  /* network box (for forward-pass slide) */
  .network-box {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: clamp(10px, 0.9vw, 16px);
    padding: clamp(12px, 1.1vw, 20px) clamp(16px, 1.5vw, 28px);
    background: linear-gradient(135deg, rgba(108,140,255,0.08), rgba(167,139,250,0.08));
    border: 1px solid rgba(108,140,255,0.2);
    border-radius: clamp(10px, 0.9vw, 14px);
    margin: 0 auto;
    max-width: var(--measure-compact);
    position: relative;
  }
  .network-box .nn-label { font-weight: 600; font-size: clamp(0.84rem, 0.8rem + 0.16vw, 0.98rem); }
  .network-box .nn-sub   { font-size: var(--font-tiny); color: var(--text-dim); }
  .network-box .param-badge {
    position: absolute;
    top: -10px; right: -10px;
    font-size: clamp(0.62rem, 0.6rem + 0.08vw, 0.72rem);
    font-weight: 600;
    background: var(--purple);
    color: #fff;
    padding: 3px clamp(6px, 0.55vw, 10px);
    border-radius: 12px;
  }
  .arrow-down {
    text-align: center;
    color: var(--text-dim);
    font-size: clamp(1.2rem, 1rem + 0.5vw, 1.55rem);
    margin: var(--space-2xs) 0;
    animation: bobDown 1.2s ease-in-out infinite;
  }
  @keyframes bobDown { 0%, 100% { transform: translateY(0); } 50% { transform: translateY(5px); } }

  /* context row (for loss slides) */
  .context-row {
    display: flex;
    align-items: center;
    gap: clamp(4px, 0.4vw, 8px);
    flex-wrap: wrap;
    margin: var(--space-sm) 0 var(--space-2xs);
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(0.96rem, 0.88rem + 0.3vw, 1.18rem);
  }
  .ctx-tok {
    padding: clamp(4px, 0.4vw, 7px) clamp(9px, 0.75vw, 14px);
    border-radius: clamp(6px, 0.6vw, 9px);
    border: 1px solid var(--accent);
    background: rgba(108,140,255,0.1);
  }
  .ctx-blank {
    padding: clamp(4px, 0.4vw, 7px) clamp(9px, 0.75vw, 14px);
    border-radius: clamp(6px, 0.6vw, 9px);
    border: 2px dashed var(--orange);
    color: var(--orange);
    min-width: clamp(56px, 5vw, 84px);
    text-align: center;
    animation: pulseBorder 1.5s ease-in-out infinite;
  }
  @keyframes pulseBorder {
    0%, 100% { border-color: var(--orange); }
    50% { border-color: rgba(251,146,60,0.3); }
  }

  /* step label pill (for loss deep-dive slides) */
  .step-label {
    display: inline-block;
    font-size: clamp(0.66rem, 0.63rem + 0.1vw, 0.76rem);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    color: var(--yellow);
    background: rgba(250,204,21,0.1);
    padding: 3px clamp(8px, 0.65vw, 12px);
    border-radius: 20px;
    margin-bottom: var(--space-xs);
  }

  /* reasoning-emergence slides */
  .pressure-grid {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: clamp(10px, 0.9vw, 16px);
    max-width: var(--measure-xl);
    margin-top: var(--space-sm);
  }
  @media (max-width: 760px) {
    .pressure-grid { grid-template-columns: 1fr; }
  }
  .pressure-card {
    background: var(--surface2);
    border: 1px solid var(--border);
    border-radius: clamp(8px, 0.8vw, 12px);
    padding: clamp(12px, 1vw, 18px);
    opacity: 0.28;
    transform: translateY(8px);
    transition: opacity 0.35s ease, transform 0.35s ease, border-color 0.35s ease;
  }
  .pressure-grid.revealed .pressure-card {
    opacity: 1;
    transform: translateY(0);
    border-color: rgba(108,140,255,0.35);
  }
  .pressure-card .title {
    font-size: clamp(0.72rem, 0.69rem + 0.12vw, 0.84rem);
    text-transform: uppercase;
    letter-spacing: 0.06em;
    color: var(--accent);
    margin-bottom: var(--space-2xs);
    font-weight: 600;
  }
  .drama-script {
    font-family: 'JetBrains Mono', monospace;
    font-size: clamp(0.78rem, 0.74rem + 0.14vw, 0.92rem);
    line-height: 1.75;
    background: var(--surface2);
    border: 1px solid var(--border);
    border-radius: clamp(8px, 0.8vw, 12px);
    padding: clamp(12px, 1vw, 18px) clamp(14px, 1.2vw, 20px);
  }
  .drama-choices {
    display: flex;
    gap: clamp(8px, 0.8vw, 14px);
    flex-wrap: wrap;
    margin-top: var(--space-xs);
  }
  .drama-choice.correct {
    background: rgba(74,222,128,0.16);
    border-color: rgba(74,222,128,0.4);
    color: var(--green);
  }
  .drama-choice.wrong {
    background: rgba(248,113,113,0.13);
    border-color: rgba(248,113,113,0.35);
    color: var(--red);
  }

  .mjx-container {
    margin: 0 !important;
  }
  .math .mjx-container,
  .math-big .mjx-container {
    color: var(--yellow) !important;
  }
</style>
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['\\(', '\\)'], ['$', '$']],
      displayMath: [['\\[', '\\]']]
    },
    svg: { fontCache: 'global' }
  };
</script>
<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>

<div class="slide-container" id="slideContainer">

<!-- ═══════ SLIDE 0 — TITLE ═══════ -->
<div class="slide centered" id="slide-0">
  <div class="badge day1">Day 1</div>
  <h1 class="large">Language Modeling<br>from Scratch</h1>
  <div class="spacer-sm"></div>
  <p class="subtitle">How LLMs learn, what they compute, and what "data work" really means</p>
  <div class="spacer-lg"></div>
  <div class="gradient-line" style="width:200px;"></div>
</div>

<!-- ═══════ SLIDE 1 — OBJECTIVES ═══════ -->
<div class="slide" id="slide-1">
  <span class="section-tag">Day 1</span>
  <div class="badge day1">Objectives</div>
  <h2>By the end of today, you'll have a mental model of:</h2>
  <div class="spacer-sm"></div>
  <ul class="obj-list">
    <li data-num="1">What an LLM <span class="hl">computes at runtime</span> — tokens in, probability distribution out</li>
    <li data-num="2">Why <span class="hl-green">next-token training</span> can create complex capabilities</li>
    <li data-num="3">What <span class="hl-purple">"training an LLM"</span> concretely means: <span class="hl-cyan">data</span> → <span class="hl">pretrain</span> → <span class="hl-orange">post-train/alignment</span> → <span class="hl-green">eval</span></li>
    <li data-num="4">What <span class="hl-cyan">"data work"</span> actually entails — collection, cleaning, dedup, filtering, annotation</li>
  </ul>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>These four objectives are what we want every participant to walk away with. They don't need to implement a transformer — just hold the correct mental model.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 2 — OPENING ═══════ -->
<div class="slide" id="slide-2">
  <span class="section-tag">Opening</span>
  <div class="badge concept">Live Demo</div>
  <h2>Let's watch an LLM complete a sentence</h2>
  <div class="spacer-sm"></div>
  <p class="small-text" style="max-width:var(--measure-md);">We know why we're all here — understanding LLMs. So let's start by watching what actually happens when an LLM processes a simple sentence.</p>
  <div class="spacer"></div>
  <div class="card" style="text-align:center; max-width:var(--measure-md);">
    <p class="small-text" style="margin-bottom:var(--space-sm); color:var(--text-dim);">Full-Pipeline Animation (3 zoom levels)</p>
    <div class="live-demo-shell" id="liveDemoHost"
      data-video-relative="LanguageModelingPipeline.mp4"
      data-video-path="/home/maincoder/Documents/inside-LLM/manimations/media/videos/pipeline/1080p60/LanguageModelingPipeline.mp4">
      <div class="live-demo-placeholder">
        <button class="nav-btn primary" id="loadLiveDemoBtn" style="min-width:180px;">Load Demo Video</button>
        <p class="tiny">Large file is lazy-loaded only when this slide is opened.</p>
      </div>
    </div>
    <p class="tiny">Zoom level 1 → 2 → 3 (controls appear after load)</p>
  </div>
  <div class="spacer"></div>
  <div class="callout info">
    <span class="icon">i</span>
    <span><em>"Over two days, we'll reduce LLMs to a small set of operations: tokens become vectors, vectors undergo repeated structured transforms, and we end with a probability distribution over the next token. By the end you'll be able to trace a forward pass end-to-end, understand what each matrix multiplication is doing, and connect those mechanics to the model's behavior — both its strengths and its failure modes."</em></span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Play the pipeline animation video here. Let it run fully. Then use the framing quote to set the tone for the two-day workshop.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 3 — THREE INGREDIENTS ═══════ -->
<div class="slide" id="slide-3">
  <span class="section-tag">The Big Picture</span>
  <div class="badge discussion">Audience Interaction</div>
  <h2>LLMs have three ingredients</h2>
  <div class="spacer-sm"></div>
  <div class="grid-3" id="ingredientsGrid">
    <div class="card" style="text-align:center;">
      <div style="font-size:clamp(1.8rem, 1.45rem + 0.95vw, 2.45rem); margin-bottom:var(--space-xs);">1</div>
      <h3 style="color:var(--cyan);">Data</h3>
      <p class="small-text">What the model is exposed to — trillions of tokens from the internet, books, code, and more</p>
    </div>
    <div class="card" style="text-align:center;">
      <div style="font-size:clamp(1.8rem, 1.45rem + 0.95vw, 2.45rem); margin-bottom:var(--space-xs);">2</div>
      <h3 style="color:var(--accent);">Architecture</h3>
      <p class="small-text">The function class (Transformer) that maps input context → output logits</p>
    </div>
    <div class="card" style="text-align:center;" id="ingredient3Card">
      <div style="font-size:clamp(1.8rem, 1.45rem + 0.95vw, 2.45rem); margin-bottom:var(--space-xs);">3</div>
      <div id="ingredient3Hidden">
        <h3 style="color:var(--purple);">???</h3>
        <p class="small-text" style="color:var(--text-dim);">What's the missing ingredient?</p>
        <button class="reveal-btn" onclick="revealIngredient3()" style="margin-top:var(--space-sm);">Reveal</button>
      </div>
      <div id="ingredient3Revealed" style="display:none;">
        <h3 style="color:var(--purple);">Learning</h3>
        <p class="small-text">The <span class="hl-yellow">objective</span> (next-token prediction), the <span class="hl-orange">optimizer</span> (Adam), and the <span class="hl-purple">compute budget</span> that makes it feasible</p>
      </div>
    </div>
  </div>
  <div class="hidden-content" id="ingredientExplanation">
    <div class="callout info">
      <span class="icon">i</span>
      <span><strong>Learning</strong> means three things: (1) the <span class="hl-yellow">objective we train on</span> — e.g., next-token prediction using cross-entropy loss, (2) the <span class="hl-orange">optimization process</span> — SGD/Adam variants, learning rate schedules, and (3) the <span class="hl-purple">compute budget</span> — thousands of GPUs for weeks.</span>
    </div>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Ask the audience: "What's the missing ingredient besides data and architecture?" Let them discuss for 30s. Then click reveal.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 4 — WORKSHOP ROADMAP ═══════ -->
<div class="slide" id="slide-4">
  <span class="section-tag">Roadmap</span>
  <div class="badge day1">Structure</div>
  <h2>Workshop roadmap</h2>
  <div class="spacer-sm"></div>
  <div class="grid-2">
    <div class="card" style="border-color: rgba(108,140,255,0.3);">
      <div class="badge day1">Day 1 — Today</div>
      <h3 style="color:var(--accent);">How learning happens + data quality</h3>
      <ul style="list-style:none; margin-top:var(--space-xs);">
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--accent);">→</span> Inference vs. training</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--accent);">→</span> Next-token prediction objective</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--accent);">→</span> Loss, gradients, parameter updates</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--accent);">→</span> Why NTP works (interactive)</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--accent);">→</span> The full training pipeline</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--accent);">→</span> Data work: collection → annotation</li>
      </ul>
    </div>
    <div class="card" style="border-color: rgba(167,139,250,0.25); opacity:0.6;">
      <div class="badge concept">Day 2 — Tomorrow</div>
      <h3 style="color:var(--purple);">What the model computes internally</h3>
      <ul style="list-style:none; margin-top:var(--space-xs);">
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--purple);">→</span> Tokenization & embeddings</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--purple);">→</span> Self-attention mechanics</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--purple);">→</span> Feed-forward layers</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--purple);">→</span> Full forward pass end-to-end</li>
        <li class="small-text" style="padding:var(--space-2xs) 0 var(--space-2xs) clamp(16px, 1.4vw, 24px); position:relative;"><span style="position:absolute;left:0;color:var(--purple);">→</span> Connecting mechanics to behavior</li>
      </ul>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout info">
    <span class="icon">i</span>
    <span><strong>Day 1 = why the weights end up where they are.</strong> Day 2 = what those weights actually do to your input.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"You just saw inference: a sentence goes in, a next-token distribution comes out, we sample, repeat. But none of that is useful unless the weights have been fit. So the workshop splits cleanly."</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 5 — INFERENCE LOOP ═══════ -->
<div class="slide" id="slide-5">
  <span class="section-tag">Inference vs Training</span>
  <div class="badge concept">Concept</div>
  <h2>The inference (use-time) loop</h2>
  <p class="small-text" style="max-width:var(--measure-md);">At inference, the model does a simple repeated cycle: read context, predict next token, append, repeat. No learning happens — weights are frozen.</p>
  <div class="spacer"></div>
  <div class="card" style="max-width:var(--measure-lg); margin: 0 auto;">
    <div class="flow">
      <div class="flow-box data">Context<br>tokens</div>
      <div class="flow-arrow loop-arrow-anim">→</div>
      <div class="flow-box model">Model<br><span class="tiny">(frozen weights)</span></div>
      <div class="flow-arrow loop-arrow-anim">→</div>
      <div class="flow-box yellow">Logits</div>
      <div class="flow-arrow loop-arrow-anim">→</div>
      <div class="flow-box pink">Softmax</div>
      <div class="flow-arrow loop-arrow-anim">→</div>
      <div class="flow-box green">Sample<br>next token</div>
    </div>
    <div style="text-align:center; margin-top:var(--space-xs);">
      <span class="tiny" style="color:var(--orange);">↻ append token to context and repeat</span>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="token-row" id="inferenceDemo">
    <span class="tok input">The</span>
    <span class="tok input">capital</span>
    <span class="tok input">of</span>
    <span class="tok input">Pakistan</span>
    <span class="tok input">is</span>
    <span class="tok blank" id="infCurrent" onclick="animateInference()">click</span>
  </div>
  <p class="tiny" id="infHint">Click the blank to simulate one inference step</p>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"You already saw the inference loop in the animation: it's a repeated forward pass. The model reads all context tokens, produces a probability distribution, we sample from it, append the result, and go again. Crucially: no weights change during inference."</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 6 — TRAINING LOOP ═══════ -->
<div class="slide" id="slide-6">
  <span class="section-tag">Inference vs Training</span>
  <div class="badge concept">Concept</div>
  <h2>The training (learning) loop</h2>
  <p class="small-text" style="max-width:var(--measure-md);">Training uses <span class="hl-yellow">teacher forcing</span>: for each sequence, inputs are <span class="hl">\(x_{1:T-1}\)</span> and targets are the same sequence shifted by one token <span class="hl-green">\(x_{2:T}\)</span>. We compute loss at every position, backpropagate, then update weights once per mini-batch.</p>
  <div class="spacer"></div>
  <div class="card" style="max-width:var(--measure-xxl); margin:0 auto;">
    <div class="flow">
      <div class="flow-box data">Mini-batch<br>token sequences</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box model">Causal LM forward<br><span class="tiny">(masked self-attention)</span></div>
      <div class="flow-arrow">→</div>
      <div class="flow-box yellow">Logits at<br>each position</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box loss">Cross-entropy vs<br>shifted targets</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box grad">Backpropagate<br>gradients</div>
      <div class="flow-arrow">→</div>
      <div class="flow-box param">AdamW step<br>update \(\theta\)</div>
    </div>
    <div style="text-align:center; margin-top:var(--space-xs);">
      <span class="tiny" style="color:var(--orange);">↻ repeat over many mini-batches for many epochs/tokens</span>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="grid-3" style="max-width:var(--measure-xxl);">
    <div class="callout info" style="margin:0;"><span class="icon">1</span><span><strong>Inputs/targets:</strong> predict token <em>t+1</em> from prefix up to <em>t</em> at every position</span></div>
    <div class="callout warn" style="margin:0;"><span class="icon">2</span><span><strong>Optimization unit:</strong> gradients from the whole mini-batch are aggregated before one optimizer step</span></div>
    <div class="callout success" style="margin:0;"><span class="icon">3</span><span><strong>Core difference vs inference:</strong> only training runs backward pass + parameter updates</span></div>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"Be precise here: training is next-token prediction at every position in a batch, with shifted labels. Loss is averaged, gradients are backpropagated, and then the optimizer updates parameters once per batch."</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 7 — PRETRAINING OBJECTIVE ═══════ -->
<div class="slide" id="slide-7">
  <span class="section-tag">Pretraining</span>
  <div class="badge concept">Core Concept</div>
  <h2>The pretraining objective</h2>
  <p class="small-text" style="max-width:var(--measure-md);">Now that we've separated inference from training, we can state the exact learning objective: for each position, the model sees the prefix and predicts the next token.</p>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:var(--measure-lg);">
    <p class="small-text" style="margin-bottom:var(--space-xs);">Given a sequence <span class="hl">\(x_1, x_2, \ldots, x_T\)</span>, for each position <span class="hl">\(t\)</span>:</p>
    <div class="token-row" style="font-size:clamp(0.88rem, 0.84rem + 0.15vw, 1.02rem);">
      <span class="tok input">\(x_1\)</span>
      <span class="tok input">\(x_2\)</span>
      <span class="tok input" style="color:var(--text-dim);">...</span>
      <span class="tok input">\(x_{t-1}\)</span>
      <span class="tok blank" style="font-size:var(--font-body); cursor:default;">\(x_t = ?\)</span>
    </div>
    <p class="tiny" style="margin-top:var(--space-2xs);">Model sees prefix \(x_{<t}\) and produces \(P(x_t \mid x_{<t})\) over the entire vocabulary</p>
  </div>
  <div class="spacer-sm"></div>
  <div class="math math-big">
    \[
      \mathcal{L} = -\frac{1}{T}\sum_{t=1}^{T}\log P_{\theta}(x_t \mid x_{<t})
    \]
  </div>
  <p class="tiny" style="text-align:center;">Cross-entropy loss = negative log-likelihood of the correct next token, averaged over all positions</p>
  <div class="spacer"></div>
  <div class="callout warn">
    <span class="icon">!</span>
    <span><strong>Key insight:</strong> This is <span class="hl-orange">distribution-matching</span>, not decision-making. The model is trained to shape its probability distribution to match the empirical distribution of text.</span>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout info">
    <span class="icon">→</span>
    <span><strong>Transition:</strong> Let's jump in and take a deeper dive into <em>one training iteration</em>, step by step.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"The loss is the negative log-probability assigned to the actual next token from the dataset. That's it. If the model assigns high probability to the observed token, the loss is low; if low probability, the loss is high."</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 8 — WHAT'S NOT IN THE LOSS ═══════ -->
<div class="slide" id="slide-8">
  <span class="section-tag">Pretraining</span>
  <div class="badge concept">Critical Point</div>
  <h2>What the loss does <em>not</em> contain</h2>
  <p class="small-text" style="max-width:var(--measure-md);">After tracing one full iteration, notice what supervision signal the model actually receives. Pretraining has no explicit term for any of these; if they emerge, they must be <em>instrumentally useful for predicting text</em>.</p>
  <div class="spacer"></div>
  <div class="not-list">
    <div class="not-item">Truth</div>
    <div class="not-item">Reasoning</div>
    <div class="not-item">Helpfulness</div>
    <div class="not-item">Safety</div>
    <div class="not-item">Intelligence</div>
    <div class="not-item">Goals</div>
    <div class="not-item">World model</div>
    <div class="not-item">Consistency</div>
  </div>
  <div class="spacer-sm"></div>
  <div class="math">
    \[
      \mathcal{L} = -\log P_{\theta}(x_t \mid x_{<t})
    \]
    <span style="color:var(--text-dim); font-size:var(--font-body);">that's the ENTIRE signal</span>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success">
    <span class="icon">i</span>
    <span><strong>The narrow bottleneck:</strong> Everything the model learns has to pass through this single constraint — lowering next-token prediction error. This explains both <span class="hl-green">emergence</span> and <span class="hl-red">brittleness</span>.</span>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout question">
    <span class="icon">?</span>
    <span><strong>Think about it:</strong> Why would a model learn facts, reasoning, or code from only this signal? Next we'll zoom back out from one step to the full repeated training loop.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"There are no terms here for truth, reasoning, helpfulness, safety, goals, or intelligence. Everything the model learns has to pass through this very narrow bottleneck — lowering next-token prediction error."</p></div>
  </div>
</div>

<!-- ═══════════════════════════════════════════════════ -->
<!--  SLIDES 9–14 : NEXT-TOKEN LOSS DEEP DIVE          -->
<!--  (embedded from next-token-loss.html)              -->
<!-- ═══════════════════════════════════════════════════ -->

<!-- ═══════ SLIDE 9 — THE TASK ═══════ -->
<div class="slide" id="slide-9">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 1 — The Task</div>
  <h2>Predict the next token</h2>
  <p class="small-text" style="max-width:var(--measure-md);">Let's jump in and take a deeper dive into one training iteration. We'll trace one concrete example from input context to parameter update.</p>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:var(--measure-md);">
    <div class="context-row">
      <span class="ctx-tok">"The</span>
      <span class="ctx-tok">capital</span>
      <span class="ctx-tok">of</span>
      <span class="ctx-tok">Pakistan</span>
      <span class="ctx-tok">is</span>
      <span class="ctx-blank">???</span>
    </div>
    <div class="spacer-sm"></div>
    <div class="callout info" style="margin:0;">
      <span class="icon">i</span>
      <span>The model receives <span class="hl">input context tokens</span> and must produce a probability for <em>every word in its vocabulary</em> as the next token. The training data already contains the answer — we just hide it and ask the model to guess.</span>
    </div>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Set up the concrete example. This is one single training step — we'll trace it all the way through loss computation to parameter update.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 10 — FORWARD PASS ═══════ -->
<div class="slide" id="slide-10">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 2 — Forward Pass</div>
  <h2>The model outputs a probability distribution</h2>
  <p class="small-text" style="max-width:var(--measure-md);">The input tokens flow through billions of parameters — attention layers, feed-forward networks — and out comes a <span class="hl">probability distribution over the entire vocabulary</span>.</p>

  <div class="spacer-sm"></div>
  <div style="max-width:var(--measure-md);">
    <div class="context-row" style="justify-content:center;">
      <span class="ctx-tok">"The</span>
      <span class="ctx-tok">capital</span>
      <span class="ctx-tok">of</span>
      <span class="ctx-tok">Pakistan</span>
      <span class="ctx-tok">is</span>
    </div>
    <div class="arrow-down">↓</div>
    <div class="network-box">
      <div>
        <div class="nn-label">Transformer</div>
        <div class="nn-sub">attention + FFN layers</div>
      </div>
      <span class="param-badge">\(\sim 7\,\mathrm{B}\) params</span>
    </div>
    <div class="arrow-down">↓</div>
    <div class="chart-title" style="color:var(--text-dim); margin-top:var(--space-xs);">Model's predicted distribution (softmax output)</div>
    <div id="predictedChart"></div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout info" style="max-width:var(--measure-md);">
    <span class="icon">i</span>
    <span>The final layer outputs a <span class="hl">logit</span> for each vocabulary token, then <span class="hl">softmax</span> converts these to probabilities that sum to 1. An untrained model spreads probability almost evenly — basically guessing randomly.</span>
  </div>
</div>

<!-- ═══════ SLIDE 11 — TARGET DISTRIBUTION ═══════ -->
<div class="slide" id="slide-11">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 3 — The Target</div>
  <h2>What the model <em>should</em> have predicted</h2>
  <p class="small-text" style="max-width:var(--measure-md);">We know the correct next token from the training data. The <span class="hl-green">target distribution</span> puts \(100\%\) probability on the correct answer.</p>
  <div class="spacer-sm"></div>
  <div class="dual-charts" style="max-width:var(--measure-lg);">
    <div class="chart-col">
      <div class="chart-title" style="color:var(--accent);">Model's prediction</div>
      <div id="dualPredicted"></div>
    </div>
    <div class="chart-col">
      <div class="chart-title" style="color:var(--green);">Target (ground truth)</div>
      <div id="dualTarget"></div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout warn" style="max-width:var(--measure-lg);">
    <span class="icon">!</span>
    <span>The model only gave <span class="hl" id="correctPctText">\(8\%\)</span> to <span class="hl-green">"Islamabad"</span>, but the target says it should be <span class="hl-green">\(100\%\)</span>. That gap is what the <span class="hl-red">loss function</span> measures.</span>
  </div>
</div>

<!-- ═══════ SLIDE 12 — LOSS COMPUTATION ═══════ -->
<div class="slide" id="slide-12">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 4 — Compute the Loss</div>
  <h2>Cross-entropy loss: how wrong is the model?</h2>
  <p class="small-text" style="max-width:var(--measure-md);">The loss measures the gap between prediction and target. For next-token prediction, we use <span class="hl-yellow">cross-entropy loss</span>.</p>
  <div class="spacer-sm"></div>
  <div class="math math-big" style="max-width:var(--measure-md);" id="lossFormula">
    \[
      \mathcal{L} = -\log\!\left(P_{\text{model}}(\text{Islamabad})\right) = -\log(0.08) = 2.53
    \]
  </div>
  <div class="loss-display">
    <div class="loss-box">
      <div class="label">\(P(\text{Islamabad})\)</div>
      <div class="value high" id="lossProbDisplay">\(0.08\)</div>
    </div>
    <div class="comparison-arrow">→</div>
    <div class="loss-box">
      <div class="label">Loss</div>
      <div class="value high" id="lossValueDisplay">\(2.53\)</div>
      <div class="formula">\(-\log(p)\)</div>
    </div>
  </div>
  <div style="max-width:var(--measure-xs); margin:0 auto;">
    <div style="display:flex; justify-content:space-between; font-size:var(--font-tiny); color:var(--text-dim); margin-bottom:var(--space-2xs);">
      <span class="hl-green">low loss (good)</span>
      <span class="hl-red">high loss (bad)</span>
    </div>
    <div class="loss-meter">
      <div class="loss-meter-fill" id="lossMeter" style="width:0%; background: linear-gradient(90deg, var(--green), var(--yellow), var(--red));"></div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout info" style="max-width:var(--measure-md);">
    <span class="icon">i</span>
    <span><span class="hl-yellow">Intuition:</span> if the model gave \(100\%\) to "Islamabad", \(\mathcal{L}=-\log(1)=0\) (perfect). If only \(1\%\), \(\mathcal{L}=-\log(0.01)\approx 4.6\) (terrible). The loss captures "how surprised the model is by the right answer."</span>
  </div>
</div>

<!-- ═══════ SLIDE 13 — BACKPROPAGATION ═══════ -->
<div class="slide" id="slide-13">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 5 — Backpropagation</div>
  <h2>Compute gradients and update parameters</h2>
  <p class="small-text" style="max-width:var(--measure-md);">The loss signal flows <em>backwards</em> through the network. For each parameter, we compute: "how much would changing this parameter reduce the loss?" Then we nudge every parameter in that direction.</p>
  <div class="spacer-sm"></div>
  <div class="update-flow">
    <div class="flow-node loss-node">\(\mathcal{L}=2.53\)</div>
    <div class="flow-arrow">→</div>
    <div class="flow-node grad-node">\(\frac{\partial \mathcal{L}}{\partial \theta}\)<br><small>compute gradients</small></div>
    <div class="flow-arrow">→</div>
    <div class="flow-node param-node">\(\theta \leftarrow \theta - \eta \nabla_{\theta}\mathcal{L}\)<br><small>update params</small></div>
  </div>
  <div class="backprop-arrows">
    <span>◂</span><span>◂</span><span>◂</span><span>◂</span>
    <span style="font-size:clamp(0.76rem, 0.72rem + 0.14vw, 0.9rem); color:var(--text-dim); animation:none; margin-left:var(--space-2xs);">gradients flow backward</span>
  </div>
  <div class="math" style="max-width:var(--measure-sm); margin:var(--space-xs) auto;">
    \[
      \theta_{\text{new}} = \theta_{\text{old}} - \eta \frac{\partial \mathcal{L}}{\partial \theta}
    \]
  </div>
  <div class="callout info" style="max-width:var(--measure-md);">
    <span class="icon">i</span>
    <span><span class="hl-purple">\(\eta\) (eta)</span> is the <strong>learning rate</strong> — a small number (e.g., \(10^{-4}\)) that controls step size. The <span class="hl-orange">gradient \(\frac{\partial \mathcal{L}}{\partial \theta}\)</span> tells us the direction and magnitude of adjustment needed for each of the billions of parameters.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>"This is the part that actually makes learning happen. The gradient is a vector pointing in the direction of steepest increase of the loss — so we go the opposite direction to decrease it."</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 14 — AFTER UPDATE ═══════ -->
<div class="slide" id="slide-14">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">Step 6 — After Update</div>
  <h2>The model improves!</h2>
  <p class="small-text" style="max-width:var(--measure-md);">That completes one training iteration: after the update, the model assigns <em>more</em> probability to the correct token. Repeating this loop at scale is how the model learns language.</p>
  <div class="spacer-sm"></div>
  <div class="before-after" style="max-width:var(--measure-lg);">
    <div class="ba-col before">
      <div class="ba-label">Before update</div>
      <div id="beforeBars"></div>
    </div>
    <div class="ba-arrow">→</div>
    <div class="ba-col after">
      <div class="ba-label">After update</div>
      <div id="afterBars"></div>
    </div>
  </div>
  <div class="loss-display">
    <div class="loss-box">
      <div class="label">Loss before</div>
      <div class="value high">2.53</div>
    </div>
    <div class="comparison-arrow">→</div>
    <div class="loss-box">
      <div class="label">Loss after</div>
      <div class="value low" id="lossAfterVal">\(1.27\)</div>
    </div>
  </div>
  <div class="callout success" style="max-width:var(--measure-lg);">
    <span class="icon">✓</span>
    <span>The model now assigns <span class="hl-green" id="afterCorrectPct">\(28\%\)</span> to "Islamabad" (up from <span class="hl-red">\(8\%\)</span>). The loss dropped from <span class="hl-red">\(2.53\)</span> to <span class="hl-green" id="afterLossText">\(1.27\)</span>. After many more steps, the model will learn to confidently predict "Islamabad" — and generalize to countless other facts.</span>
  </div>
</div>

<!-- ═══════ SLIDE 15 — BIG PICTURE (training loop) ═══════ -->
<div class="slide" id="slide-15">
  <span class="section-tag">Deep Dive</span>
  <div class="badge deepdive">The Big Picture</div>
  <h2>Training = repeating this loop trillions of times</h2>
  <p class="small-text" style="max-width:var(--measure-md);">We just traced one iteration in detail. Real training is exactly that same loop repeated over massive batches and datasets, until the parameters encode useful predictive structure.</p>
  <div class="spacer"></div>
  <div class="update-flow" style="gap:var(--space-sm);">
    <div class="flow-box model">Input tokens</div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box param">Forward pass</div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box model">Predicted dist.</div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box loss">Loss</div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box grad">Gradients</div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box green">Update \(\theta\)</div>
  </div>
  <div class="gradient-line"></div>
  <div class="grid-3" style="margin-top:var(--space-sm);">
    <div class="callout info" style="margin:0;"><span><strong>Dataset:</strong> trillions of tokens from books, web, code…</span></div>
    <div class="callout info" style="margin:0;"><span><strong>Steps:</strong> millions of gradient updates</span></div>
    <div class="callout info" style="margin:0;"><span><strong>Result:</strong> a model that can predict (and generate) fluent text</span></div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success">
    <span class="icon">✓</span>
    <span><strong>Key insight:</strong> The entire capability of an LLM — writing code, answering questions, reasoning — emerges from this loop: <em>predict the next token, measure error, update, repeat.</em> Next, let's make that pressure concrete.</span>
  </div>
</div>

<!-- ═══════ SLIDE 22 — LOCAL OBJECTIVE, GLOBAL PRESSURE ═══════ -->
<div class="slide" id="slide-22">
  <span class="section-tag">Reasoning Emergence</span>
  <div class="badge concept">Key Idea</div>
  <h2>Why next-token prediction can produce reasoning-like behavior</h2>
  <p class="small-text" style="max-width:var(--measure-lg);"><strong>Local objective, global pressure:</strong> the training signal is local (predict one token), but minimizing that error often requires building global structure over the context.</p>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:var(--measure-xl);">
    <div class="math" style="margin:0;">
      \[
        \max_{\theta}\; P(x_t \mid x_{<t}) \quad \text{for each token position}
      \]
    </div>
    <div class="spacer-sm"></div>
    <button class="reveal-btn" onclick="revealReasoningPressure()">Reveal what the model often must infer</button>
    <div class="pressure-grid" id="reasoningPressureGrid">
      <div class="pressure-card">
        <div class="title">Entities</div>
        <p class="small-text">Who or what is being discussed, and how references resolve across sentences.</p>
      </div>
      <div class="pressure-card">
        <div class="title">Causal Cues</div>
        <p class="small-text">What caused what, and which events enable or block later outcomes.</p>
      </div>
      <div class="pressure-card">
        <div class="title">Constraints</div>
        <p class="small-text">What is consistent or impossible given timing, access, and prior facts.</p>
      </div>
      <div class="pressure-card">
        <div class="title">Multi-step Structure</div>
        <p class="small-text">What comes next in a plan, argument, proof, or narrative arc.</p>
      </div>
    </div>
  </div>
  <div class="hidden-content" id="reasoningEmergenceQuote">
    <div class="callout success" style="max-width:var(--measure-xl);">
      <span class="icon">i</span>
      <span><strong>So "reasoning" can emerge as an instrumentally useful strategy for reducing prediction error,</strong> even when it is never explicitly specified as a training target.</span>
    </div>
  </div>
</div>

<!-- ═══════ SLIDE 23 — PAKISTANI DRAMA EXAMPLE ═══════ -->
<div class="slide" id="slide-23">
  <span class="section-tag">Reasoning Emergence</span>
  <div class="badge discussion">Interactive Example</div>
  <h2>Next-token prediction in a Pakistani drama</h2>
  <p class="small-text" style="max-width:var(--measure-xl);">Nothing explicitly states the answer. To predict the next words, the model must integrate distributed constraints.</p>
  <div class="spacer-sm"></div>
  <div class="drama-script" style="max-width:var(--measure-xl);">
    Karachi mein aik shaam...<br>
    10:30 baje Shahbaz Ahmed apne office mein be-harkat mila...<br>
    thori dair baad pata chala ke maut ki wajah zehr tha...<br>
    Us waqt office mein sirf teen log thay...<br>
    Farah, jo us ki secretary thi...<br>
    Salman, jo us ka business partner tha...<br>
    aur Rukhsana, jo safai karti thi...<br>
    Farah 9:50 baje office se nikal chuki thi...<br>
    Salman 10:00 baje meeting ke liye bahar gaya...<br>
    10:20 baje Rukhsana ne Shahbaz ke liye chai banayi...<br>
    Forensic report ke mutabiq zehr 10:20 aur 10:30 ke darmiyan liya gaya...<br>
    CCTV se yeh bhi clear hua ke 10:00 ke baad sirf aik shakhs pantry mein gaya...<br>
    ...<br>
    Investigation ke baad shahbaz ki family ne police walon se pucha keh qatil kon tha.<br>
    Police ne btaya keh tamaam subuton ke mutabik qatil <span class="ntp-blank" id="dramaKillerBlank" data-answer="Rukhsana thi">___</span>
  </div>
  <div class="drama-choices" id="dramaChoices">
    <button class="nav-btn drama-choice" onclick="chooseDramaSuspect('Farah', this)">Farah</button>
    <button class="nav-btn drama-choice" onclick="chooseDramaSuspect('Salman', this)">Salman</button>
    <button class="nav-btn drama-choice" onclick="chooseDramaSuspect('Rukhsana', this)">Rukhsana</button>
    <button class="nav-btn" onclick="revealDramaAnswer()">Reveal token</button>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout warn" id="dramaResult" style="max-width:var(--measure-xl);">
    <span class="icon">?</span>
    <span>Select a suspect. Then check whether your choice satisfies the timing + access constraints.</span>
  </div>
  <div class="hidden-content" id="dramaWhy">
    <div class="callout info" style="max-width:var(--measure-xl);">
      <span class="icon">i</span>
      <span><strong>Notice:</strong> no line explicitly says "Rukhsana qatil hai." The required information is distributed across the text. Correct next-token prediction requires integrating entity tracking, timing, access, and consistency constraints introduced earlier.</span>
    </div>
    <div class="callout success" style="max-width:var(--measure-xl); margin-top:var(--space-xs);">
      <span class="icon">→</span>
      <span><strong>That pressure is exactly what next-token prediction creates during training.</strong></span>
    </div>
  </div>
</div>

<!-- ═══════ SLIDE 24 — LOCAL OBJECTIVE TO GLOBAL STRUCTURE ═══════ -->
<div class="slide" id="slide-24">
  <span class="section-tag">Reasoning Emergence</span>
  <div class="badge concept">Synthesis</div>
  <h2>Why a local objective creates global structure</h2>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:var(--measure-xl);">
    <div class="card">
      <h3 style="color:var(--accent);">Local objective</h3>
      <div class="math" style="margin:var(--space-xs) 0 0;">
        Predict the next token
      </div>
      <p class="tiny" style="margin-top:var(--space-xs);">The training signal never says "identify the killer" or "reason explicitly."</p>
    </div>
    <div class="card">
      <h3 style="color:var(--green);">To do that reliably, infer:</h3>
      <ul class="obj-list" style="margin-top:var(--space-xs);">
        <li data-num="1">entities (who is who)</li>
        <li data-num="2">state (who was where, and when)</li>
        <li data-num="3">causality (what enables what)</li>
        <li data-num="4">constraints (what is impossible)</li>
        <li data-num="5">narrative consistency</li>
      </ul>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success" style="max-width:var(--measure-xl);">
    <span class="icon">✓</span>
    <span><strong>Result:</strong> reasoning-like behavior emerges as a <em>means</em>, not a goal.</span>
  </div>
  <div class="callout info" style="max-width:var(--measure-xl);">
    <span class="icon">i</span>
    <span>In narratives, plans, arguments, and code, accurate next-token prediction often demands internal representations of entities, state, and constraints. So reasoning is not trained directly; it is instrumentally useful for prediction.</span>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Close this segment by emphasizing mechanism over mystique: the objective is local, but the easiest way to minimize it across long contexts is to build useful global structure.</p></div>
  </div>
</div>

<!-- ═══════════════════════════════════════════════ -->
<!--  BACK TO MAIN PRESENTATION FLOW               -->
<!-- ═══════════════════════════════════════════════ -->

<!-- ═══════ SLIDE 16 — YOU ARE THE LANGUAGE MODEL ═══════ -->
<div class="slide" id="slide-16">
  <span class="section-tag">Activity</span>
  <div class="badge activity">Interactive Activity</div>
  <h2>You Are the Language Model</h2>
  <p class="small-text" style="max-width:var(--measure-md);">Now you run the same objective yourself: predict the next token. Notice what <em>kind of knowledge</em> each example requires. This is why next-token training yields more than memorization.</p>
  <div class="spacer-sm"></div>
  <div style="display:flex; flex-direction:column; gap:var(--space-sm); max-width:var(--measure-xl);" id="ntpGame">
    <div class="ntp-sentence">
      The Eiffel Tower is located in <span class="ntp-blank" onclick="revealNTP(this)" data-answer="Paris">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag fact">world knowledge</span>
    </div>
    <div class="ntp-sentence">
      After the rain stopped, the children ran outside to <span class="ntp-blank" onclick="revealNTP(this)" data-answer="play">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag lang">language / common sense</span>
    </div>
    <div class="ntp-sentence">
      def fibonacci(n):<br>&nbsp;&nbsp;if n <= 1: return n<br>&nbsp;&nbsp;return fibonacci(n-1) + <span class="ntp-blank" onclick="revealNTP(this)" data-answer="fibonacci(n-2)">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag code">code understanding</span>
    </div>
    <div class="ntp-sentence">
      If all roses are flowers, and all flowers need water, then all roses need <span class="ntp-blank" onclick="revealNTP(this)" data-answer="water">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag logic">logical reasoning</span>
    </div>
    <div class="ntp-sentence">
      The sum of 127 and 385 is <span class="ntp-blank" onclick="revealNTP(this)" data-answer="512">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag math">arithmetic</span>
    </div>
    <div class="ntp-sentence">
      She said "I'm not angry," but the tone of her voice suggested she was actually quite <span class="ntp-blank" onclick="revealNTP(this)" data-answer="upset">???</span>
      <span class="ntp-concept-btn" onclick="revealNTPConcept(this)">concept?</span>
      <span class="ntp-tag lang">pragmatics / subtext</span>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <button class="reveal-btn" onclick="revealAllNTP()">Reveal all answers</button>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Let participants think about each one before clicking. The point: "just predicting the next word" requires world knowledge, code understanding, logic, arithmetic, pragmatics. To predict well, you must understand deeply.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 17 — WHY NTP WORKS ═══════ -->
<div class="slide" id="slide-17">
  <span class="section-tag">Activity</span>
  <div class="badge concept">Key Takeaway</div>
  <h2>Why next-token prediction creates capable models</h2>
  <div class="spacer-sm"></div>
  <div class="card" style="max-width:var(--measure-lg);">
    <p class="small-text" style="line-height:1.7;">To predict the next token <em>well</em> across all of internet text, the model must develop internal representations of:</p>
    <div class="spacer-sm"></div>
    <div class="grid-3" style="gap:var(--space-sm);">
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center;">
        <strong style="color:var(--cyan);">Facts</strong>
        <span class="tiny">"The capital of Pakistan is <strong>Islamabad</strong>"</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(167,139,250,0.08); border-color:rgba(167,139,250,0.18); color:#cbb8ff;">
        <strong style="color:var(--purple);">Syntax</strong>
        <span class="tiny">"She <strong>doesn't</strong> like..." not "She don't like..."</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(251,146,60,0.08); border-color:rgba(251,146,60,0.18); color:#fdc89b;">
        <strong style="color:var(--orange);">Logic</strong>
        <span class="tiny">"If A then B; A; therefore <strong>B</strong>"</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(250,204,21,0.08); border-color:rgba(250,204,21,0.18); color:#fde68a;">
        <strong style="color:var(--yellow);">Math</strong>
        <span class="tiny">"\(2 + 2 = 4\)"</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(244,114,182,0.08); border-color:rgba(244,114,182,0.18); color:#fbb8d8;">
        <strong style="color:var(--pink);">Social cues</strong>
        <span class="tiny">"'I'm fine' (said angrily) means <strong>not fine</strong>"</span>
      </div>
      <div class="callout info" style="margin:0; flex-direction:column; text-align:center; background:rgba(74,222,128,0.08); border-color:rgba(74,222,128,0.18); color:#9eefbe;">
        <strong style="color:var(--green);">Code patterns</strong>
        <span class="tiny">"for i in range(n): <strong>...</strong>"</span>
      </div>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="callout success" style="max-width:var(--measure-lg);">
    <span class="icon">i</span>
    <span><strong>The compression hypothesis:</strong> The best way to predict text is to <em>understand</em> the process that generated it. Next, we'll use compression as a practical lens before zooming out to the full training pipeline.</span>
  </div>
</div>

<!-- ═══════ SLIDE 25 — COMPRESSION LENS ═══════ -->
<div class="slide" id="slide-25">
  <span class="section-tag">Compression Lens</span>
  <div class="badge concept">Mental Model</div>
  <h2>A useful lens: Intelligence as compression</h2>
  <p class="small-text" style="max-width:var(--measure-xl);">During pretraining, the model learns compressed internal representations that preserve what is useful for predicting text. This is not a full theory of intelligence, but it is a helpful lens.</p>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:var(--measure-xl);">
    <div class="card">
      <h3 style="color:var(--accent);">Compression pressure encourages</h3>
      <ul class="obj-list" style="margin-top:var(--space-xs);">
        <li data-num="1">abstraction (categories, roles, relations)</li>
        <li data-num="2">reusable features across many tasks</li>
      </ul>
    </div>
    <div class="card">
      <h3 style="color:var(--green);">Why this matters</h3>
      <p class="small-text" style="line-height:1.7;">To predict text efficiently, the model is forced to represent large amounts of structure in a compact internal form.</p>
      <div class="spacer-sm"></div>
      <p class="small-text" style="line-height:1.7;">You can view pretraining as building a compact internal model of patterns that matter for prediction.</p>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <button class="reveal-btn" onclick="document.getElementById('compressionWhy').classList.toggle('revealed')">Why next-token prediction implies compression</button>
  <div class="hidden-content" id="compressionWhy">
    <div class="callout warn" style="max-width:var(--measure-xl);">
      <span class="icon">!</span>
      <span><strong>Raw problem:</strong> language is high-dimensional; tokens are noisy/redundant/ambiguous; surface forms vary wildly while deeper structures repeat.</span>
    </div>
    <div class="callout info" style="max-width:var(--measure-xl); margin-top:var(--space-xs);">
      <span class="icon">→</span>
      <span><strong>A pure memorizer fails:</strong> poor generalization, huge capacity needs, and brittleness to slightly novel phrasing.</span>
    </div>
    <div class="callout success" style="max-width:var(--measure-xl); margin-top:var(--space-xs);">
      <span class="icon">✓</span>
      <span><strong>So loss minimization pushes compression:</strong> collapse many surface forms into shared representations; retain what matters for next-token prediction; discard what does not.</span>
    </div>
  </div>
</div>

<!-- ═══════ SLIDE 26 — WHAT GETS COMPRESSED ═══════ -->
<div class="slide" id="slide-26">
  <span class="section-tag">Compression Lens</span>
  <div class="badge concept">Mechanism</div>
  <h2>What gets compressed, and why it looks like reasoning</h2>
  <p class="small-text" style="max-width:var(--measure-xl);">These structures are not explicitly labeled in pretraining. They emerge as latent variables that make prediction easier.</p>
  <div class="spacer-sm"></div>
  <div class="grid-2" style="max-width:var(--measure-xl);">
    <div class="card">
      <h3 style="color:var(--cyan);">What gets compressed</h3>
      <ul class="obj-list" style="margin-top:var(--space-xs);">
        <li data-num="1">entities (people, places, objects)</li>
        <li data-num="2">roles (subject, object, agent, patient)</li>
        <li data-num="3">relations (ownership, causality, temporal order)</li>
        <li data-num="4">abstract patterns (arguments, plans, code structure)</li>
        <li data-num="5">latent state (what is currently true)</li>
      </ul>
    </div>
    <div class="card">
      <h3 style="color:var(--orange);">Why this appears as reasoning</h3>
      <p class="small-text" style="line-height:1.7;">In narratives, explanations, mathematics, programming, and multi-step instructions, accurate continuation requires coherent internal state that respects constraints.</p>
      <div class="spacer-sm"></div>
      <div class="callout info" style="margin:0;">
        <span class="icon">i</span>
        <span>You cannot finish a proof without tracking assumptions, continue a story without tracking who did what, or autocomplete code without tracking scope and types.</span>
      </div>
    </div>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout success" style="max-width:var(--measure-xl);">
    <span class="icon">✓</span>
    <span><strong>Transfer intuition:</strong> the same compressed internal features that help predict text also help many downstream tasks.</span>
  </div>
  <div class="callout info" style="max-width:var(--measure-xl);">
    <span class="icon">→</span>
    <span>This lens explains why pretraining transfers broadly. With that framing, now zoom out to the full training pipeline.</span>
  </div>
</div>

<!-- ═══════ SLIDE 18 — THE FULL TRAINING PIPELINE ═══════ -->
<div class="slide" id="slide-18">
  <span class="section-tag">Training Pipeline</span>
  <div class="badge concept">Overview</div>
  <h2>The LLM training pipeline</h2>
  <p class="small-text">From raw internet text to a useful assistant — four major stages.</p>
  <div class="spacer"></div>
  <div class="grid-4" style="gap:var(--space-md);">
    <div class="pipeline-box" style="border-color: rgba(34,211,238,0.3);">
      <div class="pipe-num" style="background:var(--cyan);">1</div>
      <h3 style="color:var(--cyan);">Data</h3>
      <p class="small-text">Collect, clean, deduplicate, and filter trillions of tokens from the web, books, code</p>
    </div>
    <div class="pipeline-box" style="border-color: rgba(108,140,255,0.3);">
      <div class="pipe-num" style="background:var(--accent);">2</div>
      <h3 style="color:var(--accent);">Pretrain</h3>
      <p class="small-text">Train on next-token prediction across the entire dataset, learning general language understanding</p>
    </div>
    <div class="pipeline-box" style="border-color: rgba(251,146,60,0.3);">
      <div class="pipe-num" style="background:var(--orange);">3</div>
      <h3 style="color:var(--orange);">Post-train</h3>
      <p class="small-text">Fine-tune with human feedback (SFT + RLHF/DPO) to make the model helpful, harmless, and honest</p>
    </div>
    <div class="pipeline-box" style="border-color: rgba(74,222,128,0.3);">
      <div class="pipe-num" style="background:var(--green);">4</div>
      <h3 style="color:var(--green);">Eval</h3>
      <p class="small-text">Benchmark on tasks, red-team for safety, measure calibration, test in real-world scenarios</p>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="flow">
    <div class="flow-box data" style="font-size:clamp(0.74rem, 0.71rem + 0.1vw, 0.84rem);">Raw text<br><span class="tiny">\(\sim 10\,\mathrm{T}\) tokens</span></div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box data" style="font-size:clamp(0.74rem, 0.71rem + 0.1vw, 0.84rem);">Clean data<br><span class="tiny">\(\sim 2\text{--}5\,\mathrm{T}\) tokens</span></div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box model" style="font-size:clamp(0.74rem, 0.71rem + 0.1vw, 0.84rem);">Pretrain<br><span class="tiny">weeks on \(\sim 10^3\) GPUs</span></div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box grad" style="font-size:clamp(0.74rem, 0.71rem + 0.1vw, 0.84rem);">Align<br><span class="tiny">SFT + RLHF</span></div>
    <div class="flow-arrow loop-arrow-anim">→</div>
    <div class="flow-box green" style="font-size:clamp(0.74rem, 0.71rem + 0.1vw, 0.84rem);">Deploy<br><span class="tiny">serve to users</span></div>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Give a high-level overview. Emphasize that pretraining is the expensive, foundational step. Post-training is comparatively cheap but crucial for usability.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 19 — DATA WORK ═══════ -->
<div class="slide" id="slide-19">
  <span class="section-tag">Data</span>
  <div class="badge day1">Deep Dive</div>
  <h2>What "data work" actually entails</h2>
  <p class="small-text" style="max-width:var(--measure-md);">Data quality is arguably the most important factor in LLM training. Garbage in, garbage out — but at scale, "garbage" is nuanced.</p>
  <div class="spacer"></div>
  <div style="display:flex; flex-direction:column; gap:var(--space-md); max-width:var(--measure-xl);">
    <div class="card" style="display:flex; gap:var(--space-lg); align-items:start; padding:clamp(14px, 1.2vw, 22px) clamp(16px, 1.4vw, 24px);">
      <div style="font-size:clamp(1.3rem, 1.05rem + 0.7vw, 1.85rem); line-height:1;">1</div>
      <div>
        <h3 style="color:var(--cyan); font-size:clamp(0.88rem, 0.84rem + 0.15vw, 1.02rem);">Collection</h3>
        <p class="small-text">Web crawls (Common Crawl), books, academic papers, code repositories (GitHub), Wikipedia, forums, multilingual sources. Scale: billions of web pages.</p>
      </div>
    </div>
    <div class="card" style="display:flex; gap:var(--space-lg); align-items:start; padding:clamp(14px, 1.2vw, 22px) clamp(16px, 1.4vw, 24px);">
      <div style="font-size:clamp(1.3rem, 1.05rem + 0.7vw, 1.85rem); line-height:1;">2</div>
      <div>
        <h3 style="color:var(--accent); font-size:clamp(0.88rem, 0.84rem + 0.15vw, 1.02rem);">Cleaning</h3>
        <p class="small-text">Remove boilerplate (nav bars, footers, ads), fix encoding issues, strip HTML/JS artifacts, filter out non-natural-language content.</p>
      </div>
    </div>
    <div class="card" style="display:flex; gap:var(--space-lg); align-items:start; padding:clamp(14px, 1.2vw, 22px) clamp(16px, 1.4vw, 24px);">
      <div style="font-size:clamp(1.3rem, 1.05rem + 0.7vw, 1.85rem); line-height:1;">3</div>
      <div>
        <h3 style="color:var(--orange); font-size:clamp(0.88rem, 0.84rem + 0.15vw, 1.02rem);">Deduplication</h3>
        <p class="small-text">Exact dedup (hash-based) and fuzzy dedup (MinHash/LSH). Duplicates cause memorization, poor generalization, and wasted compute. Typically removes \(30\%\text{--}50\%\) of data.</p>
      </div>
    </div>
    <div class="card" style="display:flex; gap:var(--space-lg); align-items:start; padding:clamp(14px, 1.2vw, 22px) clamp(16px, 1.4vw, 24px);">
      <div style="font-size:clamp(1.3rem, 1.05rem + 0.7vw, 1.85rem); line-height:1;">4</div>
      <div>
        <h3 style="color:var(--purple); font-size:clamp(0.88rem, 0.84rem + 0.15vw, 1.02rem);">Quality Filtering</h3>
        <p class="small-text">Heuristic filters (length, language, perplexity) and classifier-based filtering. Domain-specific upsampling for code, math, etc.</p>
      </div>
    </div>
    <div class="card" style="display:flex; gap:var(--space-lg); align-items:start; padding:clamp(14px, 1.2vw, 22px) clamp(16px, 1.4vw, 24px);">
      <div style="font-size:clamp(1.3rem, 1.05rem + 0.7vw, 1.85rem); line-height:1;">5</div>
      <div>
        <h3 style="color:var(--green); font-size:clamp(0.88rem, 0.84rem + 0.15vw, 1.02rem);">Annotation & Curation</h3>
        <p class="small-text">For post-training: human-written demonstrations (SFT data), preference rankings (RLHF), safety labels. Quality of annotation directly determines alignment quality.</p>
      </div>
    </div>
  </div>
  <div class="speaker-notes">
    <button class="notes-toggle" onclick="this.nextElementSibling.classList.toggle('open')">speaker notes</button>
    <div class="notes-body"><p>Spend time on each step. Give examples of what "bad data" looks like. Data work is unglamorous but accounts for a huge fraction of model quality.</p></div>
  </div>
</div>

<!-- ═══════ SLIDE 20 — DATA BY THE NUMBERS ═══════ -->
<div class="slide" id="slide-20">
  <span class="section-tag">Data</span>
  <div class="badge day1">Scale</div>
  <h2>Data by the numbers</h2>
  <div class="spacer"></div>
  <div class="grid-4">
    <div class="card" style="text-align:center; padding:clamp(14px, 1.2vw, 24px);">
      <div class="data-stat">
        <div class="big-num" style="color:var(--cyan);">\(\sim 15\,\mathrm{T}\)</div>
        <div class="stat-label">tokens in Llama 3's training set</div>
      </div>
    </div>
    <div class="card" style="text-align:center; padding:clamp(14px, 1.2vw, 24px);">
      <div class="data-stat">
        <div class="big-num" style="color:var(--accent);">\(\sim 100+\)</div>
        <div class="stat-label">languages represented</div>
      </div>
    </div>
    <div class="card" style="text-align:center; padding:clamp(14px, 1.2vw, 24px);">
      <div class="data-stat">
        <div class="big-num" style="color:var(--orange);">\(\sim 50\%\)</div>
        <div class="stat-label">data removed by dedup alone</div>
      </div>
    </div>
    <div class="card" style="text-align:center; padding:clamp(14px, 1.2vw, 24px);">
      <div class="data-stat">
        <div class="big-num" style="color:var(--green);">\(\sim 100\,\mathrm{K}\)</div>
        <div class="stat-label">human-labeled examples for alignment</div>
      </div>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="callout warn" style="max-width:var(--measure-lg);">
    <span class="icon">!</span>
    <span><strong>Data is running out.</strong> We're approaching the point where most useful public text has been used. This drives research into synthetic data generation, multi-epoch training, and more efficient learning.</span>
  </div>
  <div class="spacer-sm"></div>
  <div class="callout info" style="max-width:var(--measure-lg);">
    <span class="icon">i</span>
    <span><strong>Chinchilla scaling laws:</strong> For a compute-optimal model, scale data and parameters roughly equally. But recent models over-train: more data, same params → better inference-time efficiency.</span>
  </div>
</div>

<!-- ═══════ SLIDE 21 — DAY 1 RECAP ═══════ -->
<div class="slide" id="slide-21">
  <span class="section-tag">Wrap-up</span>
  <div class="badge day1">Summary</div>
  <h2>Day 1 Recap</h2>
  <div class="spacer-sm"></div>
  <div style="display:flex; flex-direction:column; gap:var(--space-md); max-width:var(--measure-lg);">
    <div class="callout success" style="margin:0;">
      <span class="icon">1</span>
      <span><strong>LLMs compute a function:</strong> tokens in → probability distribution out, by running through attention layers and feed-forward networks. At inference, we sample and repeat.</span>
    </div>
    <div class="callout success" style="margin:0;">
      <span class="icon">2</span>
      <span><strong>They learn via next-token prediction:</strong> the loss is simply \(-\log P(\text{correct token})\). This narrow objective, applied at massive scale, produces emergent capabilities — because predicting text well requires understanding the world.</span>
    </div>
    <div class="callout success" style="margin:0;">
      <span class="icon">3</span>
      <span><strong>Training = data → pretrain → post-train → eval:</strong> Pretraining is the foundation (expensive, general). Post-training (alignment) makes the model useful and safe.</span>
    </div>
    <div class="callout success" style="margin:0;">
      <span class="icon">4</span>
      <span><strong>Data work is critical:</strong> collection, cleaning, dedup, filtering, annotation. Data quality is the single biggest lever for model quality.</span>
    </div>
  </div>
  <div class="spacer"></div>
  <div class="gradient-line" style="max-width:var(--measure-xs); margin:0 auto;"></div>
  <div class="spacer-sm"></div>
  <div style="text-align:center;">
    <p class="small-text" style="color:var(--text-dim);">Tomorrow: <span class="hl-purple">what the model computes internally</span> — tokenization, embeddings, attention, FFN, the full forward pass.</p>
  </div>
</div>

</div><!-- /slide-container -->

<!-- ── Bottom navigation bar ── -->
<div class="bottom-bar">
  <button class="nav-btn" id="btnPrev" disabled>← Back</button>
  <div class="progress-track">
    <div class="progress-fill" id="progressFill" style="width:0%"></div>
  </div>
  <span class="slide-counter" id="slideCounter">1 / 27</span>
  <button class="nav-btn primary" id="btnNext">Next →</button>
</div>

<script>
// ══════════════════════════════════════
//  Slide engine
// ══════════════════════════════════════
const SLIDE_ORDER = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 8, 15, 22, 23, 24, 16, 17, 25, 26, 18, 19, 20, 21];
const TOTAL = SLIDE_ORDER.length;
let current = 0;

const $ = s => document.querySelector(s);
const $$ = s => document.querySelectorAll(s);

function renderMathIn(root = document) {
  if (!window.MathJax || !window.MathJax.typesetPromise) return;
  if (window.MathJax.typesetClear) window.MathJax.typesetClear([root]);
  window.MathJax.typesetPromise([root]).catch(() => {});
}

function updateDeckScale() {
  const container = document.getElementById('slideContainer');
  if (!container) return;

  const baseW = 1600;
  const baseH = 900;
  const styles = window.getComputedStyle(container);
  const padX = parseFloat(styles.paddingLeft || '0') + parseFloat(styles.paddingRight || '0');
  const padY = parseFloat(styles.paddingTop || '0') + parseFloat(styles.paddingBottom || '0');

  const availableW = Math.max(container.clientWidth - padX, 1);
  const availableH = Math.max(container.clientHeight - padY, 1);

  const rawScale = Math.min(availableW / baseW, availableH / baseH);
  const rootStyles = window.getComputedStyle(document.documentElement);
  const maxScaleVar = parseFloat(rootStyles.getPropertyValue('--deck-max-scale'));
  const maxScale = Number.isFinite(maxScaleVar) ? maxScaleVar : 1.22;
  const scale = Math.min(rawScale, maxScale);

  document.documentElement.style.setProperty('--deck-base-width', String(baseW));
  document.documentElement.style.setProperty('--deck-base-height', String(baseH));
  document.documentElement.style.setProperty('--deck-scale', String(Math.max(scale, 0.1)));
}

function goTo(n) {
  if (n < 0 || n >= TOTAL) return;
  $$('.slide').forEach(s => s.classList.remove('active'));
  const slideId = SLIDE_ORDER[n];
  document.getElementById(`slide-${slideId}`).classList.add('active');
  current = n;
  $('#btnPrev').disabled = n === 0;
  $('#btnNext').textContent = n === TOTAL - 1 ? 'Restart ↺' : 'Next →';
  $('#slideCounter').textContent = `${n + 1} / ${TOTAL}`;
  $('#progressFill').style.width = `${(n / (TOTAL - 1)) * 100}%`;

  // trigger animations for specific slides
  onSlideEnter(slideId);
  renderMathIn(document.getElementById(`slide-${slideId}`));
}

$('#btnNext').addEventListener('click', () => {
  if (current === TOTAL - 1) goTo(0);
  else goTo(current + 1);
});
$('#btnPrev').addEventListener('click', () => goTo(current - 1));

document.addEventListener('keydown', e => {
  if (e.key === 'ArrowRight' || e.key === ' ') { e.preventDefault(); $('#btnNext').click(); }
  if (e.key === 'ArrowLeft') { e.preventDefault(); $('#btnPrev').click(); }
});

// ══════════════════════════════════════
//  Ingredient 3 reveal
// ══════════════════════════════════════
function revealIngredient3() {
  document.getElementById('ingredient3Hidden').style.display = 'none';
  document.getElementById('ingredient3Revealed').style.display = 'block';
  document.getElementById('ingredient3Card').style.borderColor = 'rgba(167,139,250,0.4)';
  document.getElementById('ingredientExplanation').classList.add('revealed');
}

function revealReasoningPressure() {
  const grid = document.getElementById('reasoningPressureGrid');
  const quote = document.getElementById('reasoningEmergenceQuote');
  if (grid) grid.classList.add('revealed');
  if (quote) quote.classList.add('revealed');
}

function revealDramaAnswer() {
  const blank = document.getElementById('dramaKillerBlank');
  const why = document.getElementById('dramaWhy');
  const result = document.getElementById('dramaResult');
  if (blank && !blank.classList.contains('show')) {
    blank.textContent = blank.dataset.answer;
    blank.classList.add('show');
  }
  if (why) why.classList.add('revealed');
  if (result) {
    result.className = 'callout success';
    result.style.maxWidth = '800px';
    result.innerHTML = '<span class="icon">✓</span><span>Best next-token continuation: <strong>Rukhsana thi</strong>, based on timing + access constraints.</span>';
  }
}

function chooseDramaSuspect(choice, btn) {
  const buttons = document.querySelectorAll('#dramaChoices .drama-choice');
  buttons.forEach(b => b.classList.remove('correct', 'wrong'));
  if (choice === 'Rukhsana') btn.classList.add('correct');
  else btn.classList.add('wrong');

  const result = document.getElementById('dramaResult');
  if (result) {
    const isCorrect = choice === 'Rukhsana';
    result.className = isCorrect ? 'callout success' : 'callout warn';
    result.style.maxWidth = '800px';
    result.innerHTML = isCorrect
      ? '<span class="icon">✓</span><span>Consistent choice. Timing and pantry-access constraints point to <strong>Rukhsana</strong>.</span>'
      : '<span class="icon">!</span><span>This choice conflicts with the timeline/access clues. Re-check who could act between 10:20 and 10:30.</span>';
  }

  if (choice === 'Rukhsana') {
    revealDramaAnswer();
  }
}

// ══════════════════════════════════════
//  Live demo video (lazy load)
// ══════════════════════════════════════
let liveDemoLoaded = false;

function getLiveDemoCandidates(host) {
  const candidates = [];
  // 1) First try same directory as this HTML file.
  if (host.dataset.videoRelative) {
    candidates.push(host.dataset.videoRelative);
  }
  // 2) Fallback to absolute path.
  if (host.dataset.videoPath && host.dataset.videoPath.startsWith('/')) {
    candidates.push(`file://${host.dataset.videoPath}`);
  } else if (host.dataset.videoPath) {
    candidates.push(host.dataset.videoPath);
  }
  return candidates;
}

function ensureLiveDemoLoaded() {
  if (liveDemoLoaded) return;
  const host = document.getElementById('liveDemoHost');
  if (!host) return;

  const candidates = getLiveDemoCandidates(host);
  if (!candidates.length) return;

  const video = document.createElement('video');
  video.className = 'live-demo-video';
  video.controls = true;
  video.preload = 'metadata';
  video.playsInline = true;

  let idx = 0;
  const tryNextSource = () => {
    if (idx >= candidates.length) return;
    video.src = candidates[idx++];
    video.load();
  };
  video.addEventListener('error', tryNextSource);
  tryNextSource();

  host.innerHTML = '';
  host.appendChild(video);
  liveDemoLoaded = true;
}

function pauseLiveDemoIfNeeded() {
  const host = document.getElementById('liveDemoHost');
  if (!host) return;
  const video = host.querySelector('video');
  if (!video) return;
  video.pause();
}

// ══════════════════════════════════════
//  Inference demo (fixed: 3 steps only)
// ══════════════════════════════════════
const INF_TOKENS = ['Islamabad', '.', '⟨EOS⟩'];
let infStep = 0;

function animateInference() {
  if (infStep >= INF_TOKENS.length) return;

  const row = document.getElementById('inferenceDemo');
  const cur = document.getElementById('infCurrent');

  // convert current blank → filled token
  cur.removeAttribute('id');
  cur.classList.remove('blank');
  cur.style.cursor = 'default';
  cur.onclick = null;

  const tok = INF_TOKENS[infStep];
  cur.textContent = tok;

  if (tok === '⟨EOS⟩') {
    // end-of-sentence styling
    cur.classList.add('done');
  } else {
    cur.classList.add('target');
    cur.style.borderStyle = 'solid';
  }

  infStep++;

  // add next blank if not finished
  if (infStep < INF_TOKENS.length) {
    setTimeout(() => {
      const newBlank = document.createElement('span');
      newBlank.className = 'tok blank';
      newBlank.id = 'infCurrent';
      newBlank.textContent = 'click';
      newBlank.onclick = animateInference;
      row.appendChild(newBlank);
    }, 350);
  } else {
    // all done — update hint text
    document.getElementById('infHint').textContent = 'Generation complete — the model produced 3 tokens.';
    document.getElementById('infHint').style.color = 'var(--green)';
  }
}

// ══════════════════════════════════════
//  NTP game
// ══════════════════════════════════════
function revealNTP(el) {
  if (el.classList.contains('show')) return;
  el.textContent = el.dataset.answer;
  el.classList.add('show');
}
function revealNTPConcept(btn) {
  const sentence = btn.closest('.ntp-sentence');
  const tag = sentence ? sentence.querySelector('.ntp-tag') : null;
  if (tag) tag.classList.add('show');
  btn.style.display = 'none';
}
function revealAllNTP() {
  $$('.ntp-blank').forEach(el => {
    el.textContent = el.dataset.answer;
    el.classList.add('show');
  });
  $$('.ntp-concept-btn').forEach(btn => { btn.style.display = 'none'; });
  $$('.ntp-tag').forEach(tag => tag.classList.add('show'));
}

// ══════════════════════════════════════
//  Bar chart builder (for loss deep-dive)
// ══════════════════════════════════════
const VOCAB = [
  { word: 'Islamabad', predicted: 0.08, target: 1.00, after: 0.28 },
  { word: 'Karachi',   predicted: 0.11, target: 0.00, after: 0.06 },
  { word: 'the',       predicted: 0.14, target: 0.00, after: 0.09 },
  { word: 'Lahore',    predicted: 0.06, target: 0.00, after: 0.03 },
  { word: 'a',         predicted: 0.10, target: 0.00, after: 0.07 },
  { word: 'Peshawar',  predicted: 0.04, target: 0.00, after: 0.03 },
  { word: 'Delhi',     predicted: 0.05, target: 0.00, after: 0.02 },
  { word: 'not',       predicted: 0.07, target: 0.00, after: 0.05 },
  { word: '...',       predicted: 0.35, target: 0.00, after: 0.37 },
];

function buildBars(container, data, type) {
  const el = typeof container === 'string' ? $(container) : container;
  if (!el) return;
  el.innerHTML = '';
  data.forEach((d, i) => {
    const row = document.createElement('div');
    row.className = 'bar-row';

    const wordEl = document.createElement('div');
    wordEl.className = 'bar-word';
    wordEl.textContent = d.word;
    if (d.word === 'Islamabad') wordEl.style.color = 'var(--green)';

    const track = document.createElement('div');
    track.className = 'bar-track';

    const fill = document.createElement('div');
    fill.className = 'bar-fill ' + type;
    const pctWidth = d.value > 0 ? Math.max(d.value * 100, 1.5) : 0;
    fill.style.width = '0%';
    setTimeout(() => { fill.style.width = pctWidth + '%'; }, 80 + i * 50);

    track.appendChild(fill);

    const pctEl = document.createElement('div');
    pctEl.className = 'bar-pct';
    pctEl.textContent = (d.value * 100).toFixed(1) + '%';

    row.appendChild(wordEl);
    row.appendChild(track);
    row.appendChild(pctEl);
    el.appendChild(row);
  });
}

function predictedData() { return VOCAB.map(v => ({ word: v.word, value: v.predicted })); }
function targetData()    { return VOCAB.map(v => ({ word: v.word, value: v.target })); }
function afterData()     { return VOCAB.map(v => ({ word: v.word, value: v.after })); }

// ══════════════════════════════════════
//  Slide-specific enter logic
// ══════════════════════════════════════
function onSlideEnter(n) {
  // Slide 2: lazy load live demo video only when needed
  if (n === 2) {
    ensureLiveDemoLoaded();
  } else {
    pauseLiveDemoIfNeeded();
  }

  // Slide 10: forward pass — build predicted chart
  if (n === 10) {
    buildBars('#predictedChart', predictedData(), 'predicted');
  }
  // Slide 11: target comparison — dual charts
  if (n === 11) {
    buildBars('#dualPredicted', predictedData(), 'predicted');
    buildBars('#dualTarget', targetData(), 'target-fill');
    const pct = VOCAB[0].predicted;
    $('#correctPctText').innerHTML = `\\(${(pct * 100).toFixed(0)}\\%\\)`;
  }
  // Slide 12: loss computation
  if (n === 12) {
    const p = VOCAB[0].predicted;
    const loss = -Math.log(p);
    $('#lossFormula').innerHTML =
      `\\[
        \\mathcal{L} = -\\log\\!\\left(P_{\\text{model}}(\\text{Islamabad})\\right) = -\\log(${p.toFixed(2)}) = ${loss.toFixed(2)}
      \\]`;
    $('#lossProbDisplay').innerHTML = `\\(${p.toFixed(2)}\\)`;
    $('#lossValueDisplay').innerHTML = `\\(${loss.toFixed(2)}\\)`;
    const meter = $('#lossMeter');
    meter.style.width = '0%';
    setTimeout(() => { meter.style.width = Math.min(loss / 5 * 100, 100) + '%'; }, 200);
  }
  // Slide 14: before/after
  if (n === 14) {
    buildBars('#beforeBars', predictedData(), 'predicted');
    setTimeout(() => {
      buildBars('#afterBars', afterData(), 'target-fill');
    }, 300);
    const afterLoss = -Math.log(VOCAB[0].after);
    $('#lossAfterVal').innerHTML = `\\(${afterLoss.toFixed(2)}\\)`;
    $('#afterCorrectPct').innerHTML = `\\(${(VOCAB[0].after * 100).toFixed(0)}\\%\\)`;
    $('#afterLossText').innerHTML = `\\(${afterLoss.toFixed(2)}\\)`;
  }
  if (n === 22) {
    const grid = document.getElementById('reasoningPressureGrid');
    const quote = document.getElementById('reasoningEmergenceQuote');
    if (grid) grid.classList.remove('revealed');
    if (quote) quote.classList.remove('revealed');
  }
  if (n === 23) {
    const blank = document.getElementById('dramaKillerBlank');
    const why = document.getElementById('dramaWhy');
    const result = document.getElementById('dramaResult');
    const buttons = document.querySelectorAll('#dramaChoices .drama-choice');
    if (blank) {
      blank.textContent = '___';
      blank.classList.remove('show');
    }
    if (why) why.classList.remove('revealed');
    buttons.forEach(b => b.classList.remove('correct', 'wrong'));
    if (result) {
      result.className = 'callout warn';
      result.style.maxWidth = '800px';
      result.innerHTML = '<span class="icon">?</span><span>Select a suspect. Then check whether your choice satisfies the timing + access constraints.</span>';
    }
  }
}

// ══════════════════════════════════════
//  Init
// ══════════════════════════════════════
const loadLiveDemoBtn = document.getElementById('loadLiveDemoBtn');
if (loadLiveDemoBtn) {
  loadLiveDemoBtn.addEventListener('click', ensureLiveDemoLoaded);
}

window.addEventListener('resize', updateDeckScale);
document.addEventListener('fullscreenchange', updateDeckScale);

updateDeckScale();
goTo(0);

if (window.MathJax && window.MathJax.startup && window.MathJax.startup.promise) {
  window.MathJax.startup.promise.then(() => {
    const slideId = SLIDE_ORDER[current];
    renderMathIn(document.getElementById(`slide-${slideId}`));
  });
}
</script>
</body>
</html>
